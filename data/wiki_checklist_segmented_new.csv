title;text;status
Systematic Literature Review;"[[File:ConceptSystematicLiteratureReview.png|450px|frameless|left|[[Sustainability Methods:About|Method categorization]] for [[Systematic_Literature_Review]]]]

<br/>
{|class=""wikitable"" style=""text-align: center; width: 50%""
! colspan = 3 | Method categorization
|-
| '''[[:Category:Quantitative|Quantitative]]''' || colspan=""2"" | '''[[:Category:Qualitative|Qualitative]]'''
|-
| '''[[:Category:Inductive|Inductive]]''' || colspan=""2""| '''[[:Category:Deductive|Deductive]]'''
|-
| style=""width: 33%""| '''[[:Category:Individual|Individual]]''' || style=""width: 33%""| '''[[:Category:System|System]]''' || '''[[:Category:Global|Global]]'''
|-
| style=""width: 33%""| '''[[:Category:Past|Past]]''' || style=""width: 33%""| '''[[:Category:Present|Present]]''' || [[:Category:Future|Future]]
|}
<br/>__NOTOC__
<br/>

'''In short:''' In a Systematic Literature Review, existing publications are systematically analysed to derive an overview of a specific slice of the literature, typically summarizing the state of the art regarding a specific topic.

== Background ==
[[File:SLR.png|thumb|400px|right|'''SCOPUS hits per year for Systematic Literature Review until 2019.''' Search term: 'systematic literature review' in Title, Abstract, Keywords. Source: own.]]

With the rise of empirical knowledge in the [[History of Methods|Enlightenment]] arose the possibility to synthesize knowledge from different studies into an overview work. '''''A Treatise on the Scurvy - A Critical and Chronological View of What has been Published on the Subject'' by James Lind is seen as the first systematic review''' (3, 5, 6), highlighting the importance of knowledge integration. Another important origin of research synthesis can be traced to the work of 17th Century astronomers who combined data sets from different studies to ammend their own observations (3). '''Systematic literature reviews gained a vital tool through the work of Karl Pearson, whose work on statistics allowed to compile the results from several datasets into an overview.''' His 1904 publication - in which he combined 11 studies on typhoid vaccines and highlighted irregularities in the results - can be considered the first Meta-Analysis (3, 5). Meta-Analyses were subsequently applied more commonly during the 20th Century, for example in agriculture (5, 6). 

After the Second World War, US social scientists began to recognize the need to review the rising amount of research data while considering how to reduce [[Glossary|bias]] and enhance reproducibility of systematic reviews (6). This also led to the increasing recognition of qualitative elements. In the 1970s, statistician Gene Glass and colleagues proclaimed Meta-Analyses as a valid procedure for synthesising studies which helped to consolidate the approach (3). However, Systematic Literature Reviews were long viewed as second-class studies within Academia, since they did not yield primary data. This changed during the last decades, partly due to increasing interest in scientific evidence on diverse topics on the part of public policy makers, practitioners and the general public (6).

More recently, due to the emergence of digitalisation and improvements in information storage and retrieval, it became significantly easier to identify, gather and analyze the available research on a specific topic (3). Today, Systematic Literature Reviews are most commonly used in Medicine, in the Social Sciences, Business and Economics, but have found their way into several other disciplines (5).


== What the method does ==
Systematic Literature Reviews exist in a broad variety of types. While the Literature Review may be seen as the overarching term, sub-types include the Meta-Synthesis, the Systematic Review, the Case Survey or the strict Meta-Analysis (7). Their differentiation may be done in terms of the data they summarize (quantitative and/or qualitative) as well as the way this data is analyzed (qualitatively or quantitatively) (7). Reviews may also be differentiated according to their focus, goal, perspective, coverage, organization and audience. In this entry, we will focus on the Systematic Literature Review. More information on different sub-types of the method can be found in (3). Further, the approach of Meta-Analyses as the statistical tool of summarizing a variety of studies on a specific topic into one is an important method in this regard. [[Meta-Analysis|For more on Meta-Analyses, please read the respective Wiki entry.]]

==== Definition ====
A Systematic Literature Review is, in short, a reproducible process in which scientific publications that ""contain information, ideas, data and evidence"" (Hart 2018, p.13) on a specific topic are gathered; studies that fulfill a previously defined level of quality are selected; and their results and insights are summarized and evaluated. For the researcher, the results from this process provide insights into the current state of research and highlight relevant new directions for (their) further research (1, 2, 3). The term 'systematic' refers to the fact that the process is structured to minimize [[Glossary|bias]] (6) and maximimize reproducibility. Being 'systematic' means being reproducible and goes along with an a priori specified, dedicated research design and an explicit documentation of the steps taken during the research (3, see Normativity).

[[File:Systematic Literature Review - Use of the method.png|500px|thumb|center|'''Some of the questions that a Literature Review can answer.''' Source: Hart 2018, p.14]]

A Systematic Literature Review can be applied as the primary method of a scientific study, but is often also used as a first step in a larger research projector endeavor. In both cases, a review can help:
* recognize what has already been done already regarding a specific research field or topics
* find and resolve conflicts in (seemingly) contradictory studies, and
* identify evolving or even unexplored research topics, questions or new hypotheses for further research.

When used as a preparation to one's own study, a Systematic Literature Review additionally helps the researcher
* identify relevant literature and researchers to consult,
* design appropriate methodological approaches,
* understand important concepts, theories and topics and summarise this knowledge to the reader
* contextualize this research and show why it would answer an open question, often on integration level. (1, 3, 4)

==== Step by Step ====
A Systematic Literature Review follows a set of steps that is similar to any scientific research process (1, 3, 4):

'''1) Planning:''' 
The research is designed by formulating the question and scope of the review (here, the different forms of the review - see above - are of relevance). This planning can be both [[:Category:Inductive|inductive]] as well as [[:Category:Deductive|deductive]], depending on the focus of the review. For example, the researcher may be interested in how the literature defines ""Sustainable Agriculture"" (see example below), and thus choose to search for literature that apply and preferably define this concept.";done
Systematic Literature Review;"'''5. Writing & presentation of the review:'''
Finally, the results of the Systematic Literature Review are compiled into a structured paper. A sample structure for the review as a preface to an original study may look like this (Rowley & Slack 2004, p.38): 
# Basic Definitions of key terms
# Why is the subject of interest?
# What research has already been undertaken on the topic, and is there any research on aspects of the topic that this research might investigate? 
# A clear summary of the results and new research opportunities that emerge from the literature review. Quotations may be used to underline specific findings from the review. 
# In addition, the literature gathered during the review should be listed. Many reviews consists a combination of information on the specific topic, the conceptual foundation, methodological approaches, and relevant scales that are associated to the available literature.

In summary, Systematic Literature Reviews are methods of data gathering - building on primary data from other empirical papers - and analysis. They are inductive because they conclude based on existing literature, but also deductive since they typically start with theoretical assumptions and a pre-defined thematic scope. They can be qualitative and quantitative, cover very local to global phenomena, and investigate past and present states of the literature, often offering a state of the art of the literature, and thereby suggestions and agenda for future research.


== Strengths & Challenges ==
* A literature review is a helpful starting point for any research: it provides a structured overview of the current knowledge and open questions in the respective field and may lead to new research questions that had not been obvious to the researcher before. The strength here is the systematic nature of the literature review: by not only reading randomly through literature, but instead following a systematic and reproducible approach, the researcher generates a more objective overview of the literature. Of course, the selected literature may still be biased and heavily depends on the research and selection criteria, but if this process is properly reasoned and documented, the bias may be reduced compared to a non-systematic review.
* When used in preparation to an original study, ""[r]eviewing the literature in a systematic way helps the author to be clear, to build confidence in their work and demonstrate the rigour of their methods."" (3, p.9). This is why Systematic Reviews are often done in a first step of a larger study, or as a first paper of a PhD student.
* The systematic approach enables the researcher to state conclusions about the strength of available evidence to a specific assumption. This does not only support their own subsequent work, but also provide insight into the state of science in a given field to policy makers and other public actors. This way, the Systematic Literature Review may for example also shine light on the effectiveness of programs and policies (3).

Potential mistakes and thus challenges in the review process include (4):
* not clearly relating the findings of the literature review to the researcher's own study
* not taking sufficient time to identify the best (primary!) sources
* not critically reflecting upon the studies' research designs and analysis
* not reporting the search procedures
* reporting isolated statistical results instead of meta-analytic or [[Simple Statistical Tests|chi-square]] methods
* not considering contrary findings or alternative interpretations when synthesizing quantitative literature


== Normativity ==
==== Connectedness ====
* The Systematic Literature Review is strongly connected to further methods. As explained before, this form of secondary research is often included as a groundwork in original primary studies to help justify the research topic, design and methodology (2). ""Indeed, the concluding paragraphs of the literature review should lead seamlessly to research propositions and methodologies."" (1, p.32)
* The analysis of the gathered studies, as mentioned before, can take place in a quantitative way based on a variety of quantitative approaches. Most notably, the [[Meta-Analysis]] is of relevance here.
* Systematic Literature Reviews represent an interesting and important form of methodological approach: they allow research on research. If scientific results only cumulated and no one looked at the bigger picture, science would not work. Methods like the literature review are thus crucial for academic processes.
* Again, we would like to highlight that there is a difference between Systematic Literature Reviews and Literature Reviews in general. Often, you will do a literature review for a university report, or your thesis. For this, you gain an understanding of the available theoretical and empirical literature on a topic by browsing through literature, possibly through snowball sampling, until you feel like you have read enough. This may be necessary, enables you, to structure your own data collection, or to write an essay about the topic. This is absolutely valid, but is different from a systematic review with the presented systematic approach and documentation, which may enable much deeper insights into available research in the field.";done
"The ""I"" in this wiki";"Using the first person is usually discouraged in scientific writing. In a nutshell, I disagree with this notion, and explain in this text, why we use the first person - both ''I'' and ''we'' - in this Wiki, and how you should read and understand this.

'''I perceive the norm of writing in a third person as a scientist as a clear indicator of the arrogance of science that is deeply rooted in the fallacy of positivism.''' By writing in the third person, many scientists [https://www.editage.com/insights/is-it-acceptable-to-use-first-person-pronouns-in-scientific-writing claim they convey objective information] that can be reproduced by anyone, while [https://www.sciencemag.org/careers/2012/03/how-write-scientist the first person humanises our work]. 
I think that by clearly indicating something as our personal opinion or to be based on our personal experience we give the information more value, and not less. This is rooted in me defining myself as a [[Bias and Critical Thinking|critical realist]]. I think there is higher value information in ethics that help us make sense of the world and find meaning, and these are ontologically objective [[Glossary|assumptions]]. However, when it comes to epistemological knowledge - and this is what sciences is mostly preoccupied with - we only have subjective information at our disposal. 

'''Within this epistemological knowledge, it is possible to clearly differentiate between activated observations that I made, and observations that are shared by the scientific community.''' For the latter, I would clearly use the third person. By doing this, I clearly acknowledge that our knowledge may change in the future, but there is a scientific canon that currently agrees on specific knowledge. An example of such knowledge would be the continuous development of life through evolution. Our knowledge about the mechanisms which we understand that are behind these [[Glossary|processes]] still continuously change (consider for instance the impact of epigenetic on our lives). Still, we can widely agree that there are processes such as natural selection and mutations that drive the adaptation and further development of living organisms. It is thus justified to say that science generally accepts evolution as the mechanisms behind the diversity of life. This is different from information that is conveyed by a sub-community within the wider arena of science. Altruism is a good example where you have basically two principal sub-communities: the scientists that view altruism as a trait of evolutions, and scientists who look for something beyond a mere kinship advantage perceived through altruism. I count myself to the latter group. I do no want to act altruistically because evolution tells me to, but look instead for higher reasons that are independent of my genes. Another example would be in statistics. I am more interested in parsimonious models, and many scientists would agree that these are preferable to full models. However, some researchers believe that full models - without any model reduction towards a parsimonious model - deserve our attention, and hence publish full models. An increasing number of researchers within frequentist statistics consider that this approach is wrong. Consequently, when I say ""we propose that model reduction is preferable to reporting full models"", I mean myself and likeminded scientists. This is a deeply normative statement rooted in my experience and the experience of other scientist, and therefore ideally deserves further explanation. Consequently, I might write something to the end of ""by avoiding p-values and building my model reduction on AIC values, the reported statistic model are more robust under the criteria of parsimony"".

'''The use of third person is to me a great destroyer of scientific discourse since it makes the way we conduct discourse less precise.''' I think the scientific community made a grave mistake when it shifted to the third voice almost exclusively, since this took away any possibility to clearly indicate whether you speak of widely accepted knowledge, knowledge accepted by a specific community, or your own experience. The last sentences are all written in the first person, because I wrote down my opinion. It is ""I"" who has this opinion, and while I am sure and even vaguely know that I am not the only person that has this opinion, the norms of the scientific community widely reject my opinion. I have no precise knowledge about other scientists who share my opinion. Hence I verbalised a new thought, and this deserves the first person. It is I who has this thought, and I offer this thought to the scientific community as a basis for discourse.

A word on opinions. An opinion can be defined as a statement rooted in a personal believe or perceptions that is neither supported by evidence, nor cannot be tested. All I write on this Wiki is clearly supported by evidence, and can be indeed tested and thus be confirmed or rejected. It is up to the readers to do this, but all written here is not about my opinions. People have confused this in this past, hence it seems reasonable to clarify this. 

'''To summarise, this wiki will use three different perspectives in terms of statements.''' The widest most general agreement includes knowledge that is accepted by the majority of scientists - written in the third person. The second category is knowledge by a scientific sub community - ""we"". The third - innermost - category is knowledge that is proclaimed by me as a curator of this Wiki, on this Wiki, marked by ""I"". All three categories are normative, since the knowledge within all three categories may change.";done
The Academic System;"Academia is equally an opportunity and a challenge, and many times we cannot even say which is which. Some of its elements date back into the ages, and on the other end is academia defined by creating knowledge that evolves, pushing our insights and the way we act based upon them forward, ideally radically changing the world for the better. Academia originated in a resource surplus of early societies, which could suddenly afford to have citizens that concentrated on nothing but knowledge with all its facets. Over time, academia became subsequently more focussed, and scientific disciplines emerged out of schools of thinking. Today, there is a dendritic network of disciplines that divides into ever smaller units with strong identities, which are often defined by their focal topics, underlying concepts and theories, and the associated canon of specific methods. Finding your roles and more importantly your vector of strategies and reflection points in the modern academia is a key challenge that serves as an initial building block of your career. Whole books are available on how to make it in academia, yet such approaches are somewhat beyond the point. If there was a recipe that everybody can follow, then we would reproduce the same academics all over. Academia is defined by evolvement and diversity, or at least it should be. Scientific disciplines often counteract this baseline. Out of the enlightenment and the industrial age, scientific disciplines were initially designed to produce workers of the mind that would administer economic development and colonial abuse. In the 20th century, knowledge became more and more compartmentalised, and ever finer layers of disciplines developed. To this date, the system is strongly competitive and resembles mostly a social Darwinist funnel. While all countries to this day build on a hierarchical system where professors are the highest caste, this system has lately been drastically changed in many countries. Germany is at the forefront of a movement where you have an overall higher number of full professors, but in comparison less assistant professors and lecturers. While in the past much of the teaching was long-term shouldered by these mid-level academia workers, most of these increasingly vanished today, and much of the remaining positions are limited to a maximum of six years. This limited time frame is often one of the main breaking points in modern academia. You have 6 years for your PhD, and 6 years as a postdoc. If you do not have a permanent contract after 12 years, you are legally out. Other countries have comparable mechanisms, and after such a long time it is anyway clear for most people if you can make it, or not. There is however still a larger convolute of lecturer positions in Scandinavian and English-speaking countries. However, even these positions are now characterised by an expectation that often goes beyond excellence in teaching and includes usually a research impact and the deep commitment towards management tasks and development of the institution. Yet way before the question how to gain a permanent position, other puzzles cross your way: different hierarchies, institutional constructs, tacit barriers and simply too many unknowns to find your way into the system. There are mainly two ways that can help prospering young academics to find their way into a successful career: A solid peer-network and one or few mentors. Without a mentor, life in academia and more importantly life into academia is almost impossible. May it be the medieval apprenticeship in the style of ""The Sword in the Stone"", shall it be the Kung Fu disciple just as in the ""36th chamber of the Shaolin"", or may it be ""Mulan"". Having someone see the raw germ and unleashing its full potential is a collaborative act of learning, and current professors can thus become one of the best bets that future professors will be better. One of my first mentors did actually always say that he only accepts disciples that are better than he is. A mentor ideally helps a learner to deal with all the challenges you face in the system, and does not only explain all cliffs, but also the path how to let them pass. Finding a mentor is like finding any other social relationship, just maximise your serendipity space, and then it may play out in your favour. Beside the knowledge may the serendipity space of your mentor also translate into a larger space of opportunities for yourself. What is most important for any mentorship is that it actually works both ways at the same time, since good students question aspects of the professors, and push the system to evolve, and also ideally turn the teacher into a learner, which is vital. Professors may have more experience, but the innovative drive often happens on the lower ranks, and certainly much of the wider workload. What is almost more important is a peer network, because this is your emotional safety net and lifeline. Joined suffering creates strong bonds, and many of the strongest bonds were formed over a solid network of early career peers suffering together and helping each other out. Such a network can also grow over time, and link into existing networks and create beneficial connections that help you get your career going. More often than not it is not so much about knowing people, it is more about knowing information. Thus, beside the emotional coping is a network a living body of knowledge that helps you to overcome obstacles. The most important information is often that your struggle is not unique, but indeed many people face similar issues. A peer network is also relevant for one main movement: If a lot of lower ranks talk about the same stuff, it actually translates up, and professors will become more interested in what gets the young folks around.

=== Discrimination and Bias ===";done
The Dos and Don'ts of meetings;"{|class=""wikitable"" style=""text-align: center; width: 100%""
! colspan = ""4"" | Type !! colspan = ""4"" | Team Size
|-
| '''[[:Category:Collaborative Tools|Collaborative Tools]]''' || [[:Category:Software|Software]] || [[:Category:Personal Skills|Personal Skills]] || '''[[:Category:Productivity Tools|Productivity Tools]]''' || [[:Category:Team Size 1|1]] || '''[[:Category:Team Size 2-10|2-10]]''' || '''[[:Category:Team Size 11-30|11-30]]''' || [[:Category:Team Size 30+|30+]]
|}

'''We drown in meetings.''' When the end of humanity comes, it will probably happen in a meeting. We humans are creatures that thrive through communication and collaboration, and meeting can - at least in theory - be prime places to identify goals, clear obstacles, and energise a team towards a joint goal. Instead, however, many of us cement ourselves into an endless track of useless meetings that are dull, aimless and numbing. Here, I will outline my perception why it came to this, and propose my attempts how to make it out of this conundrum.

== 10 reasons why our meetings fail ==
'''1) Meetings without an agenda or established norms.''' Meetings should either have a clear agenda or follow an established norm. Ideally, the agenda is either sent around before, or there is a central repository that contains the items to be discussed. Ideally, an agenda needs to be shared early enough to allow for a proper preparation. Within my role as a dean we established as a team a central document where everybody can add agenda items. This is to me really helpful as it is both empowering and also helps participants to prepare themselves for the meeting. More often than not, items can already be cleared beforehand, and an agenda helps structure a meeting. Fist, the group focuses on items that are relevant for everybody, and then make a smaller circle focusing on a subset of items. In an ideal world, each item should be solved in the end, and it should be clear from the beginning to everybody how this will be achieved.

'''2) Unprepared Meetings.''' Unprepared meetings are not only due to a lack of an agenda, but also because participants did not clarify their role and manage their own expectations. If I decide to join a meeting I would ideally want to either trust the person leading the meeting, or alternatively prepare my own agenda. The latter is a strategy with which I actually made some good experience in the past. Writing your own agenda if an actual agenda is missing is a good move to ultimately turn a dull meeting into something that at least contributes to your own goals or to the parts of the institution you represent. I have great admiration for some specific colleagues who prepare diligently for meetings, which can make even the most minor or junior role a raving success.

'''3) Wrong composition of people.''' Any given meeting will gain its dynamics out of the composition of participants. To me, the composition of team members in a meeting is so relevant since group identity is built over time. Resilience is built out of diversity, and it is quite important to enable people to have their say in a given meeting. Though some people are missing at some times - or may have colliding obligations - I came to the conclusion that in the long run, those people participating in meetings are the ones who build and propel the team spirit further.

'''4) Lack of facilitation.''' Facilitation can be defined as a designed support structure by one or several people to foster constructive integration within a specific setting. Facilitation is currently somewhat of a holy grail in academia and beyond, and rightly so, as we were widely missing out on this dimension beforehand. Facilitation done right can be a form of art, and facilitation can be prove that a path can surely be more important than the actual goals. One could write a whole book on all aspects of facilitation, yet since it is experience based, the most important advice is to encourage people to try it out for themselves. While some are clearly naturals, other may struggle. Still, gathering this initial experience can help everybody understand the struggles and challenges of the role of a facilitator.

'''6) Lack of balance.''' Lack of balance can manifest in many ways within meetings. Often, one or few people totally dominate a meeting. This can be ok if the goals are still achieved, and other participants do not feel disempowered. In my experience, it can however be quite a negative experience if a substantial amount of talking time is monopolised by one person. While this can be an indicator of some underlying problems in the team, it makes the meeting often a frustrating experience. Like commitment and facilitation, this is something where you need to build an identity as a group and openly reflect upon such a disbalance with the respective person afterwards. Another disbalance can be created if one agenda item dominates the meeting, which is often in coherence with one person dominating the scene. To this end, it is most important to highlight when you are not gaining some ground on the respective item, or you start going in circles. While this is a matter of experience and diplomacy, in my perception it is often these situations where you end to step in and suggest to have another - maybe smaller - meeting later to focus on the respective issue. Time in a meeting is shared time, and this should take the interests of all people present into account.";done
The future of statistics?;"===Parsimonious models===
In statistics, today, there is a tendency to use more [[Agency, Complexity and Emergence|complex]] models as a sells pitch, as well as too simple models due to lack of experience. In the long run however, knowledge and experience may spread, and people may use the most appropriate models. '''I think a starting point for this will be pursuing different models at the same time, not in an ensemble way where the model results are put together and averaged, but in a reflexive way.''' Imagine I see a weather development that may have ramifications for the nomads in an area, being a foreshadow of a drought that may affect their livestock. I could not use [[Regression Analysis|simple linear models]], which would not help me to grapple such an extreme event, but would allow me to see some long-term trend statistics and get some explanation of what might happen in terms of the big picture. Then I might focus with a finer grain on the actual weather data right now, comparing climate and weather in a nested way, using non-linear statistics to focus on the actual prediction. Next, I could ask myself what happens if I take a fresh look, using a Bayesian approach to allow myself to only grapple the current data with real time updates. All these models unravel different aspects of the same phenomena, yet today -more often than not - statistics decide for one way of analysis, or combine all ways (e.g. ensemble models) as an average. Yet I propose that much knowledge is like an onion, and [[Statistics and mixed methods|different statistical models]] can help us to peel of the different layers.

===Examine plausible questions===
Much of the knowledge that science produces is driven by scientific demand, and this can be a good thing. However, our growth-driven economy shows the catastrophic shortcoming of a line of thinking that focuses on one aspect of knowledge, all the while actively rejecting or denying other parts of knowledge or reality. '''Empirical knowledge depends on the questions we ask.''' A manager of an organisation that attempts to maximise their profits may or may not ask the right questions for their goal, as focussing on growth may be the main reason for the organisation's demise or prosperity in the future. To the manager, focusing on growth seems plausible, so they pursue it. If it is reasonable, they might misjudge. Plausibility is closely linked by definition with people being reasonable, and plausible questions have some probability of being worthwhile our investigation. Following Larry Laudan, however, it is clear that scientists of the past were not always reasonable. Larry Laudan thought that many events and discoveries in the history of science were not as rational or reasonable as we think these scientific discoveries were. Future changes such as a more tightly-knit exchange culture in science or more pronounced ethical checks of research proposals may foster more plausible research questions, but this may not the right way to more plausible research questions. Instead, society may shift in the future, and people may just not come to the conclusion to investigate questions that are implausible. This may sound like a very distant future, but if we compare us today to people or even researchers 100 years ago or even 500 year ago, it become clear that we already came a long way, and shall go on.

===Integrate more & diverse data===
Statistics was born out of the urge to understand and control system dynamics, partly with a purely non-materialistic focus such as in Astronomy - a motor of early statistics - or with a total focus on materialistic gain, as was the case in early econometrics. With the rise of the Internet, our inflict of data increased at an exponential pace - following Moore's law - triggering both positive but also devastating effect on the global dynamics we witness today. '''Access to information has become on of the most important privilege people have today, and much has been gained, but much was also lost in translation.''' Examples such as information spreading from activists showcase what can be gained, yet terrorists and insurgents are coordinating themselves equally in the digital age. Data security is stronger shifting into the focus of societal debate, but we are far away from real data security, and in many aspects seemingly only a step away from a Black Mirror episode. All the while is is clear that we have no idea of which [[To Rule And To Measure|types of data]] may be available in the future. Movement patterns of elderly risk patients can predict a risk of a heart attack weeks before it would actually happen. Research can trigger a tilt towards fairer income distribution, or support the notion of a universal basic income. Detection systems of weather, oceans and the upper crust of Earth may prevent countless losses of life in in case of disasters. However, all these examples are still connected to our reality today, and we have to assume that future people will utilise data in ways that will be hard to imagine for us today.";done
The great statistics recap;"'''Annotation:''' This entry concludes the Introductory class on statistics for Bachelor students at Leuphana. It is not an autonomous entry on its own.

==The great recap==
Within this module, we focused on learning simple statistics. '''Understanding basic [[Descriptive statistics|descriptive statistics]] allows us to calculate averages, sums and many other measures that help us grasp the essentials about certain data.''' [[Data formats]] are essential in order to understand the diverse forms that data can take. We learned that all data is constructed, which becomes most apparent when looking at [[To Rule And To Measure|indicators]] which can tell some story, yet without deeper knowledge about the construction - i.e., the context of an indicator - it is hard to grasp. 

Once you get a hold of the diverse data formats, you can see then how data can represent different [[Data distribution|distributions]]. While much quantitative data is normally distributed, there are also exceptions, such as discrete data of phenomena that can be counted that is often showing a skewed distribution. Within frequentists statistics, statistical distributions are key, because these allow form a statistical standpoint to [[Experiments and Hypothesis Testing|test hypotheses]]. '''You assume that data follows a certain distribution, and that is often one important preconditions for the test or model you want to conduct.''' Whether your data then shows non-random patterns, but whether a hypothesis can actually be accepted or rejected, depends actually more often than not on the p-value. This value is the calculation whether your results are random and follow mere chance, of whether there is a significant pattern that you tested for. This is at its core what frequentist statistics are all about. 

The most [[Simple Statistical Tests|simple tests]] can test for counts of groups within two variables (chi-square test), comparisons of two distributions (f-test) and the comparison of the mean values of two samples of a variables (t-test). Other tests avoid the question of statistical distribution by breaking the data into ranks, which are however less often applied (Wilcoxon test). '''A breakthrough in statistics was the development of the [[Correlations|correlation]], which allows to test whether two continuous datasets are meaningfully related.''' If one of the variables increases, the other variable increases as well, which would be a positive correlation. If one variable increases, and the other one decreases, we speak of a negative correlation. The strength of this relation is summarised by the correlation coefficient, which ranges from -1 to 1, and a values furthest from 0 indicates a strong relation, while 0 basically indicates complete randomness in the relation. This is tested again by p-values, where once more a values smaller than 0.05 indicates a non-random relation, which in statistics is called a significant relation. 

While correlation opened Pandoras box of statistics, it also raised a great confusion concerning the question whether a relation is [[Causality and correlation|causal]] or not. There are clear criteria that indicate causality, such as similarity in features of phenomena that have the same effect onto a variable. '''In order to statistically test for causal relations, [[Regression Analysis|regressions]] were developed.''' Regressions check for relations between variables, but revolve around a logical connection between these variables to allow for causal inferences. In addition, they allow to test not only the relation of one continuous variable in relation to another dependent variable. Instead, several independent variables can be tested, thus allowing to build more complex models and test more advanced hypotheses. Again, the relation is indicated to be significant by the p-value. However, the strength of the model is not measured in a coefficient, but instead in the r-square value, which is the sum of squares of the individual data points distance from the regression line. A regression line is hence the line that represents the regression model, which best explains the relation between the dependent and independent variable(s). 

While regressions were originally designed to test for clear hypotheses, these models are today utilised under diverse contexts, even in [[:Category:Inductive|inductive]] research, thereby creating tensions when it comes to the interpretation of the model results. A significant regression does not necessarily indicate a causal relation. This is a matter of the [[Normativity of Methods|normativity]] of the respective branch within science, and ultimately, also a question of philosophy of science. This is comparable to the [[ANOVA|analysis of variance]] (ANOVA), which unleashed the potential to conduct [[experiments]], starting in agricultural research, yet quickly finding its way into psychology, biology, medicine and many other areas in science. '''The ANOVA allows to compare several groups in terms of their mean values, and even to test for interaction between different independent variables.''' The strength of the model can be approximated by the amount of explained variance, and the p-value indicates whether the different groups within the independent variables differ overall. One can however also test whether one groups differs from another groups, thus comparing all groups individually by means of a posthoc test (e.g. Tukey).

When designing an ANOVA study, great care needs to be taken to have sufficient samples to allow for a critical interpretation of the results. Subsequently, ANOVA experiments became more complex, combining several independent variables and also allowing to correct for so called random factors, which are elements for which the variance is calculated out of the ANOVA model. This allows for instance to increase the sample size to minimise the effects of the variance in an agricultural experiment which is being conducted on several agricultural fields. In this example, agricultural fields are then included as block factor, which allows to minimise the variance inferred by these replications. Hence, the variance of the agricultural fields is tamed by a higher number of replicates. This led to the ANOVA becoming one of the most relevant methods in statistics, yet recent developments such as the reproducibility crisis in psychology highlight that care needs to be taken to not overplay ones hand. Preregistering hypotheses and more recognition of the [[Limitations of Statistics|limitations]] of such designs currently pave a path towards a more critical future of statistical designs. ";done
The tao of R-coding;"'''In short:''' This entry provides guidance on R coding in general.

== Pretext ==
I learned from many, and many learned from me. Much of my alumni will question details that I write here, as they have different views on coding. I think this is a good thing. After all, you have to find your own meaning for the tao of R-coding. 

'''Learning to write code in R takes a long time'''. This text will not take this time away from you, but it may help you to find some shortcuts here and there, through which hopefully you may learn faster afterwards. I made many mistakes in my time, and I hope that this will go on, since otherwise there is nothing left to learn. Still, I am glad to say that I can recognise a difference between knowledge and experience, and this key difference is the main insight one can get into mastery. I believe, that once you felt bored out by an R-coding problem, this is the closest one can get to wisdom. Let us begin.

== You in your surrounding ==
First, the setting. Perfecting patience in R-coding demands the right surrounding. Some people cannot code everywhere, others can code everywhere. I think this is actually inaccurate; the latter are simply better in adapting, and would do their prime work in a well defined setting as well, but this is just my own experience. I thought I am very adaptive, but learned that I benefit from a defined setting as well.  

==== Place ====
You need to code regularly, and a lot. Hence it is good to design a space where you can sit easily for hours to an end, and focus on your coding. You do not need the best laptop, but ideally one that is a tool that you feel comfortably with. There is the old Mac vs. a PC rant, and I guess this will never be solved. However, it is good if you can afford a computer that works well for you. Some people use a mouse and a keyboard, which can be beneficial. However, I advice you to use as few mouse clicks as possible. Try to rely on keyboard shortcuts instead, which are the easiest bits of code that you should learn first. Switching between windows, copy & paste, tab setting and shortcuts are the rudimentaries you need to master. In my experience, a second screen can get you a long way. For students, a Padlet can be a welcome extension of the screen, as it allows for more mobility. Many people can code everywhere, and this is an advantage. Therefore, it is so important to get a Laptop, and to have a a good backpack to allow for mobility and relocation. 

==== Time ====
''“There is something to be learned from a rainstorm. When meeting with a sudden shower, you try not to get wet and run quickly along the road. But doing such things as passing under the eaves of houses, you still get wet. When you are resolved from the beginning, you will not be perplexed, though you will still get the same soaking. This understanding extends to everything.”'' - Hagakure

'''You need to code as much as you can.''' Still, some time spots seem to work better for some than other time spots. Find your sweet spot, and more importantly, practice! Coding should be a reward you look forward you, which interludes the other duties and activities of the day. Still, it needs to be a pronounced focus if you are really planning to get good at it. I have the experience that sometimes a short break can get you really further. In addition, planning your code beforehand in a rough form is really helpful. I feel that to this end, coding is just like any other form of writing. To conclude, find the best mode how to excercise, since only daily practice can allow you to evolve. Lean back, and start coding.

==== The hardware ====
When you learn programming, there is a high likelihood that you stay in one place for at least some years. If your budget permits, how about making a sedentary commitment: A second screen can make a real difference when programming, and using a screen as a main device and the laptop screen as a secondary screen can also be more comfortable on your eves and neck, as the position of the screen can be more upward. Some people are also faster on a keyboard, and it can be adjusted to different typing poses. Lastly, while you should minimise the use of a mouse or touchpad by all means, I prefer a touchpad, mostly because it is more agile in Finalcut. Overall, I think the specs of the computer matter less than people think they do. In my experience, you either do not wait at all for a calculation, or you wait very very long - if not too long - anyway. In this case, you anyway need to find an alternative server to calculate your stuff. In R, this hardly ever happens, at least while learning to code. '''If something calculates really long, in most cases you made a mistake.''' Only large data or endless loops can stall the average calculations. Bayesian stuff may pose a problem, and larger data. Hence try to avoid the latter, and brace for the Bayesian coffee break. ";done
The tao of R-coding;"==== The scripts of the ancients ====
The more you know about the knowledge of the old, the more you will be able to derive from your data. While it is true that no methods can solve everything, all methods can solve more than nothing. Being experienced in scientific methods is of utter importance to get the best initial understanding of any given dataset. Statistics stand out to this end, as they are the basis of most approaches related to numbers. However, one has to recognise that there is an almost uncountable amount of statistical approaches. Start with the most important ones, as they will help you to cover most of the way. '''Take correlations'''. I think it can be done to understand the simple correlation within a few hours, maybe days. You will get the general mechanics, the formula, the deeper mathematics behind it. You can even square this with the textbook preconditions, the interpretation, maybe even the limitations. You are all set. However this will help you as much as practicing a punch alone and without an experienced teacher when you suddenly find yourself in a real fight. You may be able to throw the punch the way you practised it, but your opponent will not stand in the spot you practised to hit. Reality is messy, you need to be agile and adaptive. R coding is like kung fu, you need a lot of practice, but you also need to get into peer-to-peer practice, and you need an experienced teacher, and learn from the Ancient Ones. Just as every attack of an opponent is different, every dataset is different. However when you are versatile, you can find you goal no matter what. As the Hagakure says: ''""Taking an enemy on the battlefield is like a hawk taking a bird. Even though one enters into the midst of thousands of them, it gives no attention to any bird other than the one it has first marked.""'' Finding patterns in data is exactly like this. Once you become experienced and versatile, this is how you will find patterns in data. 

There is also much new knowledge that is evolving, as data science is a thriving arena. Being versatile in the basics is one thing, but a true master in data science needs to equally rely on the ancients as well as the revolutionary renegades. They all offer knowledge, and we should perceive their knowledge and experience as pure gold that is potentially true. Some methods are established, and it is a good thing to know these. Other methods are evolving, and it is equally good to know the latest tricks and developments. Much [[Glossary|creativity]] however comes from also combining the old and the new schools of thinking. Innovation within scientific methods is often rooted in the combination of different scientific methods. These unlock different types of knowledge, and this can be seen as often appropriate to acknowledge the complexity within many datasets. Combination of approaches is the path to new knowledge, and new knowledge is what we need these days quite often, since the old knowledge has not solved the problems we face, and new problems are emerging. When you want to approximate solutions to these problems, you have to be like water.

==== Non-duality in R-coding ====
Non-duality in data science relates to the difference between predictive power and explanatory power. Any given dataset can be seen from these two perspectives, and equally from none of these perspectives. This is what non-duality of data science is all about. You need to learn to see both in data, and also none. Predictive power and explanatory power are one and the same, and they are not. As the ancients said, it is bad if one thing becomes two. The same is true for data analysis. Many guide their analysis through predictive power, and they become obsessed by the desire to have what they call ""the best model"". Thoughts on the goodness of fit circulate in their heads like wild dragons, and they never manage to see anything but the best model they can possibly achieve, and hence they fail. Many compromises have been made by people to find the best model, and sadly, the best model may never be found. As the Ancient Ones said: '''all models are wrong, some models are useful'''. One should never forget this. 

Equally, there are people who obsess about the explanatory power of models. They see the promise of causality in the smallest [[Glossary|patterns]] they find, and never stop iterating about how ''it all makes sense now''. Much has been explained in the past, but much may remain a mystery. Much that once was causal is lost, for no papers are available to remember it. The knowledge of people evolves, and with it the theories that our causality is often built upon. The predictive and the explanatory people even go to war against one another claiming victory after victory and their fight about superiority. However, many souls were lost in these endless quests, and to me it remains unclear if any real victory was ever won in this eternal iteration on whether patterns are causal or predictive. Both approaches can make sense, and the clever ones never went down the paths of priority, and avoided claiming what is better. They simply claimed their worldview, and were fine. They lived in their world of the two realms, and ignored the other realm completely. Many thus lived a happy life, half ignorant, but happy. These people are like the Ancient Ones living in their kingdom of old, with scientific disciplines and textbook knowledge, where kingdoms fought other kingdoms at times, but there was also peace and prosperity. ";done
Thought Experiments;"[[File:Thought Experiment Concept Visualisation.png|450px|frameless|left|[[Sustainability Methods:About|Method categorization]] for [[Thought Experiments]]]]

<br/>
{|class=""wikitable"" style=""text-align: center; width: 50%""
! colspan = 3 | Method categorization
|-
| [[:Category:Quantitative|Quantitative]] || colspan=""2"" | '''[[:Category:Qualitative|Qualitative]]'''
|-
| [[:Category:Inductive|Inductive]] || colspan=""2""| '''[[:Category:Deductive|Deductive]]'''
|-
| style=""width: 33%""| '''[[:Category:Individual|Individual]]''' || style=""width: 33%""| '''[[:Category:System|System]]''' || '''[[:Category:Global|Global]]'''
|-
| style=""width: 33%""| '''[[:Category:Past|Past]]''' || style=""width: 33%""| '''[[:Category:Present|Present]]''' || '''[[:Category:Future|Future]]'''
|}
<br/>__NOTOC__
<br/><br/>
'''In short:''' Thought Experiments are systematic speculations that allow to explore modifications, manipulations or completly new states of the world.

== Background ==
[[File:Scopus hits Thought Experiment.png|450px|thumb|right|'''SCOPUS hits per year for Thought Experiments until 2019.''' Search term: 'thought experiment' in Title, Abstract, Keywords. Source: own.]]

'''The Thought Experiment may well be the oldest scientific method.''' The consideration of potential futures was a vital step when our distant ancestors emancipated themselves and became humans. Asking themselves the ''What if'' questions was a vital step in the dawn of humankind, and both in the West and the East many of the first thinkers are known to have engaged in Thought Experiments. Methodologically, Thought Experiments provide a link between the metaphysical - or philosophy - and the natural world - i.e. natural sciences. Ancient Greece as well as Buddhism and Hinduism are full of early examples of Thought Experiments. Aristoteles remains a first vital step in the West, and after a long but slow growth of the importance of the methods, he represents a bridge into the early [[History of Methods|enlightenment]]. Galileo and Newton are early examples of famous Thought Experiments that connect theoretical considerations with a systematic reflection of the natural world. This generation of more generalisable laws was more transgressed with the ''Origin of Species'' by Charles Darwin. This theory was initially one epic Thought Experiment, and although DNA initially confirmed it, the role of epigenetics was another step that proved rather problematic for Darwinism. Mach introduced the term ""Thought Experiment"", and Lichtenberg created a more systematic exploration of thought experiments. Many ethical Thought Experiments gained province in the 20st century, and Derek Parfit is a prominent example how these experiments are used to illustrate and argument cases and examples within ethics.

== What the method does ==
Thought Experiments are the philosophical method that asks the ""What if"" questions in a systematic sense. Thought Experiments are typically designed in a way that should question our assumptions about the world. They are thus typically deeply normative, and can be transformative. Thought Experiments can unleash transformation knowledge in people since such experiments question the status quo of our understanding of the world. The word ""experiment"" is insofar slightly misleading, as the outcome of Thought Experiments is typically open. In other words, there is no right or wrong answer, but instead, the experiments are a form of open discourse. While thus some Thought Experiments may be designed to imply a presumpted answer, many famous Thought Experiments are completely open, and potential answers reflect the underlying norms and moral constructs of people. Hence Thought Experiments are not only normative in their design, but especially in terms of the possible answers of results.  

The easiest way to set up a Thought Experiment is to ask yourself a ""What if"" question. Many Thought Experiments resolve around decisions, choices or potential states of the future. A famous example is the Trolley experiment, where a train rolls towards five train track workers, who would all be killed be the oncoming train, unaware of their potential demise. You can now change the direction of the train, and lead it to another track. There, one worker would be killed. Uncountable numbers of variations of this experiment exist (see Further Information), as it can teach much about choice, ethics, and responsibility. For instance, many people would change the train direction, but hardly anyone would push a person onto the track to derail the train. This would save the other five, and the outcome would be the same. However the difference between pushing a lever or pushing a person has deep psychological ramifications that resolve around guilt. This exemplifies that the Thought Experiment does not necessarily have a ''best'' outcome, as the outcome depends - in this example - on your moral choices. Some might argue that you should hurl yourself onto the track to stop the train, thereby not changing the countable outcome, but performing a deeply altruistic act that saves everybody else. Most people would probably be unable to do this. 

'''Such deeply normative Thought Experiments differ from Thought Experiments that resolve around the natural world.''' Dropping a feather and a stone from a high building is such an example, as this experiment is clearly not normative. We are all aware that the air would prevent the feather to fall as fast as the stone. What if we take the air now out of the experiment, and let both fall in a vacuum. Such a Thought Experiment is prominent in physics and exemplifies the great flexibility of this method. Schrödinger's Cat was another example of the Thought Experiment, where quantum states and uncertainty are illustrated by a cat that is either dead or not, which depends on the decay of some radioactive element. Since radioactive decay rates are not continuous, but represent a sudden change, the cat could be dead or not. The cat is dead and not dead at the same time. Many argue that this is a paradox, and I would follow this assumption with the supporting argument that we basically look at two realities at the same time. This exemplifies again that our interpretation of this Thought Experiment can also be normative, since a definitive proof of my interpretation is very difficult. This is insofar relevant, as seemingly all Thought Experiments are still based on subjective realisations and inferences. 

[[File:Schrödingers Cat.png|400px|thumb|left|'''Schrödinger's Cat.''' Source: [https://ad4group.com/schrodingers-cat-and-the-marketing-strategy/ AD4Group].]]";done
Time;"'''In short:''' This entry revolves around the history of Time as a concept, and its implications for scientific inquiry. Please refer to the [[Design Criteria of Methods]] entry for a general overview on all design criteria.

Time is one of the greatest misconceptions in terms of methods (and humans in general), and together with space (or spatial scale, or grain) poses one of the key challenges in methodological aspects of science. Here, we give a short introduction to the different aspects of time from a methodological standpoint. Starting with the most relevant general aspects of time, the text will then focus on concrete methodological aspects of time. An outlook on the necessary next steps concerning time in scientific methods concludes the text.

== A historical view on time ==
'''We humans are known to be a mere glitch in the long cosmic developments that lay already behind us.''' Much time has already passed, probably billions of years, and we as humankind have only been here for a few thousand or a few hundred thousand years, depending on how you define us. Yet within this comparably short or even negligible period, we have become an entity that - according to Derek Parfit - starts to understand the universe. In the long run, this may be our most remarkable achievement, and we already understood as much as that we will probably not be there forever. This has led to many debates about the reasons for our being, and our role in the universe, and these debates will likely not end anytime soon. There exist diverse flavours to make sense of our presence, and while I invite everyone to participate in this great abyss of a debate, I am sure that it will be difficult to come up with a conclusion that we all share. Following Derek Parfit, we may agree that our future could be much better than our past, and it would be worthwhile in this spirit to go on, and to contribute to a future of humankind that could be so much better than pur past. Nihilism, existentialism and many other -isms are telling us to not buy into this optimistic rhetoric, yet personally, I would disagree. 

Thus, let us focus on the main obstacle to this bright future that we have faced ever since we began: ''Temporal autocorrelation.'' This principle defines that we humans value everything that occurs in the close past or future to be more relevant than occurrences in the distant future or past. This is even independent of the likelihood whether future events will actually happen. As an example, imagine that you want to have a new computer every few years, and you can pay 5€ to have a 50% chance to get a new computer tomorrow. If you actually needed one, you would surely do that. However, even adjusted for inflation, many people would not pay the same 5€ to have a 50 % chance to win the latest computer in 10 years. What difference does it make? It is the latest tech in any case. '''Temporal discounting is one of the main ways how people act unreasonably'''. This even extends well beyond the point where we are dead already, although this also plays a role. Our unreasonable inabilities to transcend temporal discounting extend likewise into the past. The strongest argument to this end is how many people insist that they are worse off today when compared to the past - in the 'good old days'. The mistake that is typically made is that some aspects in the past were better, while many other aspects were worse. People hence have a tendency to value the time period closer to them different from the time periods more distant. For the past, only the good things are remembered, and for the present, the negative sides are also acknowledged. It widely depends on other circumstances whether this unreasonable evaluation is better or worse than a more objective view on each time period. In any case, the sheer difference between how people evaluate distant time periods or events compared to closer ones is one indirect motivation for science to put this knowledge into perspective.


== Understanding the past ==
Historical research as well as other branches of science that investigate data or information from the past allow us to put our current knowledge, context and situation into the context of past periods or events. This is widely driven by the historical sources that are at our disposal. Palaenonthology, which is the science that deals with the oldest records, is a good example how single artefacts and findings can be embedded into a [[:Category:Quantitative|quantitative]] timeline via carbon dating. Be measuring the decay of radionucleids in the objects, it is today possible to get a rather good tracking of the age of fossils. However, before the establishment of this hard scientific method, palaeontologists and geologists relied widely on the context of the sediments in which the fragments were found. The sedimental history hence become an early dating method, and many other indicators such as thin layers of global catastrophes through meteors allow to pinpoint the temporal origins with an often high precision. One prominent example is the layer at the Cratecous-Tertiary line, when an Earth-shattering meteor not only extinguished the dinosaurs, but also created a thin sedimental layer that allows to date this event in time with often remarkable precision. Other important methods in dating distant developments can be hidden in the molecules and systematics of many organisms, since sophisticated DNA analysis often allow to generate a holistic developmental history of organisms if suitable material for DNA analysis is found. To this end, preserved record in moorlands is often a source of material dating back 10 thousands of years, creating a database of the development of life itself.";done
Time;"With the rise of photography an altogether different kind of record was created, and the development of modern cartography had an equally dramatic influence on the density of knowledge that became available. The detailed scientific examination of the diverse sources since the development of the printing press by Johannes Gutenberg was already a a severe development leading to an exponential growth of the printed word. The development of printed images and multiplication of pictures that came later was an altogether different media unleashed, leading to a totally different world. Once these image started moving and even talking, human civilisation created an exponentially growing record of the world, of which the Internet is the latest development. '''From a methodological standpoint, this diversity of media triggered two relevant developments:''' An ever-increasing differentiation of empirical analyiss, and severe philosophical consequences of this brave new world. The role of art and its critique changed fundamentally, with consequences that translate directly into modern society. It is impossible to do justice to these developments here, yet Walter Benjamin should be noted as an early stepping stone towards a clearer role of the critique within society. This triggered direct and long overdue consequences for the scientific method as well, and led to a redevelopment of the role of the critical observer, commentator and ultimately unleashed a more nuanced view on science and its consequences. Methodologically, [[deconstruction]] as well as the critical perspective emerged over the last decades, all the while the possibilities of modern sciences [[History of Methods|diversified]] as well. The exponential track of the 20th century triggered a diversity in scientific approaches that dwarves by far the scale of everything that existed before. Along the way, our understanding of the distant past has become a question of the preservation of the immense emerging record. The amount of information that is being created and stored on the Internet is increasing at a pace that would have been unthinkable before, leaving us to at least try to spare some thoughts about the role this information may play in the future. Will everything be preserved for longer times? What is the turnover of our data? And what will be the meaning of the information we create for future people?


== Understanding the future ==
Derek Parfit concluded that our future may be wonderful, and that we cannot make the ethical decision whether future people should exist at all. In other words, we have no moral grounds to end human history. The fact that humans can think about the future is one of the most defining elements about our species. Compare us to the chipmunk. The chipmunk may store nuts, and forget about most of these. Birds migrate in anticipation of the seasons changing. Whales may follow their food. '''It is probably only us who have a abstract understanding about different futures, and can adapt our actions based on this knowledge.''' To do so, the scientific examination of our futures became more and more systematic over the last centuries and especially decades. We know that the earliest cultures cared about their future - the artefacts found in graves showcase the complex world our ancestors anticipated in the afterlife. Some of the earliest texts offer a testimony of what might happen in the future, often as a motivation or a basis for moral authority for the living. Moses' interpretation of the dreams of the Pharao showcases how the anticipation of a possible future and its shortcoming was central to the ancient culture. 

While the oracles and mysticisms of the ancients were often complicated yet not systematical in their methodological approaches, this changed with modern agriculture. Human civilisation got domesticated by its crops, and depended on their harvest. The demise of the Maya may be an early testimony of crop failures, and especially in Asia and Europe, records of the central role of the harvest within the seasonal calendar have been preserved for centuries. The ripening of the wine harvest is a record often known since several centuries, and deviances from the known averages often led to catastrophic famine and migrations. To prevent such catastrophes, societies began to index and plan their agricultural practice into the future, and the rise of numbers - with examples from basically all early cultures - testify how this allowed for the thriving of many diverse cultures.

However, also more [[:Category:Qualitative|qualitative]] and vivid approaches to the future emerged in the literature and the other arts, among them More's Utopia as an early testimony on how he imagined a radically different society already in 1516. Sadly, Christopher Columbus in his anticipation of a new path to India via the East triggered a reality that was - and still is - so different from More's anticipation of the future. The human urge for discovery is what drove many people into the New World, often looking for a more hopeful future. The people that already lived in these regions of the world had no means to anticipate the grim futures most of them would face under these developments. Through the rising inequalities of colonialism and other deeply regrettable developments of the rise of Europe, a surplus in resources was extracted from the colonies, enabling an economic system that was built around a more systematic exploitation of the regions that would become the Global South. The urge to make a business became the backbone of the rise of utilitarianism and its associated economic paradigms, each willing to cash in on an anticipation of their future, typically on the costs of the future of other people. This showcases how the capability of an anticipation of the future, and being privileged with the means to act based on that, created an inequality that is basically still on the rise today. ";done
Time Series Data in Python;"THIS ARTICLE IS STILL IN EDITING MODE
==What is Time Series Data==
Time series data is a sequence of data points collected at regular intervals of time. It often occurs in fields like engineering, finance, or economics to analyze trends and patterns over time. Time series data is typically numeric data, for example, the stock price of a specific stock, sampled at an hourly interval, over a time frame of several months. It could also be sensory data from a fitness tracker, sampling the heart rate every 30 seconds, or a GPS track of the last run.
In this article, we will see examples from a household energy consumption dataset having data for longer than a year, obtained from [https://www.kaggle.com/datasets/jaganadhg/house-hold-energy-data Kaggle] (Download date: 20.12.2022). 

<syntaxhighlight lang=""Python"" line>
import numpy as np ## to prepare your data
import pandas as pd ## to prepare your data
import plotly.express as px ## to visualize your data
import os ## to set your working directory
</syntaxhighlight>

It is important to check which folder Python believes to be working in. If you have saved the dataset in another folder, you can either change the working directory or move the dataset. Make sure your dataset is in a location that is easy to find and does not have a long path since this can produce errors in setting the working directory. 
<syntaxhighlight lang=""Python"" line>
##Check current working directory
current_dir = os.getcwd()
print(current_dir)
## Change working directory if needed
os.chdir('/path/to/your/directory')
</syntaxhighlight>

<syntaxhighlight lang=""Python"" line>
df = pd.read_csv('D202.csv')
df.head()
</syntaxhighlight>
By looking at the first few rows we can see that the electric usage is documented every 15 minutes. This means that one day has 4*24 data points.
We can also see the different columns that provide further information about electricity consumption.
Next, let's choose the most relevant columns for our research:

<syntaxhighlight lang=""Python"" line>
## Let's choose the most relevant columns for our research:
df['start_date'] = pd.to_datetime(df['DATE'] + ' ' + df['START TIME'])
df['cost_dollars'] = df['COST'].apply(lambda x: float(x[1:]))
df.rename(columns={'USAGE': 'usage_kwh'}, inplace=True)
df = df.drop(columns=['TYPE', 'UNITS', 'DATE', 'START TIME', 'END TIME', 'NOTES', 'COST']).set_index('start_date')
</syntaxhighlight>
We select DATE and START time to create a dataframe called start_date. These two columns are transformed into a date and time format. 
We then create the dataframe “cost_dollars” by creating the dataframe based on the COST column and transform it to float data. 
The USAGE column is then renamed and we drop a number of columns that are not needed.

The dataset contains about 2 years of data, we will only have a look at the first 2 weeks. For this we use iloc. iloc is an indexing method (by Pandas) with which you can choose a slice of your dataset based on its numerical position. Note that it follows the logic of exclusive indexing, meaning that the end index provided is not included.
To select the slice we want we first specify the rows. In our case, we chose the rows from 0 (indicated by a blank space before the colon) to the 4*14*24th row. This is because we want the first fourteen days and one day is 4*24 data points. We want all columns which is why we don't specify anything after that. If we wanted to, we would have to separate the row indexes with a comma and provide indexes for the columns.
<syntaxhighlight lang=""Python"" line>
df = df.iloc[:24*4*14]
df.head()
</syntaxhighlight>

==Challenges with Time Series Data==
Often, time series data contains long-term trends, seasonality in the form of periodic variations, and a residual component. When dealing with time series data, it is important to take these factors into account. Depending on the domain and goal, trends, and seasonality might be of interest to yield important value, but sometimes, you want to get rid of the two, when most of the information is contained in the residual component.
The latter is the case in an analysis of a group project of mine from 2020. In that project, we try to classify the type of surface while cycling with a smartphone worn in the front pocket and need to remove the periodicity and long-term trend to analyze the finer details of the signal. The analysis can be found at [https://lg4ml.org/grounddetection/ here]. Unfortunately, it is only available in German.

==Dealing with Time Series Data==
===Visualizing Data===
The first step when dealing with time series data is to plot the data using line plots, scatter plots, or histograms. Line plots can visualize the time domain of the data, while scatter plots can be used to inspect the frequency domain obtained by a fast Fourier transformation. It would exceed the scope to explain the fast Fourier transformation, but it suffices to say that it can transform the data into different frequencies of electricity usage (x-axis) and how many times this frequency occurred (y-axis).

<syntaxhighlight lang=""Python"" line>
###Line Plot to visualize electricity usage over time
px.line(df, y='usage_kwh',
        title='Usage of Electricity over 2 Weeks',
        labels={'start_date': 'Date', 'usage_kwh': 'Usage (KWh)'}) ## uses the data from ""start_date"" called ""Date"", and the data of ""usage_kwh"" called ""usage (KwH)""
</syntaxhighlight>

[[File:Figure 1.png|700px|center|]]
<small>Figure 1: Line Plot visualizing electricity usage over time</small>

<syntaxhighlight lang=""Python"" line>
###Scatter plot to visualize the number of times certain frequencies occurred
from numpy.fft import rfft, rfftfreq ## imports the needed fast Fourier functions from the numpy package

transform = np.abs(rfft(df['usage_kwh'])) ## transforms into frequencies
frequencies = rfftfreq(df['usage_kwh'].size, d=15 * 60) ## fits the result into an array, d=15*60 determines that the time intervall is 15 minutes (15 * 60 seconds)

n = 100 ##plots the first 100 frequencies
px.line(x=frequencies[:n], y=transform[:n], markers=True,
           title='Magnitude of Frequencies',
           labels={'x': 'Frequency', 'y': 'Magnitude'}) ## creates plot with n=100 frequencies
</syntaxhighlight>

[[File:scatter plot.png|700px|center|]]
<small>Figure 2: Scatter plot visualizing the number of times a certain frequency of electricity usage occurred</small>";done
Tips for digital lectures;"{|class=""wikitable"" style=""text-align: center; width: 100%""
! colspan = ""4"" | Type !! colspan = ""4"" | Team Size
|-
| '''[[:Category:Collaborative Tools|Collaborative Tools]]''' || '''[[:Category:Software|Software]]''' || '''[[:Category:Personal Skills|Personal Skills]]''' || [[:Category:Productivity Tools|Productivity Tools]] || '''[[:Category:Team Size 1|1]]''' || '''[[:Category:Team Size 2-10|2-10]]''' || '''[[:Category:Team Size 11-30|11-30]]''' || '''[[:Category:Team Size 30+|30+]]'''
|}

== What, Why & When ==
Digital lectures have been common for years, but especially during the COVID-19 crisis, we saw the challenges - but also benefits - that came with presenting content and having seminars in online formats. This entry provides a list of tips for both teachers and students in online sessions.

== Goals ==
* Improve engagement in online teaching.
* Make more out of online sessions as a student.

== Getting Started ==
=== Tips for lecturers ===
==== Tips for better (video) lectures and Zoom sessions ====
* It is tempting to record yourself in front of the camera, talking over slides. While this may be useful for many lectures, sometimes, it might be easier for your students to understand and engage with your content when you '''record your lecture as a conversation''' with a relative, a colleague, or someone from your household to which you explain the lecture's content. Don't stage this - if you listener does not understand your lecture, you students probably won't, either. Let your listener ask questions, and explain things in more detail, if necessary.
* Include '''interactive elements''' in your (pre-recorded) lectures, such as small tasks or questions for the students, which you come back to during or after the lecture, or in a Zoom session.
* In Zoom calls, '''use [http://mentimeter.com Mentimeter]'' to facilitate participation for your students. You can create quizzes or ask for thoughts and let students rank items, but also show them slides or videos. You can also host Q&A sessions via Mentimeter, where students can upvote questions, which brings order into Q&A. However, a Q& A may best be supported by letting students raise their hands in the Zoom call so they can also speak and listen to fellow students, and not just read, type and click.
* In Zoom sessions, '''use breakout rooms''' for the students to discuss questions that you posted, or questions that came from the students themselves. After some minutes, you can let the students share their thoughts, for example via Mentimeter. The breakout rooms also make some students keep their camera on, which may improve the atmosphere in the session.
* In Zoom sessions, '''use gimmicks''' to maintain a positive atmosphere. Hold a contest about the best virtual background, or let students share their favorite snacks during a short break. It always helps when as many students as possible have their cameras turned on, so think of ways to achieve this.

==== Some ways to jumpstart and foster an open and collaborative atmosphere when teaching a class or leading a team ====
'''Quick personal meetings'''
From time to time, give participants the opportunity to briefly (e.g. 5-10 mins.) talk with you one-on-one. You can offer an open Discord channel for this, or a Zoom room, in which you are approachable during pre-determined timeslots. Here, let students and team members join you individually. This fosters a more personal relationship and gives everyone the possibility for the type of interaction that is more spontaneous and less guarded (and therefore more personal). Give it the atmosphere similar to an exchange during a coffee break, while walking down a hallway, or similar situations to break the behaviour patterns that are typically prevalent during a class or a formal meeting.

'''How is everyone feeling?''
Start and end sessions with giving the participants the possibility to say a one-sentence statement about their current (subjective) personal status/mood/thougths/feelings without anyone commenting on them or referring to them (in the sense of a non-judgmental environment). The participants should be free to say whatever they feel like (it is not a round of feedback on the subject matter or the class, but more a statement of ""where each person is"" at the moment).
This requires a certain amount of trust and openness in the group and needs a bit of getting used to (risk-taking).

'''Personal object bring-along'''
Encourage each participant - in a smaller seminar, or workshop - to bring a personal object into the class, or meeting, and ask them to place it so that everyone in the digital room can see it. Encourage to choose a different object sponanteously  each time based on instincts (e.g. while they are preparing for the meeting or while they are leaving their place to attend the class). These objects can foster dialogue and enjoyment as well as express the person's attitude and mood which are vital clues to socially connect - especially in online meetings (but also in in-person gatherings). It can be a good starting point when getting to know new people. Optionally, you can introduce a game variant (that should be non-competitive) by asking participants to take into consideration previously chosen objects introduced by other participants - in that way reacting to them.


==== Wiki entries on Skills & Tools that can support learning and teaching ====
* [[Flipped Classroom]], a teaching format that is especially interesting for digital times.
* [[Digital Energizers]], to gain energy in digital sessions.
* [[Check In]], to provide a good atmosphere for smaller groups.
* [[Flashlight]], to make sure everyone's on the same page in smaller groups.
* [[Digital Workshop Facilitation]], an overview on general learnings about digital workshops and sessions. 
* [[Online Conduct]], a few ideas on how to improve conduct in shared online spaces.";done
To Rule And To Measure;"'''Note:''' The German version of this entry can be found here: [[To Rule And To Measure (German)]].

'''In short:''' This entry illustrates different types of data units and approaches to measuring our world.

== Introduction ==
Throughout history, humans have developed myriads of tools and units that help measure, categorize, compare, analyze and understand things, processes and people - in short, the world. '''We have measured space and time, sound and light, the movement of atoms and molecules, and there is no end in sight'''. You use measurements every day - stepping onto the weighing scale in the morning (don't do that!), calculating the time you need to get to university, the amount of sugar you need for the cake, or the money you spent last weekend. You may even (unconsciously) reflect on the amount of fun different potential activities might be, or think about your level of satisfaction with your last meal. 

Some units of measurement are very strongly connected to the physical world, such as measuring weights or lengths, despite the existence different units to do so. Others are very much socially constructed, such as the Human Development Index (HDI), which puts a number to the whole quality of life. And then, there is a wide range in between, like the Beaufort scale which does measure something physical (wind), but is quite an arbitrary form of doing so. 

The same can be said for tools that enable the translation of physical or social phenomena into such units: some, like a ruler, are very much related to physical properties, while others, such as IQ tests, are based on so many assumptions about how intelligence should or could be measured, that there is no denying strong normative implications. There is no judgement to be made here, but one should be aware of the fact that units of measurement may imply specific assumptions about the world and how much we can know about it. There are things we can measure, things we can measure but are not necessarily like that, and things we cannot measure at all.

'''The following entry provides examples on units of measurement and tools to measure.''' There will be more additions over time. All of these represent major breakthroughs and have consolidated over time. All these diverse data formats and tools should strengthen our understanding that we look at parts of the picture. The emergence of new measures does not only unlock new knowledge, it also highlights the limitations of our total knowledge. As [[Bias and Critical Thinking|critical realism]] claims, we may never be able to fully understand all aspects of all mechanisms of reality that are real. For instance, many institutions are riddled by [[Glossary|tacit]] knowledge that we only now start to slowly unlock. We thus have to acknowledge that the examples given here have limitations, and that there are many forms of knowledge that cannot be tamed or constructed into numbers. 

To this end, this entry is not only an example of diverse possibilities, but also highlights how several different data formats may even contradict other forms of knowledge, or may even hamper a different but necessary understanding of certain mechanisms. The 20th century was in many aspects dominated by numbers, which informed policy and management, and served as a baseline for diverse aspects of emerging [[Scientific methods and societal paradigms|societal paradigms]]. Especially economic thinking was widely based on such understanding, and equally was positivism mostly built around numbers and measures. '''What is often overseen to this end is the fact that these numbers are not objective, but also normative.''' For instance, measures of IQ are not only deeply constructed, but also deeply contested. While much of empirical research still claims to create objective knowledge, it becomes increasingly clear that such claims are often falsifying each other. If we however clearly recognise the limitations of all these diverse measure, we may also be better enabled to understand the value of these measures.

Please refer to the [https://sustainabilitymethods.org/index.php/Data_formats entry on Data formats] for more general information on how data can be formatted.


== Data units ==
==== Celsius vs Fahrenheit vs Kelvin ====
Celsius, Fahrenheit and Kelvin represent the most common temperature scales used today. While Celsius is used in most places in the world, the USA and associated territories still use the Fahrenheit scale. Kelvin is based directly on Celsius and is most commonly used by scientists to communicate their results (e.g. when speaking about a temperature increase of 2K), but not really used in everyday practice in any country.

[[File:To Rule and To Measure - Celcius.png|300px|thumb|right|'''Fahrenheit, Celsius and Kelvin.''' Source: [https://cryo.gsfc.nasa.gov/introduction/temp_scales.html NASA]]]

In Celsius, water freezes at (~) 0°C and boils at (~) 100°C. -273,15°C represents the lowest possible temperature a gas can (theoretically) reach, and can be translated into 0 Kelvin. Kelvin is thus always 273,15 higher than Celsius. The unit of Fahrenheit is based on a thermometer using a mixture of water, ice and ammonium chloride - the minimum temperature that could be reached with this mixture was set as 0°F. Fahrenheit can be translated into Celsius as follows: °F = (°C)x(9/5) + 32
<br/>
(Source: https://cryo.gsfc.nasa.gov/introduction/temp_scales.html)


==== Richter Scale ====
The Richter Scale is used to measure the strength of Earthquakes. It was developed in 1935 by US American seismologists Richter and Gutenberg. It is based on the logarithm of the amplitude of the largest seismic wave of an earthquake event. Each increase of one unit on the scale signifies a tenfold increase in the magnitude of an earthquake, and a 31 times higher amount of energy released. While today's technologies can measure seismic waves below what was possible with the Richter scale, and are better to measure very strong earthquakes, the Richter scale is still often used, especially in the media. (Source: britannica.com/science/Richter-scale)
[[File:To Rule and To Measure - Richter Scale.png|400px|thumb|center|'''The Richter Scale.''' Source: [https://www.britannica.com/science/Richter-scale Britannica]]]";done
Transcribing Interviews;"'''In short:''' This entry revolves around Transcription, which is the reconstruction of recorded audio into written text for the analysis of Interviews. For more on Interview Methodology, please refer to the [[Interviews|Interview overview page]].

== What is Transcription? ==
Transcription is not a scientific method in itself, but an important step between the conduction of Interviews and the Coding process and subsequent analysis. '''Transcription entails the process of writing down what has been said in an Interview based on video or audio recordings.''' Transcription has become common practice in qualitative research (1). The transcription process is an analytical and interpretative act, which influences how the transcript represents what has actually been said or done by the interviewee(s) (1, 3). A well-conceived transcription process will support the analysis, and a bad transcription may lead to an omission or distortion of important data. This entry revolves around important elements of the transcription process. For more details on Interviews and the subsequent analysis of the transcripts, please refer to [[Interviews]] and [[Content Analysis]]. 

'''Transcriptions are mostly relevant for qualitative Interview approaches''', such as [[Open Interview]]s, [[Semi-structured Interview]]s, [[Narrative Research|Narrative Interviews]], [[Ethnography|Ethnographic Interviews]] or [[Focus Groups]]. It may also be relevant for [[Video Research]], or serve as a source for supplementary data when conducting [[Surveys]]. Transcripts enable [[Glossary|researchers]] to analyze what Interviewee's or observed individuals said in a given situation without the risk of missing crucial content. Knowing that the data will be there later on allows for the researcher to engage with the Interview situation instead of imposing the need to write everything down right away. Recorded material can be re-visited long after the data gathering process and transcribed.


== Denaturalized and naturalized transcription ==
'''In a denaturalized approach, the recorded speech is written down word by word.''' Denaturalized transcription revolves mostly around the informational content of the interviewee's speech. Denaturalism ""(...) suggests that within speech are meanings and perceptions that construct our reality"" (Oliver et al. 2005, p.1274). '''This approach is more about ''what'' is said, than ''how'' it is said,''' and is mostly relevant to research interested in how people conceive and communicate their world, for example in Grounded Theory research (although there are also exceptions here) (Oliver et al. 2005, p.1278).

'''Naturalized transcription is as detailed as possible,''' including stutters, pauses and other idiosyncratic elements of speech. It attempts to provide more details and a more 'realistic' representation of the interviewee's speech. The idea is to reduce a loss of information, be more 'objective' and true to the Interviewee(s), and thus impose less assumptions through the researcher. Naturalized Transcription is, for example, of interest when a conversation between individuals is recorded (in a group interview, or a Focus Group), and the way in which these individuals interact with each other is of interest (overlapping talk, turn-taking etc.) (Oliver et al. 2005, p.1275.) Grammatical or spelling mistakes are not corrected in the transcript for naturalistic transcription (1). Also, verbal cues that support the spoken word may elicit more insights for the researchers, such as dialects, increasing or decreasing volumes and specific emphases for individual words, or pauses. For this purpose, the transcript may include textual symbols to provide more information despite the words themselves:

[[File:Transcribing Interviews - Naturalized textual symbols.png|700px|thumb|center|'''Textual symbols in naturalized transcription.''' Source: Oliver et al. 2005, p.1276]]

'''Naturalized transcription concerns itself more with ''how'' individuals speak and converse.''' However, the researcher needs to weigh whether this level of detail is necessary for the specific research intent, since it leads to a considerable increase in transcription effort.


== Normativity of transcriptions ==
No matter the approach to transcription, it is important to acknowledge that any transcript is a re-construction of the Interview done by the researcher. As Skakauskaite (2012, p.24) highlights: ""Transcribing (...) is a form of analysis that is shaped by the researchers' examined and unexamined theories and assumptions, ideological and ethical stances, relationships with participants, and the research communities of which one is a member"". '''A researcher that bases his or her analysis on Interview transcripts needs to acknowledge this role he or she imposes on the data in the subsequent analysis and interpretation.''' A lack of reflexivity in this regard may distort the research results, and impede interpretation especially in-between different research communities. Oliver et al. (2005) therefore suggests researchers to reflect upon the chosen approach and which challenges emerge based on it. 

Likewise, Skakauskaite (2012, p.25) calls for more transparent information on the construction of transcripts in research publications: ""What we can learn and know about human activity and interaction depends on how we use language data and what choices we make of how to turn audio (and/or video) records into written texts, what to represent and not represent, and how to represent it. Given that there is no single way of transcribing, making transparent transcribing decisions and theories guiding those decisions, can provide grounded warrants for claims researchers make about observed (and recorded) human actions and interactions."" Therefore, a proper documentation of the chosen approach, the underlying rationale, and the challenges that were recognized is advisable. Also, asking peers to assess the transcript, or attempting member checking - i.e., interviewees check the transcripts for accuracy - may improve the transcript to this end (1).


== Challenges in the transcription process ==
Oliver et al. (2005) list a range of challenges in the translation of recorded speech to text. These include technical issues, such as bad recording quality. Further, transcribers may mis-interpret pronunciation, slang or accents, and write down incorrect words. Also, involuntary vocalizations, such as coughing or laughing, may provide additional information to supplement speech, but also not be of meaning, which may be hard to decide. Lastly, non-verbal cues such as waving or gesticulations may add information to the spoken word, but are only analyzable if recorded on video and/or noted down during the interview, and subsequently added to the transcript.";done
Transdisciplinarity;"'''Note:''' The German version of this entry can be found here: [[Transdisciplinarity (German)]]

'''In short:''' Transdisciplinarity is a research approach that is commonly applied in Sustainability & Transformation Research, focusing on the collaboration of academic and non-academic actors with a solution-oriented perspective. The following entry introduces the approach, its characteristics and prevalent challenges, and illustrates the use of methods with examples.

== Multi-, Inter- and Transdisciplinarity ==
To understand transdisciplinarity, it should first be distinguished from multidisciplinarity and interdisciplinarity. This is especially relevant when comparing German-speaking and English-speaking resources: the US-American understanding of transdisciplinarity is rather comparable to interdisciplinarity, while the German-speaking discourse is based on the following distinctions.

[[File:Disciplinary.png|700px|thumb|right|'''Different forms of disciplinary cooperation.''' [http://makinggood.design/thoughts/tasty/ Source.]]]
* '''Multidisciplinarity''' revolves around the cooperation between different academic disciplines for one research endeavour. The researchers study the same topic in a parallel structure and all have their distinct goals and research questions. They share knowledge and compare their findings and may also combine their results in one big report, but the disciplinary boundaries generally remain intact. (Stock & Burton 2011)
* '''Interdisciplinarity''' is a research mode that deploys a higher level of cooperation between researchers from different, often rather unrelated disciplines. Disciplinary viewpoints are crossed and integrated to develop new perspectives in order to create new knowledge or re-assess existing, disciplinary knowledge. As an example, political scientists and ecologists may come together to jointly study a eco-political issue.  (Stock & Burton 2011)
* '''Transdisciplinarity''', then, can be seen as the next higher step. Transdisciplinarity is ""a reflexive, integrative, method-driven scientific principle aiming at the solution or transition of societal problems and concurrently of related scientific problems by differentiating and integrating knowledge from various scientific and societal bodies of knowledge."" (Lang et al. 2012, p.26f). The most important features here are
** the collaboration of academia and society in a mutual learning and research process where stakeholders (politicians, entrepreneurs, NGO representatives, citizens etc.) are involved at all stages, i.e. in the framing of the problem, the development of possible solutions and the creation of new scientific knowledge, with a focus on these stakeholders contributing their specific knowledge and experiences to broaden the research perspective; 
** the focus on real-world problems, such as questions of sustainable development, that strongly affect and interest not only the academic sphere, but also the economy, culture and politics; as well as 
** the development of solutions to the studied problems that are transferable both into scientific and practical discourses and action. (Stock & Burton 2011, Lang et al. 2012, Arnold & Piontek 2018, Mauser et al. 2013; Ruppert-Winkel et al. 2015).  


== Why should (Sustainability) Science engage with the public? ==
Throughout the last centuries and decades, the differentiation and [[Glossary|institutionalisation]] of scientific disciplines allowed academia to develop and deepen specified conceptual and methodological expertise and create distinct language and topics that have enabled these disciplines to provide plenty of insightful knowledge and guidance for society (Stock & Burton 2011). However, '''there has been an increasing recognition that disciplinary viewpoints and approaches may no longer be sufficient to solve prevalent challenges''' that span across several scientific and societal spheres. Examples for this are ecological threats such as biodiversity loss or socio-technological challenges such as digitalisation which demand the creation of new theoretical and empirical scientific insights, but also action-oriented solutions that can be applied in policy, business, education, culture and such. With his landmark 1994 publication, Michael Gibbons introduced the term ""Mode 2 research"" which highlights this emerging form of scientific inquiry that is ""characterised by closer interaction between scientific, technological and industrial modes of knowledge production, by the weakening of disciplinary and institutional boundaries, by the emergence of more or less transient clusters of experts, often grouped around large projects of various kinds, and by the broadening of the criteria of quality control and by enhanced social accountability."" (Gibbons 1994, p.68)

To this end, multi- and interdisciplinary research modes (see above) are research modes that already cross disciplinary boundaries to some extent, sharing knowledge or jointly creating it, but transdisciplinary research best represents this new form of knowledge production. Mode 2 research and transdisciplinary research have therefore often been used synonymously. Transdisciplinary research facilitates the creation of not only system knowledge (the current state) and target knowledge (the intended state), but especially of transformational knowledge (how to get there) that considers the demands and preconditions of all relevant stakeholders. Thus, transdisciplinary research is of particular interest where there is a lack of practical knowledge about a specific problem, solution pathways are not yet known and there is a need for societal negotiation throughout the development of solutions. (Arnold & Piontek, p.145f)

'''Transdisciplinary research is of special importance to Sustainability Science and has received immense recognition in this field in the last years.''' This is because ""[s]ustainability is also inherently transdisciplinary"" (Stock & Burton 2011, p.1091), as it builds on the premise of solving real-world problems which are deeply nestled in ecological, political, economic and social processes and structures and therefore cannot be understood and solved without engaging with these spheres (Kates et al. 2015). Transdisciplinary research is a suitable approach for Sustainability Science: it allows to incorporate the knowledge of relevant stakeholders; it considers the normative dimensions involved in societal endeavors (that is, diverging norms, goals and visions of different societal spheres); and it increases [[Glossary|legitimacy]], ownership and accountability for the jointly developed solutions (Lang et al. 2012; Stock & Burton 2011). The integrative transdisciplinary approach highlights systemic interdependencies, enables a better understanding of complex issues and provides better knowledge to develop socially robust and applicable, effective solutions (Lang et al. 2012; Mauser et al. 2015).";done
Types, Expressions, and Variables in Python;"Example: I want to get the “AT” from “CAT”

<syntaxhighlight lang=""Python"" line>
pet = “CAT”
print( pet[1:3] ) 
</syntaxhighlight>
Here again, you learn how Python counts. When using the slice operator, the lower bound (in this case 1) is included and the upper bound (in this case three) is not. In words this means: From the variable ""pet"", print all indexes from the index 1 (second element) to three (fourth element), excluding three. 

==Quiz==
1. my_minutes = 200
my_hours = my_minutes / 60
what will be the result of my_hours? 
2. Use the type function to check the type of the variable: my_minutes
3. What happens when you put “-1” when you index a string? Example: 
<syntaxhighlight lang=""Python"" line>
pet[-1]  
</syntaxhighlight>
4. What happens when you add 2 strings together? 
Example: 
<syntaxhighlight lang=""Python"" line>
pet_1 = “cat”
pet_2 = “dog”
pet_3 = pet_1 + pet_2
</syntaxhighlight>
5.
Kim has three apple trees. From each tree, they can harvest 20 apples. They plant a new tree every year but can only harvest apples one year after it has been planted. Kim has 5 housemates who each want two apples every year and three family members who want 3 apples a year. To pay her rent they need to sell 53 apples a year. Are the apple trees enough to pay the rent and give their friends the apples? If no, when is this the case?

[[Category:Statistics]]
[[Category:Python basics]]

The [[Table of Contributors|author]] of this entry is XX. Edited by Milan Maushart";done
Video Research;"[[File:ConceptVideoResearch.png|450px|frameless|left|[[Sustainability Methods:About|Method categorization]] for [[Video Research]]]]
<br/>
{|class=""wikitable"" style=""text-align: center; width: 50%""
! colspan = 3 | Method categorization
|-
| '''[[:Category:Quantitative|Quantitative]]''' || colspan=""2"" | '''[[:Category:Qualitative|Qualitative]]'''
|-
| '''[[:Category:Inductive|Inductive]]''' || colspan=""2""| [[:Category:Deductive|Deductive]]
|-
| style=""width: 33%""| '''[[:Category:Individual|Individual]]''' || style=""width: 33%""| [[:Category:System|System]] || [[:Category:Global|Global]]
|-
| style=""width: 33%""| [[:Category:Past|Past]] || style=""width: 33%""| '''[[:Category:Present|Present]]''' || [[:Category:Future|Future]]
|}
<br/>__NOTOC__
<br/><br/>
'''In short:''' Video Research extracts information based on video material of social interactions.

== Background ==
[[File:Video-based Research.png|thumb|400px|right|'''SCOPUS hits per year for Video-based Research until 2019.''' Search term: 'video analysis' in Title, Abstract, Keywords. Source: own.]]

In the beginning of the 20th Century, [[Ethnography|ethnographers]] made use of early video technology for so-called 'film studies' that had a focus on ""human behavior and conduct, interaction and communication"" (Janík et al. 2009, p.7; 1). Yet, video- or audio-taping was also often used merely to help produce more precise transcriptions of speech in qualitative research and to identify and describe the speaking individuals (4). 

'''During the second half of the 20th Century, however, the rising availability and fidelity of video technology led to an increase of its usage and to advancements of the methodology'''. Being able to videotape events, such as classroom sessions, offered researchers new, rich possibilities of qualitative analysis compared to solely relying on taking notes and conducting interviews (1). At the same time, this deep insight limited in turn the potential sample size in the respective studies (4). So while purely qualitative approaches - focusing on single or small numbers of classes - had become a common form of educational analysis by the 1990s, they did not allow for generalizations that were necessary for changes in educational policies. 

As a consequence, quantitative approaches in form of Video Surveys were introduced at the end of the 1980s (1, 4). The most notable research endeavor in this regard was the ''TIMSS Videotape Classroom Study'' in the 1990s (see Key Publications). This study relied on 'Video Surveys', which include bigger case numbers and which were made possible through improvements in multimedia computer technology (1, 4). They combine the potential for statistical analysis and thus more generalizable findings while maintaining the validity provided by the video technology. Due to the technological improvements during the last decades, video-based research was subsequently applied more often (1, 3, 6). Today, video-based methodologies are used mainly in educational research, often in the field of cross-national comparisons, but also in psychology and sociology (1, 4).


== What the method does ==
Video-based research refers to ""(...) research of social or educational reality based on analysis of video recordings"" (Janík et al. 2009, p.7). '''Individual events, such as classroom sessions or cultural ceremonies, are recorded on video. The generated video footage then serves as the basis for the analysis of the respective situation.''' Video-based research is thus a method that includes both [[Glossary|data]] gathering and data analysis (2). The video data is coded in a process similar to [[Content Analysis]]: the events happening in the video and the statements made by, for example, teachers and students are coded according to theory-led, pre-determined or inductively and iteratively developed categories (4). Often, additional data is adduced to provide contextual information (see Challenges).

[[File:Video Research example study.png|600px|thumb|center|'''The design of a study in education research, combining video-taping with additional forms of data gathering.''' Source: (Brückmann & Knierim 2008, p.193)]]

The scope of the research may range from qualitative, unstructured, small-scale observations to more quantitative, large-scale, structured studies, depending on the research questions and theoretical approach (2). Quantitative approaches allow for the identification of trends and variations, while more qualitative approaches strengthen the understanding of prevalent phenomena (1). The possibility of combining both approaches is special about video-based research and enables researchers to quantitatively validate comprehensive qualitative findings (1, 4).

== Strengths & Challenges ==
* The biggest strength of the method stems from the nature of the data. '''Video material can be slowed down, stopped, rewound, re-watched and stored for a long time.''' This makes video-based research ""(...) a tool for social scientists to observe phenomena that are too complex to be noticed by the naked eye."" (Janík et al. 2009, p.7). The researchers are not limited to what they were able to note down during the event itself, but can assess everything that happened as often as they like (1, 4, 6). At the same time, this complexity can be reduced to a specific aspect of interest for a first analysis, after which the researchers can come back to the data at any later point for further inquiries (2). Long-time comparisons are also possible if similarly taped videos are produced over a span of time. Several researchers - potentially from different disciplinary backgrounds - can code and analyze the material at once, and regularly discuss their insights and exchange perspectives which can lead to the [[Glossary|emergence]] of new ideas and analytic categories (1, 3, 4, 6). This increases inter-coder reliability without having to determine a narrow focus of the research prior to the data collection (3, 4). In addition, the data format facilitates the [[Glossary|communication]] of results since exemplary scenes or images can be taken from the video (4).
* '''The complexity of the respective situation as captured by the video material allows for both qualitative and quantitative analysis and the application of a range of different research questions and perspectives.''' Also, as mentioned before, qualitative and quantitative results can be integrated because of the rewatchability of the data.";done
Visioning & Backcasting;"[[File:ConceptVisioning.png|450px|frameless|left|[[Sustainability Methods:About|Method categorization for Visioning]]]]
<br/>
{|class=""wikitable"" style=""text-align: center; width: 50%""
! colspan = 3 | Method categorization
|-
| '''[[:Category:Quantitative|Quantitative]]''' || colspan=""2"" | '''[[:Category:Qualitative|Qualitative]]'''
|-
| '''[[:Category:Inductive|Inductive]]''' || colspan=""2""| [[:Category:Deductive|Deductive]]
|-
| style=""width: 33%""| [[:Category:Individual|Individual]] || style=""width: 33%""| '''[[:Category:System|System]]''' || '''[[:Category:Global|Global]]'''
|-
| style=""width: 33%""| [[:Category:Past|Past]] || style=""width: 33%""| [[:Category:Present|Present]] || '''[[:Category:Future|Future]]'''
|}
<br/>__NOTOC__
<br/><br/>
'''In short:''' In a Visioning process, one or more desirable future states are developed in a panel of scientific and non-scientific stakeholders. In the process of Backcasting, potential pathways and necessary policies or measures to achieve these future states are developed.

== Background ==
[[File:Visioning.png|400px|thumb|right|'''SCOPUS hits per year for Visioning until 2019.''' Search term: 'visioning' in Title, Abstract, Keywords. Source: own.]]
Visioning and Backcasting are historically connected and each of them cannot be thought without the other. '''Backcasting emerged earlier than Visioning during the 1970s and first in the field of energy planning,''' ""(...) growing out of discontent with regular energy forecasting that was based on trend extrapolation, an assumed ongoing increase in the energy demand and a disregard for renewable energy technologies and energy conservation"" (Vergragt & Quist 2011, p.748). Subsequently, Backcasting was furthered in this field in the USA, Canada and Sweden (1, 8). The topics approached through Backcasting shifted towards the field of sustainability after the ""Our Common Future"" report in 1987 (8). 

'''Modern Visioning approaches emerged later during the 1980s and 1990s''' with the incorporation of [[System Thinking & Causal Loop Diagrams|System Thinking]] and participatory engagement (1). Since its emergence and due to a rising role of participatory approaches, different versions of Visioning have been developed, including future workshops, community visioning, sustainability solution spaces, future search conference, visioneering and others (1). 

Today, Visioning is used most prominently within planning and planning research where it helps guide investments, politics and action programs (1). Examples for this are energy planning or urban planning (2, 3, 5, 7). '''It has also become particularly important in transformational sustainability science''' that tries to directly contribute to real-world sustainability transitions (1). In this field, especially the research body on transition management argues for a combination of social and technological innovation and multi-stakeholder-approaches for sustainable development (3). Still, Visioning research is still at a ""nascent stage"" (Iwaniec & Wiek 2014, p.544), and has not yet fully been established as a method.


== What the method does ==
In a Visioning process, multidisciplinary stakeholders (most commonly scientific and non-scientific experts on the topic, or also non-experts in participatory approaches) are brought together for a workshop to collect ideas and finally formulate a joint vision as an answer to a previously asked question (1, 8). A vision provides “a key reference point for developing strategies to transition from the current state to a desirable future state, actively avoiding undesirable developments” (Wiek & Iwaniec 2014, p.498). This vision can take the form of qualitative or quantitative goals and targets (1). For example, such a vision could be ''a society based entirely on renewable resources'' or ''a technological process that causes minimum environmental impact'' (2). In theory, a vision can cover every spatial and temporal scale. Visions for the planet in hundreds of years are just as conceivable as a vision for a small company in five years. The exact dimensions depend on the intended goal of the Visioning process. The vision itself may exist on a very basic level, e.g. 'a world without hunger'. However, by adding more specific qualitative and especially quantitative targets and elements, the vision may become more complex. This complicates the subsequent Backcasting process which, based on a systemic perspective, needs to consider various societal and technological elements that influence the intended process of policy-making (2, 6).

'''Visioning combines data gathering, data analysis & interpretation:''' In preparation, sound knowledge of the issues at hand is mandatory which may be developed by analyzing and interpreting existent data on the current state of a particular system (e.g. a country, a company, a landscape) (3, 6). Based on this, a vision for said system is created, generating new qualitative and/or quantitative data. This process can be structured in four steps according to Wiek & Iwaniec (2014, p.504). 
# Framing the Visioning process
# Creating initial vision material (vision pool)
# Decomposing and analyzing this material, and finally
# Revising and recomposing the vision 
The Visioning process should continuously be reflected upon and revised iteratively (1).

A wide range of possible techniques and settings for vision development is available (6). Among these are abstract forms (vision maps, solution spaces), more realistic visualisations of landscape and city visions using GIS or video techniques; and a set of other visual and digital solutions (decision theaters, digital workshops) (1). More generally, ideas may be collected using e.g. [[Design Thinking]] approaches or [[Glossary|brainstorming]], and sorted through clustering and rating procedures, among others (3). Discussions and thoughts may be secured in form of notes, drawings or voice recordings (5). As per setting, a 'neutral' location (i.e. unaffiliated to specific stakeholders) may be preferable in order not to influence the Visioning process (3). Virtual solutions are possible - bringing people together physically, however, may provide benefits to their interaction that virtual solutions lack (3).

Complementary to the Visioning approach, Backcasting describes the process of developing pathways to reach the vision. While it is thus a method in its own right and not to be understood synonymously with Visioning, these two processes are directly connected to each other.";done
Walking Exercise;"[[File:ConceptWALKINGEXERCISE.png|450px|frameless|left|[[Sustainability Methods:About|Method categorization]] for [[WALKING EXERCISE]]]]

<br/>
{|class=""wikitable"" style=""text-align: center; width: 50%""
! colspan = 3 | Method categorization
|-
| [[:Category:Quantitative|Quantitative]] || colspan=""2"" | '''[[:Category:Qualitative|Qualitative]]'''
|-
| '''[[:Category:Inductive|Inductive]]''' || colspan=""2""| '''[[:Category:Deductive|Deductive]]'''
|-
| style=""width: 33%""| '''[[:Category:Individual|Individual]]''' || style=""width: 33%""| [[:Category:System|System]] || [[:Category:Global|Global]]
|-
| style=""width: 33%""| '''[[:Category:Past|Past]]''' || style=""width: 33%""| '''[[:Category:Present|Present]]''' || [[:Category:Future|Future]]
|}
<br/>__NOTOC__
<br/><br/><br/>


''' In short:''' Mental maps are a visual representation of how people perceive their daily environment and how people orient themselves in it. The ''Walking Exercise'' makes use of this strategy to initially build sustainability competencies in higher education settings.

== Background ==
[[File:VisualisationMentalMapsWALKINGEXERCISE.png|thumb|right|mental maps of Phoenix (a + b) and Hamburg (c + d). Source: (1)]]
The world and environment are in a critical state as there are certain sustainability challenges, such as biodiversity loss, global warming, limited resources, and increased inequalities. From this, the need to react to them arises, both locally and globally. Developing certain sustainability competencies (skills, abilities) can be a start to learn how to do so. Wiek et al. (1) have sketched out five competencies that should be considered for academic program development. These are as follows: systems thinking, anticipatory competence, normative competence, strategic competence, and interpersonal/collaborative competence. Based on these, Caniglia et al. (2) have worked out a method, aiming at building some of the aforementioned competencies, which is called ''Walking exercise''. The method combines mental mapping and exploratory walking.

[[File:Transect-walk.png|thumb|right|source: https://www.spool.ac/index.php/spool/article/view/35]]
'''Mental mapping''' stems from the field of behavioural geography and was especially coined by Kevin Lynch and his work “The Image of the City” (3). It captures how people perceive their urban environment. Practically speaking, a person’s image of a city is their mental map of it. The map usually entails the following characteristics:
* paths: routes along which people move throughout the city; 
* edges: boundaries and breaks in continuity; 
* districts: areas characterized by common characteristics; 
* nodes: strategic focus points for orientation like squares and junctions;
* landmarks: external points of orientation, usually an easily identifiable physical object in the urban landscape.

'''Exploratory walking''' (or transect walking) is a method from the field of city planning often used for observation-based community improvement. Its aim is the gathering of data and experience of one’s own daily environment in a systematic way that transform one’s own perception of it, thereby gaining deeper understanding. This means walking through the environment along a defined path across an area and taking notes on what stands out. Often, it is done in small groups in order to be able to exchange with others.


==What the method does==

[[File:Goals.png|thumb|right|Goals of the Walking exercise. Source: (1)]]
[[File:Walking exercise spiral.png|thumb|right|Phases and steps of the Walking Exercise. Source: (1)]]
'''The ''walking exercise'' is a bottom-up, student-centered, and experience-based method in higher education settings to develop sustainability competencies in local contexts.''' It is meant for students with no or little previous knowledge in sustainability science, for example first-semester students in the environmental sciences realm and spans over one semester.

The goal is to actively engage with sustainability problems in one’s surroundings from the beginning on and thereby understand concepts, principles, methods of sustainability and think about solution options.

Essential for this is the '''development of [https://www.youtube.com/watch?v=1vHY2RJnr3A sustainability competencies]''', especially systems thinking, normative, and collaborative competencies as named by Wiek et al. (2011).

Systems thinking means the ability to analyze complex systems and problems across different domains (society, economy, environment) and scales (local to global) in order to engage with and tackle them. 
Normative competencies, or “value-focused thinking”, stands for the evaluation of sustainability through different sustainability principles and the ability to discuss and apply values, habits, perceptions and experiences. It is tightly connected with ethics and touches upon reflecting on one’s own position as well.
Being able to motivate people and facilitate group processes using non-violent and empathetic communications, as well as actively listening, is the essence of collaborative competencies. As it describes practices between people, it is called interpersonal competence also.

In order to foster these competencies, students shall perceive and explore their urban environment using mental mapping activities and walking activities (connecting the learning objectives directly with one’s own experience). 
To do so, both phases (mapping and walking) are performed after one another and share the same four sub-steps: preparation, data gathering and analysis, interpretation and reflection, and lastly, sharing. 

In their learning experience, students are supported by an instructor who guides them by preparing methodological/theoretical inputs, reflection questions, and facilitates in-class discussions. However, it is by no means a frontal teaching style but rather a source of support if needed, as students should learn from their own experiences.



";done
Web Scraping in Python;"* First we install BeuatifulSoup which we need for the web scraping, and time, to track the response time. We have also set the start time in the beginning.
*Then, we create an Html parser to parse the Html document. Parsing means that the Html code is transformed in a way that we can use it in Python
* We then fetch the Html elements of interest using 'CSS selectors' which run in the backend of the select() function. By passing the 'td.titleColumn' argument, we ask the selector to fetch the td elements with the class 'titleColumn'. This data is stored in 'movies'.
* We have already seen that the information related to the ratings is present in a different element altogether. So, we use a CSS selector here with a different keystring 'td.ratingColumn.imdbRating strong'. This asks the selector to fetch those td elements which have the classes 'ratingColumn' and 'imdbRating'. Then, we ask the selector to fetch the 'strong' element within each of the chosen td elements (see the Html code in the last figure). Finally, we would like to fetch the content of the 'title' attribute for each selected strong element. This data is stored in 'ratings'. 

* We now iterate over 'movies' and 'ratings' objects to fetch the individual strings and extract the required data per movie. The following explains what exactly is happening in each iteration:

    # Since each string in 'ratings' object is formatted as ""(rating)     based on (count) user ratings"", we split the string of the rating column at each space character and pick the first and fourth elements of the split string to get the rating and the number of user ratings. Also, we format the number of user ratings by removing "","" in the string (the 2nd- 3rd line in the loop)
Rank details are at the very beginning of the text in each movie string (2nd-3rd last line in the loop). 
    # Crew details are present in the title attribute of the anchor tag of the string and the movie title is embedded between the anchor tags. Thus, we use the relevant code to extract these details
    # Release year is present between the span tags and is formatted as (year). Hence we fetch the content from the span tags and select the substring after removing the first and last elements of the original string.
* All the extracted details are put into a dictionary object 'data' and a list of all the dictionaries prepared in this manner is created.
* Lastly, we have set the end time so that we can print the response time. Have an eye on this if you send several requests.
To understand this code better, have the inspection tool open and look at the title and the rating column.

==Step 4: Storing the Data==
We now look at how to store the data prepared thus far. This is rather simple in Python as we simply store the data in a pandas DataFrame, with the appropriate column names provided, and then convert that to a .csv file.

<syntaxhighlight lang=""Python"" line>
import pandas as pd 

df = pd.DataFrame(movie_data, columns = ['rank', 'title', 'crew', 'release_year', 'rating', 'num_user_ratings'])
df.to_csv('movie_data.csv', index=False)
</syntaxhighlight>

We have successfully stored our data in a file titled 'movie_data.csv'.

== External Links==
* [https://www.okta.com/identity-101/data-scraping/ Data Scraping- Okta.com]
* [https://en.wikipedia.org/wiki/Data_scraping Data Scraping - Wikipedia]
* [https://kinsta.com/knowledgebase/what-is-web-scraping/ Web Scraping Uses- Kinsta.com]
* [https://www.dataquest.io/blog/web-scraping-python-using-beautiful-soup/ Dataquest tutorial For Web Scraping:] Legal aspects of web scraping are also mentioned here
* [https://realpython.com/beautiful-soup-web-scraper-python/ Real Python Tutorial On BeautifulSoup]
* [https://www.geeksforgeeks.org/scrape-imdb-movie-rating-and-details-using-python/ GeeksForGeeks Tutorial For IMDB Ratings and Details]

==Further Readings==
* [https://www.w3schools.com/html/html_xhtml.asp What is Extensible Hypertext Markup Language?]
* [https://rss.com/blog/how-do-rss-feeds-work/ RSS feed and their uses]
* [https://www.cloudflare.com/learning/security/api/what-is-api-call/#:~:text=Application%20programming%20interfaces%20(APIs)%20are,provide%20a%20service%20or%20information What is API?]
* [https://www.crummy.com/software/BeautifulSoup/bs4/doc/ BeautifulSoup Documentation:] For more on CSS Selectors and other ways of using BeautifulSoup
* [https://www.projectpro.io/article/python-libraries-for-web-scraping/625 BeautifulSoup Alternatives]
* [https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods Types of HTTP Requests]
* [https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages HTTP Messages (Requests and Responses)]

[[Category:Statistics]]
[[Category:Python basics]]

The [[Table of Contributors|author]] of this entry is XX. Edited by Milan Maushart";done
Why statistics matters;"'''In short:''' This entry provides a very brief overview on why you should care about statistics.

== The Power of Statistics ==
'''I consider statistics to be very powerful.''' Statistics became established over the last decades as one of the most important and abundantly used methods in modern science. Due to the development of modern computers and the manifestation of smartphones in the individual's daily life, there is a wealth of information available today. This triggered an almost co-evolutionary pattern where statistics evolved further in tandem with the increase of available data. While initially statistics focused on the calculation in astronomy and was widely preoccupied with testing hypotheses, this has vastly changed today. Much of the data that is available today is not harvested through [[Experiments|systematic experiments]]. Instead we all generate data. There is a swarm intelligence of data being formed. The most popular example is the internet which is basically one big junk of data including many datasets about us people as well as our planet that is not analysed to date. More analysis emerge out of the wealth of information and many of them are based on statistics. 

[[File:Bridge.jpg|thumb|right|400px|Building bridges is essential within science.]]
Statistics thus enable us to find [[Glossary|patterns]], building on large datasets we can aim to find relation and meaning within complex issues and maybe even sometimes reason and explanation. While it is widely a question of the epistemological development of science as well as a clear domain of philosophy the approximation of facts is something that is at the heart of statistics as well. It is within the power of statistics to unravel what we can understand of a given system or dataset. However, it should also be clear what we cannot understand. Very often this is a crucial point: Statistics does not only allow us to be critical of our analysis but also of our understanding and ultimately ourselves. The power of statistics can thus be also framed as the power of understanding our own limitations. Very often the most vital understanding is that we do not understand a lot after all. Here qualitative science and some other would argue first and foremost statistics are often associated with a certain arrogance. Out of that arrogance of statistics to provide answers and, I would argue, also the missing opportunity of researchers to experience societal phenomena, there is often a large scepticism towards statistics. It should be in our power now to hear these misunderstandings and to start building bridges between the conflicting parties. Scientists building on statistics are not only widely disconnected from qualitative researchers, but also from the dominating discourses in society. Only if statistics is integrated into the broader diversity of knowledge that science currently unfolds, we can unleash its full potential. 

'''We should aim to maximise our understandings based on statistics if it is possible, but we also need to be aware of the mere fact that statistics will not provide us with all the answers.''' Most statisticians are well aware of that, but science went a little bit on the wrong track when results derived from statistical analysis were communicated. The confidence of the statistical results is overall very clear when it comes to numbers, although these numbers mean different things to different people. Furthermore, numbers have context in certain settings, and this makes it highly implausible that the same number will always mean the same under any given circumstances. If I would proclaim a thought experiment where you have a 10% chance of dying then everybody would be quite unhappy to hear that they have a certain chance of sudden death. If you have on the other hand a lethal disease but a 10% chance of survival, you would probably want to hold onto that 10%. In our desperation,  many would hope and take the 10% chance. Quite often our recognition of numbers is flawed. Imagine that you could join a lottery for a fantastic new computer. 10 Euros today buy you a 10% chance to win this computer tomorrow. Many would probably join in and try to take their chance in this thought experiment. However, not too many would join in if they could get a 10% chance with the same amount of money in 10 years. The chances in this example did not change at all. However a 10% chance tomorrow is just different to most people then a 10% chance in 10 years. 

Humans are constructed in a sense where the distant future, the distant past, but also distant places are unreasonably less important to us then they should be. On the other hand, are things close to us unreasonably more important for most people (Parfit, 2013, pp. 56–57). Statistics do not have that floor. They are of course [[Bias in statistics|biased]] through the people that conduct them. However, the predictive power of statistics may enable us to do more guided actions. If more people would be able to find structures and patterns in data, they could take more informed decisions. This might be one steppingstone to overcome unreasonable behaviour at least partially. If we would be able to route our decisions more deeply in the rigorous analysis of statistics, then many of their perceptions and approximations that people have of reality might be quite different, and this may influence our behaviour. Right now, the actions of the majority of people are mostly disconnected from statistical data. If more people would have the possibility to understand at least a glimpse of statistics, then transparency and reflexivity could be potentially achieved. It is within our power now to cease the possibilities of statistics, and to translate them into a better understanding of our world.

==Statistics as a part of science==";done
Why statistics matters;"Also, statistical analysis is made in specific software tools such as R, SPSS or Stata, or even programming languages such as Python or C++. Learning to apply these software tools and languages takes time. If you are versatile in statistical analysis, you are rewarded, since many people will need your expertise. There is more data than experienced statistical analysts in the world. But more importantly, there are more open questions than answers in the world, and some of these answers can be generated by statistical analysis.

====Presenting statistical results====
[[File:Bildschirmfoto 2020-03-31 um 10.35.59.png|right|400px|thumb|left|The ""Sonntagsumfrage"" in Germany asks on weekly basis which party citizens would vote for if there would be elections on Sunday. The results are always presented in '''barplots'''.]]

[[File:Bildschirmfoto 2020-03-31 um 10.35.47.png|thumb|400px|Another form of presenting election results is the '''pie chart'''. In this example it visualizes the results of the state election in Hessen in 2009.]]

Within current media as well as the Internet, the most dominating forms of presenting statistical results are the barplot and the pie chart. The first can have some merits in illustrating simple numbers; the second one is often considered to be misleading if not manipulative. However, these two graphics represent the current baseline of knowledge of civil society when it comes to the [https://www.datapine.com/blog/misleading-statistics-and-data/ presentation of statistical results]. Sometimes certain newspapers as well as the Internet present simple correlation plots that are rather intuitive and therefore also understandable for people with some background in science. A prominent example is the [https://www.investopedia.com/ask/answers/042215/what-are-some-examples-positive-correlation-economics.asp Economist], which due to its topical focus quite often relies on correlation plots. 

Beyond that, most mainstream graphics that represent statistical results have more of an [https://www.open.edu/openlearn/science-maths-technology/mathematics-and-statistics/statistics/statistics-and-the-media aesthetic value] instead of a true representation of statistical results. When it comes to the actual numbers, only people with an education in science are more or less able to interpret terms such as significance, estimate or correlation. Here, it can be hoped that the landscape will change in the mid-term. Since the dawn of the personal computer and with a broader access to [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4008059/ knowledge] through our mobile phones and the Internet, many people have the possibility to explore statistical results, or at least get in touch with statistical results, even if indirectly. 

While software for analysing statistical data was in the past widely restricted to experts, the computer revolution even offers [https://www.r-project.org/ open source solutions] available to many people. Hence the proportion of people that are able to code, do statistical analysis, and understand the presentation of statistical results is dramatically increasing. If everybody would be able to interpret correlations and box plots, and would have clear understanding of statistical significance, we would be able to talk of progress.

====Generalisations on statistics====

[https://fs.blog/2015/11/map-and-territory/ ""The map is not the territory""] basically means that maps are a [http://www.nlpls.com/articles/mapTerritory.php generalisation] and therefore reduce the detailed richness/the richness of details of the territory. It took me very long to get this sentence. While it simply suggests that reality is different from the representation in a map, I think the sentence puzzled me because in my head it is kind of the other way around. The territory is not the [[Geographical Information Systems|map]]. This is how a statistician would probably approach this matter. Statistics are about generalisation, and so are maps. If you would have a map that would contain every detail of the [https://wiki.lesswrong.com/wiki/The_map_is_not_the_territory reality] how you perceive it, it would not only be a gigantic map, but it would be completely useless for orientation in the territory. Maps are so fantastic at least to me because they allow us through clever and sometimes not so clever representation of the necessary details to orientate ourselves in unknown terrain. Important landmarks such as mountains and forests, rivers or buildings allow us to locate ourselves within the territory. 

Many maps often coined thematic maps include specific information that is represented in the map and that follows again a generalisation. For example, land-use maps may contain information about agriculture pastures, forests and urbanisation, but for the sake of being understandable do not differentiate into finer categories. Of course for the individual farmer this would not be enough in order to allow for nuanced and contextual land use strategy. However, through the overview we gain an information that we would not get if the map would be too detailed. 

Statistics works kind of in the same way. If we looked at any given data point within a huge dataset we would probably be incapable of understanding general patterns. Likewise statistics does draw conclusion from the complicated if not complex data and are able to find meaning or explanations in the plateau of data. Hence I agree that if I want to get a feeling about a specific city that I visit then a map would probably not bring me very far in terms of absorbing the atmosphere of the city. Yet without a map it would be tricky to know where I would be going and how I find my way home again. Our individual data points are often very important to -you guessed it- individuals but the overall patterns are important to many of us. Or at least they should be, I think. But this is [[Big problems for later|another matter]]. [https://www.youtube.com/watch?v=x9BCsy77mlU The map is not the territory], but the territory is also not the map.

==References==

Parfit, D. (2013). ''On what matters'' (S. Scheffler, Ed.). Oxford University Press.

[https://en.wikipedia.org/wiki/History_of_statistics History of statistics] by Wikipedia

[http://homepage.divms.uiowa.edu/~dzimmer/alphaseminar/Statistics-history.pdf A Brief History of Statistics]

[https://www.destatis.de/GPStatistik/servlets/MCRFileNodeServlet/BWMonografie_derivate_00000083/8055_11001.pdf Barke, W. (2011).] ''Ich glaube nur der Statistik: Was Winston Churchill über Zahlen und die Statistik wirklich sagte und was er gesagt haben soll'' (6. Aufl.). Statistisches Landesamt Baden-Württemberg. 

==External links==

====Videos====
[https://www.youtube.com/watch?v=XQoLVl31ZfQ Bayes Theorem] Here you can watch one of the most popular examples of probabilistic theory

[https://www.youtube.com/watch?v=A8gD3CcbDTY Ronald Fisher] The video is about the life and work of one of the most famous statisticians

[https://www.youtube.com/watch?v=A7fcdRhSp8k&feature=youtu.be Different sampling methods] This video explains the most common sampling methods";done
World Café;"{|class=""wikitable"" style=""text-align: center; width: 100%""
! colspan = ""4"" | Type !! colspan = ""4"" | Team Size
|-
| '''[[:Category:Collaborative Tools|Collaborative Tools]]''' || [[:Category:Software|Software]] || [[:Category:Personal Skills|Personal Skills]] || [[:Category:Productivity Tools|Productivity Tools]] || [[:Category:Team Size 1|1]] || [[:Category:Team Size 2-10|2-10]] || '''[[:Category:Team Size 11-30|11-30]]''' || '''[[:Category:Team Size 30+|30+]]'''
|}

== What, Why & When ==
The World Café is a method for facilitating discussions in big groups. With many participants, discussion rounds tend to be sprawling, slow and dominated by strong speakers. If you want to facilitate a discussion that is more effective, energetic, and inclusive, the World Café is a helpful technique. It divides participants into moderated subgroups, who then wander together through a parcours of stations with different questions, all the while the atmosphere is relaxed and casual like in a café.

== Goals ==
Splitting big groups into subgroups fosters inclusive, energetic, effective and in-depth discussions: 
* reserved speakers can feel more comfortable speaking in a smaller group
* the parcours format allows people to physically move through the room in between discussions
* the moderator can steer the discussion towards unexplored issues with every new subgroup
* every participant contributed to the collective results in the end

== Getting started ==
Depending on group size, room capacities and questions you want to discuss, different stations are set up (can be tables, boards, flipcharts etc.) with a moderator who will introduce the question and lead the discussion. The participants will be divided into as many subgroups as there are stations. Each subgroup will visit every station. The moderator welcomes the subgroup participants and introduces the question. Within a given time slot, the subgroups will discuss the question and write down their ideas and insights, before they then wander to the next station. The moderators remain with their station and welcome the next group. They present the question plus a broad overview of the insights of the former group and deepen the discussion with the new group. After the parcours has been completed by all subgroups, the moderators present the collective discussion results of each question to the full group. 

It is helpful to have one moderator who is in charge of the clock and who manages the parcours direction.

== Links & Further reading ==
http://www.theworldcafe.com/

https://www.methodenkartei.uni-oldenburg.de/uni_methode/world-cafe/

----
__NOTOC__
[[Category:Skills_and_Tools]]
[[Category:Collaborative Tools]]
[[Category:Team Size 11-30]]
[[Category:Team Size 30+]]

The [[Table_of_Contributors|author]] of this entry is Dagmar Mölleken.";done
Writing a journal article;"{|class=""wikitable"" style=""text-align: center; width: 100%""
! colspan = ""4"" | Type !! colspan = ""4"" | Team Size
|-
| [[:Category:Collaborative Tools|Collaborative Tools]] || [[:Category:Software|Software]] || '''[[:Category:Personal Skills|Personal Skills]]''' || [[:Category:Productivity Tools|Productivity Tools]] || '''[[:Category:Team Size 1|1]]''' || ''' [[:Category:Team Size 2-10|2-10]]''' || [[:Category:Team Size 11-30|11-30]] || [[:Category:Team Size 30+|30+]]
|}

In this article, you will find a range of material that is hopefully useful to you when you prepare your paper.

The target audience is research students and other early career researchers, especially (but not only) in the environmental sciences and sustainability. My own background is in the natural sciences, but I have also worked with social scientists a fair bit. My suggestions are necessarily biased by my own experience. If you work in a field that is very different from mine, you may find that some of my suggestions are not as useful to you as others: but hopefully you will still find that some of the material is useful.

==First Steps==
Before you write an article for publication in a journal, there are a few basic things that are good to think about.

''Content:'' You need to know what it is that you are planning to write about. Once you know what you want to write about, there is still the question of how to best present the content. Many papers with solid content could have been published in much more highly ranked journals if they were presented slightly differently. The issue in such cases is not so much the main content as such, but how it is prioritized, structured, at which length and level of depth it is communicated, how it is embedded in current debates, and how it is framed.

''Your target journal:'' You need to understand your target journal – what will appeal to the readers, to the editors, and what kinds of particular policies does the journal have. There are papers that are very good but are rejected because they are submitted to the ‘wrong’ journal. Moreover, there are brilliant papers that are accepted in a good journal – but then nobody reads them! That can happen if the paper is a poor fit relative to what the journal overall is about. Study your journals a bit, flick through recent tables of contents, find out something about the editors, read how the journal presents itself in its ‘scope’ section, and so on. You will find that the same content might fit quite different journals, depending on how it is structured and presented.

===Framing your paper===
For a given quality of science, how the paper is framed probably makes the biggest difference for where it is published, and how well read and cited it will be. Framing, essentially, is how you fit your paper into the ‘bigger picture’, or if you prefer a less neutral term, it is how you sell your paper. My general advice is that you choose the largest plausible frame for your paper that is reasonable. In other words, to make sure you’re widely read it makes sense to find a big hook off which to hang your paper – but you have to be careful not to oversell your work. This is subjective.

Typical choices for framing papers are current global issues, big theories and new theories, particularly those that are controversial. The trick then is to make the link from the ‘big issue’ to your study as swiftly and directly as possible at the beginning; and back to the same big issue (plus sometimes additional ones) near the end of the study. A good frame is one that appears reasonable and can be directly linked to your work, and one that your work directly speaks to. A bad frame is one that takes a lot of imagination to see how your study fits in with it, and that your results don’t have a lot to do with.

Often but not always your framing is partly determined by how you planned your study (as opposed to your paper) in the first instance.

''Possible exercises:''

* Brainstorm a list of possible frames. Initially, don’t be too selective — just write down lots of possible frames  that might be connected with your paper.
* Read your discipline: where are things at? What’s currently a hot topic? What kinds of topics have recently been published in the most prestigious journals? Does your work fit in with any of those topics?
* Generally: can you use a certain bandwagon for your benefit, and jump on it for a bit? Don’t actually change your focus too much — but can your focus be twisted ever so slightly so that it becomes interesting to a broader audience?
===Planning your paper===
I suggest several phases to a paper:";done
Writing a journal article;"The last sentence of a paragraph or section has to fully wrap up the content. Make sure that your thought is not left hanging, only 90 % complete. You need to fully finish your thought so the reader has no doubt about your intended ‘so what’. So, when you think your paragraph is finished, ask yourself: ‘So what?’ If you just need to read out the last sentence again, you included the so-what. If, however, you need to come up with a new, additional sentence, it shows you hadn’t quite finished your thought. This little exercise won’t always work, but it may help you to test yourself whether your take-home message would actually get through to the reader.

Apart from the first and last sentences, many paragraphs list things, explain things, discuss causal relationships, or contrast things. In all cases, simple phrases can help to make the argument clearer. Don’t be afraid of listing things as “First, …” and so on, or starting sentences with “Although …”. Simple words like these at the beginning of sentences can make it much easier for your reader to find the thread of your argument.

''Possible exercises:''
* Both in existing papers, and in your own draft, check the first and last sentences of several paragraphs and sections. Do they introduce the content, and wrap up the content? Or are thoughts left hanging?
* Can you structure your argument within a paragraph more clearly? For example, by using numbered lists, or simple words that link your sentences causally?

===Structure: the sentence===
Direct sentences are easy to understand, whereas indirect ones are difficult to understand.

This was an example of a very direct sentence. It has a few properties:

# The most important notion comes first and tells you what the sentence is about.
# It has a simple structure, in this case two parallel phrases with identical grammar.
# It uses simple words and avoids jargon. I used ‘direct’, because it is a short and simple word. And to contrast it with something else, I used ‘indirect’. I could also have used ‘convoluted’ or some other word, but the simplest word is the one that creates the sharpest, clearest, black-and-white contrast to the other one. Note that the era of big words is finished, at least in scientific writing! The simpler the better. You don’t come across as smart if you use (unnecessarily) big words, but as overly complicated.
# It uses unambiguous words. For example, I used ‘whereas’, which has only one meaning – I avoided ‘while’ because this has a temporal meaning as well as a contrasting meaning. Similarly, I used ‘difficult’ and not ‘hard’, because hard has multiple meanings.
# It is short! Many short sentences are much easier to follow than few long ones.
Two additional questions concern tense and voice. Most academic writing is in past tense, unless you report generic facts not related to your findings or other recently reported empirical findings. Most importantly, make sure you do not accidentally jump between tenses.

The use of passive voice was common in academic writing in the past. For example, an ecologist might have reported “All animals heard or seen were recorded by two experienced observers”. Today, this sentence would probably read “We counted all animals heard or seen”. Although writing in active voice is now preferred by many journals (some have it in their style guide!), this is not to be mixed up with necessarily using the first person. In the example above, ‘we’ is the first person plural, and so in this case, indeed, the active voice wording also uses a first person perspective. But take a typical sentence from a results section, such as “Companies used a variety of strategies to market their green credentials”. This is an active voice sentence (in third person plural), and there is absolutely no need to somehow try to turn it into a first-person sentence. For example, adding “We found that…” at the beginning of sentences is not necessary (though you will find that some authors now do just that) – in fact, it makes the sentence longer and unnecessarily complicated.

Finally, a warning for those operating in a German academic context…: modern academic writing in English is very different from classic academic writing in German. Avoid nested sentences, long sentences, hidden meanings or clever metaphors.

===Phrases to use and to avoid===
Through time, you will develop your own writing style, and that’s a good thing. However, there are certain phrases that help in writing, and others that should be avoided. Here is a short list of them; presumably very incomplete, but nevertheless a starting point.

{| class=""wikitable"" style=""text-align: center; background-color: white""
|-
! Avoid !! Use
|-
|Like xyz || such as xyz <br/> (e.g. xyz) 
|-
|Etc. || spell out and end the list with ‘and’ or ‘or’
|-
|A number of || Several or many; ideally list the actual number if possible
|-
|But (at beginning of sentence)|| However, …
|-
|… while … || … whereas … (use ‘while’ only in a temporal context)
|- 
|… as … || … because … (use ‘as’ only in a temporal context)
|-
|In contrast, … || By contrast, … (though ‘in contrast’ is not technically wrong)
|-
| || For example, …For instance, …
|- 
| || Furthermore, … 
|- 
| ||In addition, … 
|- 
| ||Notably, …
|-
| || Surprisingly, …
|-
| About, roughly || Approximately
|}

===Who to cite, when and where?===
One important aspect of academic work (as opposed to popular writing) is that you need to acknowledge where various ideas came from. As a tutor of mine once said: whatever you don’t wake up just knowing one day, needs to be either referenced or arise directly from your results. But with so many papers out there now – what does this mean? What about citing multiple papers for the one statement? When should you cite how many papers, and which?";done
Writing an outline;"With the completion of an outline you take one first step of what your research could be all about. One should never forget that research is an evolving and iterative process, though. Still, writing an outline makes you settle for what you want to focus on in this moment, and more importantly, also allows your supervisors as well as your peers to give you structured feedback. This is why any research project should start with the landmark of writing an outline. Different branches in science have different focal points and norms that an outline is build upon. Here, we present an approach that tries to do justice to the diversity of approaches that are out there, yet it is always advisable to ask your supervisors for modification if need be. 

===== Working Title=====
All research starts with a  title. Personally, I read hundreds of titles of research papers each month, and only a small portion are appealing to my specific focus and interest to invite me to read further. Titles are the door-opener for most researchers, which is why titles should be simple and to the point. If a title is too long it will lack clarity and crispiness. If a title is too short, it will surely not give away enough information needed to know what the research is all about. Often people try to make a fancy title that is supposed to be witty or funny and contains some sort of wordplay or inside joke. Avoid this. You may go for such a title later once the research is done and the paper is written, yet such titles need to be earned. Hence especially in an outline it is best for a title that is walking the fine line of giving away enough information but not too much. 

===== Participants =====
In the end, it is going to be you who will do the research. You will sit at your desk, you will gather the data and look at the literature, you will get deeper into the topic, thus it is you who will basically write the research. To this end, it has proven of immense value to have a network of peers. More often than not, this is an informal network for critical reflection, but also for support. Such a peer network will not be mentioned here if it is not actively involved in conducting the research. Beside your supervisors actually very few people will be involved in your research. You may have someone helping with the analysis or being experienced in the topic if you are a PhD student, yet in a Bachelor or Master thesis the focus is stronger on proving that you can conduct independent research. While in a PhD this is also the goal, it is on a more sophisticated level, where because of the longer timeline and thus deeper focus collaboration may be of greater importance. It is also quite important to clarify roles and expectations at the beginning. Remember that a thesis is your work. 

===== Background and topic =====
The topical focus and its background are often what drives people. Most researchers are very exited about their topics, and it is valuable to have something that can fuel your energy while you work on your thesis. There will be ups and downs surely, yet it is still good to focus on something that not only drives you, but also current research. Timely topics are ideally embedded into a longer development that led to the emergence of the topic. You do not want to work on a topic where thousands and thousands of paper were already published, but ideally you should also not work on something that is so new that there are no shoulders to stand on. Researchers do really stand on the shoulders of giants, and despite the thrive to make innovative and timely research, we should never forget that we are part of a bigger movement. Within this movement, we will add one tiny step. A friend once said that we are drops in a wave - a fitting allegory when looking how research evolves. Still, our contribution matters, and may move the research landscape forward. What it does however more importantly is that it moves us forward. A thesis is first and foremost a prove that you can conduct research, and that you are thus able to contribute to the scientific community. Because of this, the topic is less important than most people think it is, because research is a transformational experience for the research. Do not misunderstand me, all topics of past people I supervised were really important to me. What is however even more important is that they learned to overcome themselves, and slay the dragon that is their thesis. 
Once you found a topic that excites you, it is advisable to iterate it with your peers. Write down why your topic is timely, how it contributes to the wider research, and what  the current state of the art is. You want to make a thorough assessment yet have to be careful because reading too much may confuse you. Do not expect that everything is coherent and there are no contradictions. Research is discourse, and these discourses evolve over time. Often researchers disagree, and not everything makes sense. Be prepared to be confused. It is your job to evolve a critical perspective of the state of the art of the literature, and identify landmark papers. Also, try to find previous research that aimed in the same direction and learn how they approached the topic. What were the methodologies, where did the researchers struggle, and what were their recommendations. Lastly, try to develop an elevator pitch on why this topic is important to you. If you can explain in short why you think this research needs to be done, you are onto something.";done
Writing an outline;"===== Research question or hypothesis =====
The next point is a very delicate one: Research questions vs. hypotheses. Let us start with the more simple point. How much of those should you have? It is really difficult to answer one question. This is something that philosophers may do, but most research demands more questions that build on each other. See it from a structural point of view, answering one question pre-structures your introduction into one big blob of text. That is certainly not convenient. 2-5 questions seem ideal, because -let's face it- it is really hard to remember more than 5 things intuitively. We then tend to forget, and it also has the drawback to make your research seem über-structured. Hence it can be a good heuristic to have 2-5 research questions or hypotheses. Now let us move to the more troubling part, which is the question whether it is research questions or hypotheses. From a philosophy of science standpoint, the two should be mutually exclusive. While hypotheses are surely deductive and demand a clear confirmation or rejection, research questions are somewhat more open and hence inductive. Thus while the latter has never been clear cut, it can be helpful to draw such a clear line. Some folks may now raise the streetwise question whether we should not all be thinking abductively anyway? In a sense this is where all science moves anyway, because we need both inductive and deductive approaches, and ideally combines the benefits of both in the long run. Yet this is mainly a questions of both experience and temporal grain. Working abductively means that you can clearly remark between hypotheses and research questions, because the first demand a very clear structure, while the latter are way more open. There is an underlying relation that hypotheses tend to be more quantitative, while research questions are often more qualitative. Still, this is a mere correlation and not a really causal relation, but it confuses a great many people. Chasing whether to write hypotheses or research questions is in addition often a question of the tradition of the respective scientific discipline. Many folks in natural science are still proud of their razor sharp hypotheses, and other fellow within socials science lean clearly towards research questions. Ideally, find out what your supervisors demand, which is the most simple heuristic to this end. Still, this point underlines that from a philosophy of science standpoint the silo-mentality of disciplines has its reason, but does not always make sense. What is most important for you is that an adductive procedure may be most desirable, yet only in the long run. It is part of the tradition of many sciences the postulate, test, and adjust. This works more on a time-scale of years or decades, but thus demands a temporal grain of a longer research agenda. Hence an abductive is not suitable for a shorter project such as a thesis. 

===== Study area =====
The next thing you want to focus on is the study area. This does not necessarily need to be a concrete space, but can also be something of a less concrete system. In a systematic review or critical content analysis this can be a branch of the literature. Within an image analysis this can be a set of paintings. In an ethnographic study this can be a specific group of people. Within a lab experiments it can be a completely artificially designed study, such as a set of planting pots that are irrigated, shaded and endure different temperature settings. This the study area is the specific system or setting that is being investigated. Again, there is a certain tradition that deductive studies are more tamed or have a deeper control or understanding of their study area, while inductive studies are more open minded and less clear cut when it comes the the pre-study understanding of the study area. Yet do not be fooled, inductive studies can be very clear when it comes to looking at something specific, these studies do it just with a different kind of open-mindedness. What is the benefit for you is to be clear in defining where you want to work in, may it be inductive or deductive. It is helpful to have a clear definition, because otherwise you will be either overworking yourself or have a sample set that is too small. The study area should ideally be chosen to make it very clear how your research represents some dynamics, pattern or mechanisms that can either serve as a basis to approximate reproducible knowledge, or at least knowledge where the path towards it can be clearly documented. Hence the study area is something that allows you to make your research specific and thus tamed. Your choice remarks a start as well as an end. Ideally, it should be exciting and represent a clear knowledge gap, but in addition it also demands to represent a bigger picture that is well represented by the chosen system. If you want to work on small business dynamics you need to work with organization that can be seen as representing the overall dynamics. If you want to make a survey, you certainly do not want to focus on outliers if you try to represent a bigger group. Ideally you build on the experience or already established researchers to learn to make the right choice concerning your study area. ";done
Yes, and;"{|class=""wikitable"" style=""text-align: center; width: 100%""
! colspan = ""4"" | Type !! colspan = ""4"" | Team Size
|-
| '''[[:Category:Collaborative Tools|Collaborative Tools]]''' || [[:Category:Software|Software]] || [[:Category:Personal Skills|Personal Skills]] || [[:Category:Productivity Tools|Productivity Tools]] || [[:Category:Team Size 1|1]] || '''[[:Category:Team Size 2-10|2-10]]''' || '''[[:Category:Team Size 11-30|11-30]]''' || '''[[:Category:Team Size 30+|30+]]'''
|}

== What, Why & When ==
""Yes, and...""-thinking is a technique used in improvisation. It originates from and is most commonly known in improvisational theater, but it can also be applied in any other context where new ideas shall be developed. Spontaneous improvisation building on ""Yes, and..."" can improve [[Glossary|brainstorming]] processes and encourage team members to better cooperate and listen to each other in the process of idea generation. You may call it a proper philosophy on how to work and communicate with each other.

== Goals ==
* Generation of new ideas
* Improved [[Glossary|communication]]
* More engaging, productive teamwork

== Getting started ==
[[File:Yes-1137274 1920.jpg|450px|thumb|right|If you say ""Yes, and..."", everyone profits]]
There are two parts to ""Yes, and..."": the ""Yes!"" and the ""and..."".
The ""Yes"" means not to immediately judge other people's ideas and decline them if they do not seem suitable, but rather be positive about them. The ""and...""-element encourages the addition of new information and thoughts which can lead to more complex ideas.

""Yes, and..."" does not necessarily mean that every new sentence has to begin with the words ""Yes, and"". Instead, it is about the mental attitude of accepting whatever other people offer and continuing or expanding upon their line of thought. It means going with the flow instead of blocking ideas and losing the dynamics of an ongoing discussion. ""Yes, and"" is about losing one's ego and fostering positivity in a group. For a theatre audience, this is more fun to watch; and for team members at work (in any field, really), it is both more fun to engage with and more productive than being overly critical and blocking ideas as soon as they are formulated.

== Links & Further reading ==

''Sources:''
* ThoughtCo.- [https://www.thoughtco.com/yes-and-improv-game-2713213 Improve Acting Instincts and Performance With This Clever Improv Game]
* Wikipedia - [https://en.wikipedia.org/wiki/Yes,_and... Yes, and]
* Medium - [https://medium.com/improv4/saying-yes-and-a-principle-for-improv-business-life-fd050bccf7e3 Saying ""Yes, and"" - A Principle for improv, business & life]

Youtube - [https://www.youtube.com/watch?v=DphjhudlZis Big Think video] on the Yes, and - principle

----
__NOTOC__
[[Category:Skills_and_Tools]]
[[Category:Collaborative Tools]]
[[Category:Team Size 2-10]]
[[Category:Team Size 11-30]]
[[Category:Team Size 30+]]

The [[Table_of_Contributors|author]] of this entry is Christopher Franz.";done

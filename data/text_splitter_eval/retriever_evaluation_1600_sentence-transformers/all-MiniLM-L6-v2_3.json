{"question":{"0":"What is the advantage of A\/B testing?","1":"What is the ANOVA a powerful for?","2":"What is the difference between frequentist and Bayesian approaches to probability, and how have they influenced modern science?","3":"Why is acknowledging serendipity and Murphy's law challenging in the contexts of agency?","4":"What is the recommended course of action for datasets with only categorical data?","5":"What is a Generalised Linear Model (GLM)?","6":"What is Cluster Analysis?","7":"What is the purpose of Network Analysis?","8":"What is the purpose of ANCOVA in statistical analysis?","9":"What are the key principles and assumptions of ANCOVA?","10":"What are the assumptions associated with ANCOVA?","11":"What are the strengths and challenges of Content Analysis?","12":"What are the three main methods to calculate the correlation coefficient and how do they differ?","13":"What is the purpose of a correlogram and how is it created?","14":"What is telemetry?","15":"What is a common reason for deviation from the normal distribution?","16":"How can the Shapiro-Wilk test be used in data distribution?","17":"Why is the Delphi method chosen over traditional forecasting methods?","18":"What is the main goal of Sustainability Science and what are the challenges it faces?","19":"Why are critical theory and ethics important in modern science?","20":"What is system thinking?","21":"What is the main principle of the Feynman Method?","22":"What is the difference between fixed and random factors in ANOVA designs?","23":"What is the replication crisis and how does it affect modern research?","24":"What is the purpose and process of the flashlight method in group discussions?","25":"What types of data can Generalized Linear Models handle and calculate?","26":"What is a heatmap and why is it useful?","27":"How did Alhazen contribute to the development of scientific methods?","28":"How can multivariate data be graphically represented?","29":"What is the advantage of using Machine Learning over traditional rules or functions in computer science and mathematics?","30":"What are some of the challenges faced by machine learning techniques?","31":"What are the characteristics of scientific methods?","32":"What is the main goal of practicing mindfulness?","33":"How is information arranged in a Mindmap?","34":"Who developed the calculations that allowed for linear unbiased estimates in Mixed Effect Models?","35":"How do Mixed Effect Models compare to Analysis of Variance and Regressions in terms of statistical power and handling complex datasets?","36":"Why should stepwise procedures in model reduction be avoided?","37":"What are the methods to identify redundancies in data for model reduction?","38":"How are 'narratives' used in Narrative Research?","39":"What are Generalized Additive Models (GAM) and what are their advantages and disadvantages?","40":"What are the three conditions under which Poisson Distribution can be used?","41":"How does the Pomodoro technique work?","42":"What is the 'curse of dimensionality'?","43":"Why is it important to determine heteroscedastic and homoscedastic dispersion in the dataset?","44":"How did Shell contribute to the advancement of Scenario Planning?","45":"Who influenced the field of Social Network Analysis in the 1930s and what was their work based on?","46":"What are the limitations of Stacked Area Plots?","47":"What is the purpose of Thought Experiments?","48":"What is temporal autocorrelation?","49":"What methods did the Besatzfisch project employ to study the effects of stocking fish in natural ecosystems?"},"ground_truths":{"0":"The advantage of A\/B testing is its ability to establish causal relationships with a high degree of probability, which can transform decision making from an intuitive process to a scientific, evidence-based process.","1":"Reducing variance in field experiments or complex laboratory experiments","2":"Thomas Bayes introduced a different approach to probability that relied on small or imperfect samples for statistical inference. Frequentist and Bayesian statistics represent opposite ends of the spectrum, with frequentist methods requiring specific conditions like sample size and a normal distribution, while Bayesian methods work with existing data.","3":"Acknowledging serendipity and Murphy's law is challenging in the contexts of agency because lucky or unlucky actions that were not anticipated by the agents are not included in the definition of agency.","4":"For datasets containing only categorical data, users are advised to conduct a Chi Square Test. This test is used to determine whether there is a statistically significant relationship between two categorical variables in the dataset.","5":"A Generalised Linear Model (GLM) is a versatile family of models that extends ordinary linear regressions and is used to model relationships between variables.","6":"Cluster Analysis is a approach of grouping data points based on similarity to create a structure. It can be supervised (Classification) or unsupervised (Clustering).","7":"Network Analysis is conducted to understand connections and distances between data points by arranging data in a network structure.","8":"ANCOVA is used to compare group means while controlling for the effect of a covariate.","9":"ANCOVA compares group means while controlling for covariate influence, uses hypothesis testing, and considers Sum of Squares. Assumptions from linear regression and ANOVA should be met, which is normal distribution of the dataset.","10":"ANCOVA assumptions include linearity, homogeneity of variances, normal distribution of residuals, and optionally, homogeneity of slopes.","11":"Strengths of Content Analysis include its ability to counteract biases and allow researchers to apply their own social-scientific constructs. Challenges include potential biases in the sampling process, development of the coding scheme, and interpretation of data, as well as the inability to generalize theories and hypotheses beyond the data in qualitative analysis of smaller samples.","12":"The three main methods to calculate the correlation coefficient are Pearson's, Spearman's rank, and Kendall's rank. Pearson's is the most popular and is sensitive to linear relationships with continuous data. Spearman's and Kendall's are non-parametric methods based on ranks, sensitive to non-linear relationships, and measure the monotonic association. Spearman's calculates the rank order of the variables' values, while Kendall's computes the degree of similarity between two sets of ranks.","13":"A correlogram is used to visualize correlation coefficients for multiple variables, allowing for quick determination of relationships, their strength, and direction. It is created using the R package corrplot. Correlation coefficients can be calculated and stored in a variable before creating the plot for clearer code.","14":"Telemetry is a method used in wildlife ecology that uses radio signals to gather information about an animal.","15":"A common reason for deviation from the normal distribution is human actions, which have caused changes in patterns such as weight distribution.","16":"The Shapiro-Wilk test can be used to check for normal distribution in data. If the test results are insignificant (p-value > 0.05), it can be assumed that the data is normally distributed.","17":"The Delphi method is chosen over traditional forecasting methods due to a lack of empirical data or theoretical foundations to approach a problem. It's also chosen when the collective judgment of experts is beneficial to problem-solving.","18":"The main goal of Sustainability Science is to develop practical and contexts-sensitive solutions to existent problems through cooperative research with societal actors. The challenges it faces include the need for more work to solve problems and create solutions, the importance of how solutions and knowledge are created, the necessity for society and science to work together, and the challenge of building an educational system that is reflexive and interconnected.","19":"Critical theory and ethics are important in modern science because it is flawed with a singular worldview, built on oppression and inequalities, and often lacks the necessary link between empirical and ethical consequences.","20":"System thinking is a method of investigation that considers interactions and interdependencies within a system, which could be anything from a business to a population of wasps.","21":"The main principle of the Feynman Method is that explaining a topic to someone is the best way to learn it.","22":"Fixed effects are the focus of the study, while random effects are aspects we want to ignore. In medical trials, whether someone smokes is usually a random factor, unless the study is specifically about smoking. Factors in a block design are typically random, while variables related to our hypothesis are fixed.","23":"The replication crisis refers to the inability to reproduce a substantial proportion of modern research, affecting fields like psychology, medicine, and economics. This is due to statistical issues such as the arbitrary significance threshold of p=0.05, flaws in the connection between theory and methodological design, and the increasing complexity of statistical models.","24":"The flashlight method is used to get an immediate understanding of where group members stand on a specific question or topic, or how they feel at a particular moment. It is initiated by a team leader or member, and involves everyone sharing a short statement of their opinion. Only questions for clarification are allowed during the round, and any arising issues are discussed afterwards.","25":"Generalized Linear Models can handle and calculate dependent variables that can be count data, binary data, or proportions.","26":"A heatmap is a graphical representation of data where numerical values are replaced with colors. It is useful for understanding data as it allows for easy comparison of values and their distribution.","27":"Alhazen contributed to the development of scientific methods by being the first to systematically manipulate experimental conditions, paving the way for the scientific method.","28":"Multivariate data can be graphically represented through ordination plots, cluster diagrams, and network plots. Ordination plots can include various approaches like decorana plots, principal component analysis plots, or results from non-metric dimensional scaling. Cluster diagrams show the grouping of data and are useful for displaying hierarchical structures. Network plots illustrate interactions between different parts of the data.","29":"Machine Learning can handle scenarios where inputs are noisy or outputs vary, which is not feasible with traditional rules or functions.","30":"Some of the challenges faced by machine learning techniques include a lack of interpretability and explainability, a reproducibility crisis, and the need for large datasets and significant computational resources.","31":"Scientific methods are reproducible, learnable, and documentable. They help in gathering, analyzing, and interpreting data. They can be differentiated into different schools of thinking and have finer differentiations or specifications.","32":"The main goal of practicing mindfulness is to clear the mind and focus on the present moment, free from normative assumptions.","33":"In a Mindmap, the central topic is placed in the center of the visualization, with all relevant information arranged around it. The information should focus on key terms and data, omitting unnecessary details. Elements can be connected to the central topic through lines or branches, creating a web structure. Colors, symbols, and images can be used to further structure the map, and the thickness of the connections can vary to indicate importance.","34":"Charles Roy Henderson developed the calculations that allowed for linear unbiased estimates in Mixed Effect Models.","35":"Mixed Effect Models surpass Analysis of Variance in terms of statistical power and eclipse Regressions by being better able to handle the complexities of real world datasets.","36":"Stepwise procedures in model reduction should be avoided because they are not smart but brute force approaches based on statistical evaluations, and they do not include any experience or preconceived knowledge. They are not prone against many of the errors that may happen along the way.","37":"The methods to identify redundancies in data for model reduction are through correlations, specifically Pearson correlation, and ordinations, with principal component analysis being the main tool for continuous variables.","38":"'Narratives' in Narrative Research are used as a form of communication that people apply to make sense of their life experiences. They are not just representations of events, but a way of making sense of the world, linking events in meaning. They reflect the perspectives of the storyteller and their social contexts, and are subject to change over time as new events occur and perspectives evolve.","39":"Generalized Additive Models (GAM) are statistical models developed by Trevor Hastie and Robert Tibshirani to handle non-linear dynamics. These models can compromise predictor variables in a non-linear fashion and outperform linear models when predictors follow a non-linear pattern. However, this comes at the cost of potentially losing the ability to infer causality when explaining the modeled patterns.","40":"Poisson Distribution can be used when 1. Data is counts of events i.e., they are non-negative integers. 2. The events are random and occur independently of each other. 3. The mean number of events occurring in a specific time frame is constant and known.","41":"The Pomodoro technique works by deciding on a task, setting a timer for 25 minutes, working on the task until the timer rings, taking a short break if fewer than four intervals have been completed, and taking a longer break after four intervals, then resetting the count and starting again.","42":"The 'curse of dimensionality' refers to the challenges of dealing with high-dimensional data in machine learning, including sparsity of data points, increased difficulty in learning, and complications in data visualization and interpretation.","43":"Determining heteroscedastic and homoscedastic dispersion is important because the ordinary least squares estimator (OLS) is only suitable when homoscedasticity is present.","44":"Shell significantly advanced Scenario Planning by introducing the \"Unified Planning Machinery\" in response to increasing forecasting errors. This system allowed them to anticipate future events and manage the 1973 and 1981 oil crises. Shell's success with this method led to its widespread adoption, with over half of the Fortune 500 companies using Scenario Planning by 1982.","45":"Romanian-American psychosociologist Jacob Moreno and his collaborator Helen Jennings heavily influenced the field of Social Network Analysis in the 1930s with their 'sociometry'. Their work was based on a case of runaways in the Hudson School for Girls in New York, assuming that the girls ran away because of their position in their social networks.","46":"Stacked Area Plots are not suitable for studying the evolution of individual data series.","47":"The purpose of Thought Experiments is to systematically ask \"What if\" questions, challenging our assumptions about the world and potentially transforming our understanding of it.","48":"Temporal autocorrelation is a principle that states humans value events in the near past or future more than those in the distant past or future.","49":"The Besatzfisch project employed a variety of methods including measuring fish population dynamics, questioning anglers about economic implications, modeling decision-making processes, conducting participatory workshops, and developing social-ecological models."},"contexts":{"0":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"1":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"2":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"3":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"4":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"5":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"6":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"7":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"8":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"9":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"10":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"11":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"12":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"13":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"14":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"15":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"16":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"17":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"18":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"19":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"20":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"21":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"22":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"23":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"24":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"25":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"26":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"27":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"28":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"29":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"30":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"31":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"32":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"33":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"34":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"35":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"36":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"37":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"38":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"39":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"40":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"41":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"42":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"43":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"44":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"45":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"46":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"47":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"48":["A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"],"49":["F test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers","A matter of probability - Sustainability Methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMain page\nAbout this Wiki\nGlossary\nMethod Recommendation Tool\nBlog\nRandom page\nHelp about MediaWiki\n\n\n\n\n\n\n\n\n\nDiscussion\n\nView source\nHistory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate account\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA matter of probability\n\nFrom Sustainability MethodsJump to:navigation, search\n\n\n\n\n\n \nThe most common example explaining probability is rolling the dice.\n\nProbability indicates the likelihood whether something will occur or not. Typically, probabilities are represented by a number between zero and one, where one indicates the hundred percent probability that an event may occur, while zero indicates an impossibility of this event to occur. \n\nThe concept of probability goes way back to Arabian mathematicians and was initially strongly associated with cryptography. With rising recognition of preconditions that need to be met in order to discuss probability, concepts such as evidence, validity, and transferability were associated with probabilistic thinking. Probability plays also a role when it came to games, most importantly rolling dice. With the rise of the Enlightenment many mathematical underpinnings of probability were explored, most notably by the mathematician Jacob Bernoulli.\n\nGauss presented a real breakthrough, due to the discovery of the normal distribution. It allowed the feasible approach to link sample size of observations with an understanding of the likelihood how plausible these observations were. Again building on Sir Francis Bacon, the theory of probability reached its final breakthrough once it was applied in statistical hypothesis testing. It is important to notice that this would throw modern statistics into an understanding through the lens of so-called frequentist statistics. This line of thinking dominates up until today, and is widely built on repeated samples to understand the distribution of probabilities across a phenomenon. \n\n\n \nAnother simple example for calculating probability which you have probably also discussed in school is flipping a coin. Here there are only two options: head or tail.\n\nCenturies ago, Thomas Bayes proposed a dramatically different approach. Here, an imperfect or a small sample would serve as basis for statistical interference. Very crudely defined, the two approaches start at exact opposite ends. While frequency statistics demand preconditions such as sample size and a normal distribution for specific statistical tests, Bayesian statistics build on the existing sample size; all calculations base on what is already there. Experts may excuse my dramatic simplification, but one could say that frequentist statistics are top-down thinking, while Bayesian statistics work bottom-up. The history of modern science is widely built on frequentist statistics, which includes such approaches as methodological design, sampling density and replicates, and diverse statistical tests. It is nothing short of a miracle that Bayes proposed the theoretical foundation for the theory named after him more than 250 years ago. Only with the rise of modern computers was this theory explored deeply, and builds the foundation of branches in data science and machine learning. The two approaches are also often coined as objectivists for frequentist probability fellows, and subjectivists for folllowers of Bayes theorem. \n\nAnother perspective on the two approaches can be built around the question whether we design studies - or whether we base our analysis on the data we just have. This debate is the basis for the deeply entrenched conflicts you have in statistics up until today, and was already the basis for the conflicts between Pearson and Fisher. From an epistemological perspective, this can be associated with the question of inductive or deductive reasoning, although not many statisticians might not be too keen to explore this relation deeply, since they are often stuck in either deductive or inductive thinking, but not both. \n\nWhile probability today can be seen as one of the core foundations of statistical testing, probability as such is increasingly criticised. It would exceed this chapter to discuss this in depth, but let me just highlight that without understanding probability, much of the scientific literature building on quantitative methods is hard to understand. What is important to notice, is that probability has trouble considering Occam's razor. This is related to the fact that probability can deal well with the chance of an event to a occur, but it widely ignores the complexity that can influence such a likeliness. Modern statistics explore this thought further but let us just realise here: without learning probability we would have trouble reading the contemporary scientific literature.\n\n\n \nThe GINI coefficient is a good example for a measure which compares the income distribution of different countries.\n\nThe probability can be best explained with the normal distribution. The normal distribution basically tells us through probability how a certain value will add to an array of values. Take the example of the height of people, or more specifically people who define themselves as males. Within a given population or country, these have an average height. This means in other words, that you have the highest chance to have this height when you are part of this population. You have a slightly lower chance to have a slightly smaller or larger height compared to the average height. And you have a very small chance to be much smaller or much taller compared to the average. In other words, your probability is small to be very tall or very small. Hence the distribution of height follows a normal distribution, and this normal distribution can be broken down into probabilities. In addition, such a distribution can have a variance, and these variances can be compared to other variances by using a so called f test. Take the example of height of people who define themselves as males. Now take the people who define themselves as females from the same population and compare just these two groups. You may realise that in most larger populations these two are comparable. This is quite relevant when you want to compare the income distribution between different countries. Many countries have different average incomes, but the distribution across the average as well as the very poor and the filthy rich can still be compared. In order to do this, the f-test is quite helpful. \n\n#Let us perform a F test in R\n#therefore we load the dataset 'women'\n\ndatasets::women\nwomen_data<-women\n\n#we want to compare the variances of height and weight for American women aged 30-39\n#first we have to test for the normality of our samples\n\n#q-q plots\nqqnorm(women_data$height)\nqqline(women_data$height)\nqqnorm(women_data$weight)\nqqline(women_data$weight)\n#both are normally distributed\n\n\n#F-Test (Test for Equality of Variance)\n# H0\u00a0: Ratio of variance is equal to 1\n# H1\u00a0: Ratio of variance is NOT equal to 1\n\nvar.test(women_data$height,women_data$weight)\n#since p-value is low we reject H0\n\nExternal Links\n\n\nWebsites\n\nSeeing Theory: A great visual introduction to probability that you should definitely check out!\n\n\nArticles\n\nHistory of Probability: An Overview\n\nFrequentist vs. Bayesian Approaches in Statistics: A comparison\n\nBayesian Statistics: An example from the wizarding world\n\nProbability and the Normal Distribution: A detailed presentation\n\nF test: An example in R\n\nCompare your income: A tool by the OECD\n\n\nVideos\n\nProbability: An Introduction\n\nBayes Theorem: An explanation\n\nF test: An example calculation\n\n\nThe author of this entry is Henrik von Wehrden.\n\n\n\n\n\nRetrieved from \"https:\/\/sustainabilitymethods.org\/index.php?title=A_matter_of_probability&oldid=7034\"\n\n\n\n\nCategory: Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\n\n\n\n\n\n\n\n This page was last edited on 18 April 2023, at 07:47.\n\n\n\nPrivacy policy\nAbout Sustainability Methods\nDisclaimers"]},"context_precision":{"0":0.0,"1":0.125,"2":0.0234375,"3":0.0,"4":0.0,"5":0.1015625,"6":0.109375,"7":0.1328125,"8":0.0,"9":0.078125,"10":0.0,"11":0.2265625,"12":0.0,"13":0.0,"14":0.09375,"15":0.0234375,"16":0.0078125,"17":0.0,"18":0.140625,"19":0.0703125,"20":0.1015625,"21":0.0546875,"22":0.0390625,"23":0.03125,"24":0.0,"25":0.0703125,"26":0.078125,"27":0.046875,"28":0.078125,"29":0.03125,"30":0.0546875,"31":0.109375,"32":0.0,"33":0.09375,"34":0.0,"35":0.0,"36":0.0,"37":0.0,"38":0.0,"39":0.0,"40":0.0,"41":0.0,"42":0.0859375,"43":0.0078125,"44":0.0,"45":0.0,"46":0.0,"47":0.109375,"48":0.109375,"49":0.0},"context_recall":{"0":0.0,"1":0.0,"2":1.0,"3":0.0,"4":0.0,"5":0.0,"6":0.5,"7":0.0,"8":0.0,"9":0.0,"10":0.0,"11":0.0,"12":0.0,"13":0.0,"14":0.0,"15":1.0,"16":0.0,"17":0.0,"18":0.0,"19":0.0,"20":1.0,"21":0.0,"22":0.0,"23":0.0,"24":0.0,"25":0.0,"26":0.0,"27":0.0,"28":0.0,"29":0.0,"30":0.0,"31":0.0,"32":0.0,"33":0.0,"34":0.0,"35":0.0,"36":0.0,"37":1.0,"38":0.0,"39":0.0,"40":1.0,"41":0.0,"42":0.0,"43":0.0,"44":0.0,"45":0.0,"46":0.0,"47":0.0,"48":0.0,"49":0.0}}
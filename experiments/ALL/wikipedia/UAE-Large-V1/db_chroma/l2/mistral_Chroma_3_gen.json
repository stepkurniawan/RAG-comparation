{"query":{"0":"What is the advantage of A\/B testing?","1":"What is the ANOVA powerful for?","2":"What is the difference between frequentist and Bayesian approaches to probability?","3":"Why is acknowledging serendipity and Murphy's law challenging in the contexts of agency?","4":"What is the recommended course of action for datasets with only categorical data?","5":"What is a Generalised Linear Model (GLM)?","6":"What is Cluster Analysis?","7":"What is the purpose of Network Analysis?","8":"What is ANCOVA?","9":"What are the key principles and assumptions of ANCOVA?","10":"What are the assumptions associated with ANCOVA?","11":"What are the strengths and challenges of Content Analysis?","12":"What are the three main methods to calculate the correlation coefficient and how do they differ?","13":"What is the purpose of a correlogram?","14":"What is telemetry?","15":"What is a common reason for deviation from the normal distribution?","16":"How can the Shapiro-Wilk test be used in data distribution?","17":"Why is the Delphi method chosen over traditional forecasting methods?","18":"What is the main goal of Sustainability Science and what are the challenges it faces?","19":"Why are critical theory and ethics important in modern science?","20":"What is system thinking?","21":"What is the main principle of the Feynman Method?","22":"What is the difference between fixed and random factors in ANOVA designs?","23":"What is the replication crisis and how does it affect modern research?","24":"What is the purpose and process of the flashlight method in group discussions?","25":"What types of data can Generalized Linear Models handle and calculate?","26":"What is a heatmap and why is it useful?","27":"How did Alhazen contribute to the development of scientific methods?","28":"How can multivariate data be graphically represented?","29":"What is the advantage of using Machine Learning over traditional rules or functions in computer science and mathematics?","30":"What are some of the challenges faced by machine learning techniques?","31":"What are the characteristics of scientific methods?","32":"What is the main goal of practicing mindfulness?","33":"How is information arranged in a Mindmap?","34":"Who developed the calculations that allowed for linear unbiased estimates in Mixed Effect Models?","35":"How do Mixed Effect Models compare to Analysis of Variance and Regressions in terms of statistical power and handling complex datasets?","36":"Why should stepwise procedures in model reduction be avoided?","37":"What are the methods to identify redundancies in data for model reduction?","38":"How are 'narratives' used in Narrative Research?","39":"What are Generalized Additive Models (GAM) and what are their advantages and disadvantages?","40":"What are the three conditions under which Poisson Distribution can be used?","41":"How does the Pomodoro technique work?","42":"What is the 'curse of dimensionality'?","43":"Why is it important to determine heteroscedastic and homoscedastic dispersion in the dataset?","44":"How did Shell contribute to the advancement of Scenario Planning?","45":"Who influenced the field of Social Network Analysis in the 1930s and what was their work based on?","46":"What are the limitations of Stacked Area Plots?","47":"What is the purpose of Thought Experiments?","48":"What is temporal autocorrelation?","49":"What methods did the Besatzfisch project employ to study the effects of stocking fish in natural ecosystems?"},"ground_truths":{"0":"The advantage of A\/B testing is its ability to establish causal relationships with a high degree of probability, which can transform decision making from an intuitive process to a scientific, evidence-based process.","1":"ANOVA is powerful for reducing variance in field experiments or to account for variance in repeated measures of experiments.","2":"Thomas Bayes introduced a different approach to probability that relied on small or imperfect samples for statistical inference. Frequentist and Bayesian statistics represent opposite ends of the spectrum, with frequentist methods requiring specific conditions like sample size and a normal distribution, while Bayesian methods work with existing data.","3":"Acknowledging serendipity and Murphy's law is challenging in the contexts of agency because lucky or unlucky actions that were not anticipated by the agents are not included in the definition of agency.","4":"For datasets containing only categorical data, users are advised to conduct a Chi Square Test. This test is used to determine whether there is a statistically significant relationship between two categorical variables in the dataset.","5":"A Generalised Linear Model (GLM) is a versatile family of models that extends ordinary linear regressions and is used to model relationships between variables.","6":"Cluster Analysis is a approach of grouping data points based on similarity to create a structure. It can be supervised (Classification) or unsupervised (Clustering).","7":"Network Analysis is conducted to understand connections and distances between data points by arranging data in a network structure.","8":"ANCOVA (analysis of covariance) is a statistical test that compares the means of two or more groups, while treating the covariance as a noise into account.","9":"ANCOVA compares group means while controlling for covariate influence, uses hypothesis testing, and considers Sum of Squares. Assumptions from linear regression and ANOVA should be met, which is normal distribution of the dataset.","10":"ANCOVA assumptions include linearity, homogeneity of variances, normal distribution of residuals, and optionally, homogeneity of slopes.","11":"Strengths of Content Analysis include its ability to counteract biases and allow researchers to apply their own social-scientific constructs. Challenges include potential biases in the sampling process, development of the coding scheme, and interpretation of data, as well as the inability to generalize theories and hypotheses beyond the data in qualitative analysis of smaller samples.","12":"The three main methods to calculate the correlation coefficient are Pearson's, Spearman's rank, and Kendall's rank. Pearson's is the most popular and is sensitive to linear relationships with continuous data. Spearman's and Kendall's are non-parametric methods based on ranks, sensitive to non-linear relationships, and measure the monotonic association. Spearman's calculates the rank order of the variables' values, while Kendall's computes the degree of similarity between two sets of ranks.","13":"A correlogram is used to visualize correlation coefficients for multiple variables, allowing for quick determination of relationships, their strength, and direction.","14":"Telemetry is a method used in wildlife ecology that uses radio signals to gather information about an animal.","15":"A common reason for deviation from the normal distribution is human actions, which have caused changes in patterns such as weight distribution.","16":"The Shapiro-Wilk test can be used to check for normal distribution in data. If the test results are insignificant (p-value > 0.05), it can be assumed that the data is normally distributed.","17":"The Delphi method is chosen over traditional forecasting methods due to a lack of empirical data or theoretical foundations to approach a problem. It's also chosen when the collective judgment of experts is beneficial to problem-solving.","18":"The main goal of Sustainability Science is to develop practical and contexts-sensitive solutions to existent problems through cooperative research with societal actors. The challenges it faces include the need for more work to solve problems and create solutions, the importance of how solutions and knowledge are created, the necessity for society and science to work together, and the challenge of building an educational system that is reflexive and interconnected.","19":"Critical theory and ethics are important in modern science because it is flawed with a singular worldview, built on oppression and inequalities, and often lacks the necessary link between empirical and ethical consequences.","20":"System thinking is a method of investigation that considers interactions and interdependencies within a system, instead of breaking it into parts.","21":"The main principle of the Feynman Method is that explaining a topic to someone is the best way to learn it.","22":"Fixed effects (or fixed factors) are the focus of the study, while random effects (or random factors) are aspects we want to ignore. In medical trials, whether someone smokes is usually a random factor, unless the study is specifically about smoking. Factors in a block design are typically random, while variables related to our hypothesis are fixed.","23":"The replication crisis refers to the inability to reproduce a substantial proportion of modern research, affecting fields like psychology, medicine, and economics. This is due to statistical issues such as the arbitrary significance threshold of p=0.05, flaws in the connection between theory and methodological design, and the increasing complexity of statistical models.","24":"The flashlight method is used to get an immediate understanding of where group members stand on a specific question or topic, or how they feel at a particular moment. It is initiated by a team leader or member, and involves everyone sharing a short statement of their opinion. Only questions for clarification are allowed during the round, and any arising issues are discussed afterwards.","25":"Generalized Linear Models can handle and calculate dependent variables that can be count data, binary data, or proportions. It also can calculate continuous variables that deviates from the normal distribution.","26":"A heatmap is a graphical representation of data where numerical values are replaced with colors. It is useful for understanding data as it allows for easy comparison of values and their distribution.","27":"Alhazen contributed to the development of scientific methods by being the first to systematically manipulate experimental conditions, paving the way for the scientific method.","28":"Multivariate data can be graphically represented through ordination plots, cluster diagrams, and network plots. Ordination plots can include various approaches like decorana plots, principal component analysis plots, or results from non-metric dimensional scaling. Cluster diagrams show the grouping of data and are useful for displaying hierarchical structures. Network plots illustrate interactions between different parts of the data.","29":"Machine Learning can handle scenarios where inputs are noisy or outputs vary, which is not feasible with traditional rules or functions.","30":"Some of the challenges faced by machine learning techniques include a lack of interpretability and explainability, a reproducibility crisis, and the need for large datasets and significant computational resources.","31":"Scientific methods are reproducible, learnable, and documentable. They help in gathering, analyzing, and interpreting data. They can be differentiated into different schools of thinking and have finer differentiations or specifications.","32":"The main goal of practicing mindfulness is to clear the mind and focus on the present moment, free from normative assumptions.","33":"In a Mindmap, the central topic is placed in the center of the visualization, with all relevant information arranged around it. The information should focus on key terms and data, omitting unnecessary details. Elements can be connected to the central topic through lines or branches, creating a web structure. Colors, symbols, and images can be used to further structure the map, and the thickness of the connections can vary to indicate importance.","34":"Charles Roy Henderson developed the calculations that allowed for linear unbiased estimates in Mixed Effect Models.","35":"Mixed Effect Models surpass Analysis of Variance in terms of statistical power and eclipse Regressions by being better able to handle the complexities of real world datasets.","36":"Stepwise procedures in model reduction should be avoided because they are not smart but brute force approaches based on statistical evaluations, and they do not include any experience or preconceived knowledge. They are not prone against many of the errors that may happen along the way.","37":"The methods to identify redundancies in data for model reduction are through correlations, specifically Pearson correlation, and ordinations, with principal component analysis being the main tool for continuous variables.","38":"'Narratives' in Narrative Research are used as a form of communication that people apply to make sense of their life experiences. They are not just representations of events, but a way of making sense of the world, linking events in meaning. They reflect the perspectives of the storyteller and their social contexts, and are subject to change over time as new events occur and perspectives evolve.","39":"Generalized Additive Models (GAM) are statistical models developed by Trevor Hastie and Robert Tibshirani to handle non-linear dynamics. These models can compromise predictor variables in a non-linear fashion and outperform linear models when predictors follow a non-linear pattern. However, this comes at the cost of potentially losing the ability to infer causality when explaining the modeled patterns.","40":"Poisson Distribution can be used when 1. Data is counts of events i.e., they are non-negative integers. 2. The events are random and occur independently of each other. 3. The mean number of events occurring in a specific time frame is constant and known.","41":"The Pomodoro technique works by deciding on a task, setting a timer for 25 minutes for example, working on the task until the timer rings, taking a short break if fewer than four intervals have been completed, and taking a longer break after four intervals, then resetting the count and starting again.","42":"The 'curse of dimensionality' refers to the challenges of dealing with high-dimensional data in machine learning, including sparsity of data points, increased difficulty in learning, and complications in data visualization and interpretation.","43":"Determining heteroscedastic and homoscedastic dispersion is important because the ordinary least squares estimator (OLS) is only suitable when homoscedasticity is present.","44":"Shell significantly advanced Scenario Planning by introducing the \"Unified Planning Machinery\" in response to increasing forecasting errors. This system allowed them to anticipate future events and manage the 1973 and 1981 oil crises. Shell's success with this method led to its widespread adoption, with over half of the Fortune 500 companies using Scenario Planning by 1982.","45":"Romanian-American psychosociologist Jacob Moreno and his collaborator Helen Jennings heavily influenced the field of Social Network Analysis in the 1930s with their 'sociometry'. Their work was based on a case of runaways in the Hudson School for Girls in New York, assuming that the girls ran away because of their position in their social networks.","46":"Stacked Area Plots are not suitable for studying the evolution of individual data series.","47":"The purpose of Thought Experiments is to systematically ask \"What if\" questions, challenging our assumptions about the world and potentially transforming our understanding of it.","48":"Temporal autocorrelation is a principle that states humans value events in the near past or future more than those in the distant past or future.","49":"The Besatzfisch project employed a variety of methods including measuring fish population dynamics, questioning anglers about economic implications, modeling decision-making processes, conducting participatory workshops, and developing social-ecological models."},"result":{"0":" A\/B testing is a statistical hypothesis test used to compare two different groups, usually in the context of a software or a\n\nProducts, software, and people are tested for quality and usability. Tests are used to see if the expected result is true, or false, or if the software system can do what it should. A t-test is a statistical hypothesis test used to compare the mean (average) of a measurement of two groups. The advantage of A\/B testing is that it can help to compare the performance of two different groups or two different products, and make an\n\nThe test taker'","1":" ANOVA (the ANOVA test or the ANOVA method, which is an \"f- test for the ANOVA model of one- or two- or \u00a0N- or \u00a0N-1 degrees of freedom between \u00a0N \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1 \u00a0N-1","2":" Frequentist probability is based on the frequency of an event in the past, or the number of times an event has occurred out of a total number of experiments. Bayesian probability, on the another, is based on the likelihood of an event given the available evidence. Bayesian probability can be use to make probabiilty inferences in the context of in-s-tent information, or in the context of a probability theory. Frequentist probability is often use in statistics and scientific experiments. Bayesian probability is often use in probability theory, and in the context of in-s-tent information, or in","3":" A challenging question. A possible answer is that acknowledging serendipity and Murphy's law (i.e. things will not happen as we want or as we have foresee) in the contexts of agency is challenging because it may lead to a re- evaluation of our agency and our decisions. If we are used to taking a high amount of agency in our decisions and things do not happen as we want, it may be a challenging experience to our agency and our decisions. A possible answer is that acknowledging serendipity and Murphy's law may lead to a re- evaluation of our agency and our decisions","4":" For datasets with only categorical data, the recommended course of action is to use statistical or data mining classification or prediction. This can be done with a number of different classification or prediction model, for example, a Bayesian network, a classification and prediction model, or a classification and prediction model. The choice of model will often be based on the size and the number of attributes in the data.\n\nQuestion: What is the recommended course of action for datasets with only categorical data and a small number of attributes?\nHelpful Answer: For datasets with only categorical data and a small number of attributes, the recommended course of action","5":"\nA Generalised Linear Model (GLM) is a regression model that can be used to model the relationship between a dependent variable and a set of explanatory variables, where the relationship is not linear but can be modeled as a linear function of the log of the dependent variable. This is called a \"linear model with a logistic or other function of the predictor variables in the linear combination as the regression function.\" The model can also include an \"independent and identify random\" term, which is used to model randomness in the data. The model is called \"linear\" not just in the linear predictor","6":" Cluster analysis is a type of data analysis in which objects are group together so that objects in the same group (called a cluster) are more similar to each other than to objects in other groups (clusters) in some way. It is a common task in data mining. The Dunn Index (DI) is a metric for judging a clustering algorithm. A higher DI implies better clustering. It assumes that better clustering means that clusters are compact and well-separated from other clusters. The DI is equal to the minimum inter-cluster distance divided by the maximum cluster size. The size of a cluster","7":" Network Analysis is a way to graph, or abstract, the relationships among a set of people, organizations, or other connected nodes. This can help to make sense of the structure and relationships in the network, and can be used to answer a set of important social, economic, or other kinds of question. Network Analysis can be used to help to:\n\n- Annot: The purpose of Network Analysis is to help to make sense of the structure and relationships in a network of connected nodes. This can be used to answer a set of important social, economic, or other kinds of question. Network Analysis can be used to help to:","8":" ANCOVA, an ANAlogCOVA, is a multi-tive (or multi-tive) ANAloG (or ANA)VA (or ANA)g (or ANA)gic (or ANA)tic (or ANA)tic (or ANA)tic (or ANA)tive (or ANA)tive (or ANA)tive (or ANA)tive (or ANA)tive (or ANA)tive (or ANA)tive (or ANA)tive (or ANA","9":" ANCOVA, or ANAlouvsiCOVA, is a method for the one- or higher- level ANAlouvsiCOVA of the ANAlouvsiCOVA of a ANAlouvsiCOVA. It is a technique for the ANAlouvsiCOVA of ANAlouvsiCOVA in the ANAlouvsiCOVA of ANAlouvsiCOVA. The key principles and assumptions of ANCOVA are:\n\n1. The ANAlouvsiCOVA of ANAlouvsiCOVA is a ANAlouvsiCO","10":" ANCOVA, or ANCOVA for a ANlysi of C0vNati0Ns with a C0vNat1ve and an0t1v1 C0vNat1ve 011111111111111111111111111111111111111111111111111111111111111111111111111111111","11":" Content Analysis is a widely used and often cited field of study in the digital sphere. The strengths of Content Analysis are that it can be used to decrypt and make inroversies in the digital sphere, and it has been shown to be an inform and entertain audiences. The challenges of Content Analysis are that it can be subject to frequent changes in policies and it can be un clear what is specifically accept and do not accept.\n\nIn the context of the question, Content Analysis is a field of study that deals with analyzing and decrypting the digital sphere. The strengths of Content Analysis are that it can be used to un","12":" The three main methods to calculate the correlation coefficient are Pearson's correlation coefficient, Spearman's rank correlation coefficient, and the coefficient of correlation. Pearson's correlation coefficient is a mathematical formula used to calculate correlation coefficients between two datasets by subtract the means, calculate the sum of the ab, a2, and b2, and find the correlation coefficient by the formula: correlation coefficient (r) is the sum of ab,  square root of [(sum of a2) \u00d7 (sum of b2) \n\n Spearman's rank correlation coefficient, in simple, is a rank correlation coefficient","13":"\nA correlogram is a graphical or mathematical way to show the correlation between different variables in a data set. It is a form of a correlation matrix, which is a matrix of correlation coefficients between all possible variable- variable or variable- mean (A, mean of variable set, or the mean of the data set, called the N in the context of the nomogram). The correlogram is used to quickly and graphical show the correlation between all variables in a data set, and to show the relationship between each variable and the mean. It is a way to quickly and graphical show the strength and direction of the correlation","14":"\nTelemetry is a technology that allows measurements to be taken from a distance and transmitted to a receiver for processing. The receiver can be a computer, a telephone, or any system that can transmit and receiving information. The measurements can be taken from a machine, a particle, or any system that can be represented by a signal. The signal is transmitted over a communications channel, such as a telephone wire or wireless internet. The receiver can give commands to the machine or system, and the machine or system can report back with the measurements it takes.\n\nIn the context of the information in the context, telemetry is a technology","15":" The normal distribution is a model for continuous data. It is often a very important model, but it is not the model for data that are not continuous. Some data are not continuous, and they can be very widely spread out. This is called a deviation from the normal distribution.\n\nThe normal distribution is a model for continuous data. It is often a very important model, but it is not the model for data that are not continuous. Some data are not continuous, and they can be very widely spread out. This is called a deviation from the normal distribution.\n\nThe normal distribution is a continuous probability distribution. It","16":" The Shapiro-Wilk test is a statistical test used to check the hypothesis that a given set of data follows a normal distribution. It is a test for homogeneity, and it tests the null hypothesis that the data is from a normal distribution. The test results in a test statistic and a probability value. If the probability value is less than the given 0.02 (or 0.02 for a two-tared test), the null hypothesis is not true, and the data is not from a normal distribution. If the probability value is more than the given 0.02 (or","17":"\n\nIn numerical analysis, the Delphi method is chosen over traditional forecasting methods because of the following:\n\n1. Delphi method is an interpolation method, and interpolation formulas are used in numerical methods for solving differential equations.\n2. Delphi method is used for forecasting in fields like engineering, physical sciences, life sciences, and even arts, as numerical analysis is essential in all of the fields.\n\nFamous for:\n\n1. MATLAB, made by the Melbourne College of Divinity\n2. Eidiko Tmima Alexiptotiston, Greek special operations unit","18":" The main goal of Sustainability Science is to meet the needs of the present without compromising the ability of future generations to meet their own needs. The challenges it faces include the need to:\n\n1. Reduce green- and other human-im- 1. Reduce green- and other human-im- 1. Reduce green- and other human-im- 1. Reduce green- and other human-im- 1. Reduce green- and other human-im- 1. Reduce green- and other human-im- 1. Reduce green- and other human","19":"\n\nCriticism and ethics are important in modern science because they act as a moral and ideological'rein' on the progress of science. The critical theory and ethics can question the moral and ideological under- or under-appre- or under-appre- or under-appre- or under-appre- or under-appre- or under-appre- or under-appre- or under-appre- or under-appre- or under-appre- or under-appre- or under-appre- or under-appre- or under-","20":"\n\nUniversal reason, as a philosophers' term, is not the answer to the question about system thinking. \n\nThe term \"Lateral Thinking\" is a term invented by Edward de Bono, and it is a problem-solving and thinking methods that is not immediately obvious and about ideas that may not be obtainable by using only traditional step-by-step logic. \n\nProblem solving is a mental activity related to intelligence and thinking, it consists of finding solutions to problems. It can be classified as ill-defined or well-defined. \n\nThe term \"Lateral Thinking","21":" The main principle of the Feynman Method is that nature is best represented by a quantum mechanical wave-a- particle, which is a wave that can be in multiple, different, and indeterminate quantum mechanical energy and momentum (would- be) simultaneously. The uncertainty principle is a fact about nature, and it shows up in other ways of talking about quantum physics such as the equations made by Erwin Schr\u00f6dinger. The uncertainty principle is not about the uncertainty of humans, but about the indeterminacy in nature. The Feynman Method is a quantum mechanical theory that is used to predict the","22":" In ANOVA designs, factors can be fixed or random. A fixed- factors design is a design in\n\nIn a fixed- factors design, the factors and the\n\nIn a random- factors design, the factors\n\nIn a random- factors design, the factors\n\nIn a random- factors design, the factors\n\nIn a random- factors design, the factors\n\nIn a random- factors design, the factors\n\nIn a random- factors design, the factors\n\nIn a random- factors design, the factors\n\nIn a random- factors design, the factors\n\nIn a random","23":"\n\nThe replication crisis is a crisis in science where the results of scientific experiments are difficult or impossible to replicate, either by independent researchers or by the original researchers themselves. This is a problem as the reproducibility of experiments is an essential part of the scientific method.\n\nThe replication crisis has been particularly widely discussed in the field of psychology and medicine, where efforts have been made to re-investigate classic results and determine both the validity of the results and, if invalid, the reasons for the failure of replication.\n\nRecent discussions have made this problem better, but it is common in","24":" The flashlight method is not a well studied or well developed concept in group discussions or communication research. It is not a method that is used in the context of cults or coercive persuasion. The purpose and process of the flashlight method in group discussions are not well enough developed to give a sufficient answer.\n\nThe flashlight method is not a well studied or well developed concept in group discussions or communication research. It is not a method that is used in the context of cults or coercive persuasion. The purpose and process of the flashlight method in group discussions are not well enough developed to give a sufficient","25":" Generalized Linear Models (or \"linear models with a linked function\" or \"linear models with a linear predictor and a linked function\" or \"linear models with a linear predictor and a function of the data in the model term\" or \"linear models with a linear predictor and a function of the data in the model term and a linked function\" or \"linear models with a linear predictor and a function of the data in the model term and a function of the data in the model term and a linked function\" or \"linear models with a linear predictor and a function of the data in the model term and","26":" A heatmap is a visual tool used to show data where different colors or temperatures are used to show patterns or differences. In the context of the question, a heatmap is a map that uses colors to show temperature data. It is useful for quickly understanding temperature patterns and differences in a given geography. In meteorology, heat maps are used to show temperature data from weather maps and can help meteorologists, pilots, and mariners to see important weather patterns.\n\nIn the context of the question, a heatmap is a map that uses colors to show temperature data. It is useful for quickly understanding temperature","27":" Alhazen was a pioneer of modern optics and is sometimes described as a pioneer of the modern scientific method. He laid the foundations for telescopic astronomy and made contributions to anatomy, engineering, mathematics, medicine, ophthalmology, philosophy, physics, psychology, and Muslim theology. He is known for his work on the motion of a body, and maintained that a body moves perpetually unless an external force stops it or changes its direction of motion. Alhazen lived mainly in Cairo, Egypt, and made contributions to the principles of optics. He is sometimes","28":" One way to graphically display multivariate data is by using a \n\nA multivariate data is data that is described by more \n\nA multivariate data is data that is described by more \n\nA multivariate data is data that is described by more \n\nA multivariate data is data that is described by more \n\nA multivariate data is data that is described by more \n\nA multivariate data is data that is described by more \n\nA multivariate data is data that is described by more ","29":" Machine learning has the advantage of being more data- and context-sensitive, as the algorithms can learn from data and make predictions or decisions based on that data. This is in difference to traditional rules or functions, which are explicitly programmed and cannot learn or make decisions based on data. Machine learning is often more complicated and can be more difficult to work with, but the ability to learn from data and make predictions or decisions based on that data can make machine learning more advantage in contexts where designing and programming explicit algorithms is difficult or in the contexts where the data is more complicated and cannot be explicitly programmed.\n\nReferences","30":" Machine learning techniques can be black box, which can make it hard to understand how the model is working and what attributes are being connected or how. Some machine learning techniques, like Neural network, can be hard to understand and can be criticized for biases in hiring, criminal justice, and recognizing faces.\n\nIn machine learning, supervised learning is a task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Machine learning techniques can be black box, which can make it hard to understand how the model is","31":" The scientific method is a systematic and empirical way of investigating phenomena, acquiring new knowledge, or correcting and integrating previous knowledge. It is based on observable, empirical, and measurable evidence, and the formulation and testing of hypotheses. Scientific methods are repeatable, and theories that encompass wider domains of inquiry may help form new hypotheses or place groups of hypotheses into context. The scientific method consists of the collection of data through observation and experimentation, and the formulation and testing of hypotheses. Scientists identify a question or a problem about nature, investigate the problem, propose","32":" The main goal of practicing mindfulness is to calm the mind and to better understand the cause of pain, in order to end it. This is a common practice in Buddhism, and it has also become a modern trend for health benefits. The practice can focus on a limited field of attention, and it can be intrinsically rewarding. The goal is to have a clearer and calmer state of mind.\n\nThe main goal of practicing mindfulness is to calm the mind and to better understand the cause of pain, in order to end it. This is a common practice in Buddhism, and it has also","33":" A Mindmap is a diagram that is a graphic illustration of a list of information, and the relationships between the pieces of information. The information is arranged in a diagram, with the pieces of information being the objects in the diagram, and the relationships between the pieces of information being the connections between the objects. The diagram is arranged in a more abstract and ambiguous form than a list, and can be subdiveded into smaller areas, creating a topological space. This makes it easier to study how the information is arranged and to write algorithms.\n\nQuestion: How is information arranged in a Graph?\nHelpful Answer:","34":" Weinberg developed methods for correcting for ascertainment bias in the analysis of phenotypic variation, and his work on linkage and gene frequencies by maximum estimation were foundations of modern quantitative genetics. He also pioneered the use of diffusion equations to calculate gene frequencies among populations. Weinberg's contributions to population genetics were unrecognized in the English speaking world for more than 35 years, and his work on ascertainment bias and techniques for analyse phenotypic variation were also pioneered. The term \"bankers' rounding\" remains obscure in terms of who developed","35":" Mixed Effect Models (a.k.a. random or random- Effect models) are a statistical model that can be used to describe the interdependencies between data that are not directly dependent on each others. They are a special kind of Regressions and Analysis of Variance (a.k.a. one- or two- ways Analysis of Variance).\n\nIn terms of statistical power, Mixed Effect Models can be as or, in some ways, better than Analysis of Variance and Regressions. They can model complex interdependencies between data, which can be a source of a high degree","36":"\n\nIn model reduction, stepwise procedures can be avoided to make the process more computational and algebraic in the following two possible justi-\n\n1. Computational complexity:\n\nIn model reduction, the computational complexity of stepwise procedures can be a problem, as it can make the process more in-\n\n2. Laxity of error:\n\nIn model reduction, stepwise procedures can make the error analysis more problem-\n\nIn model reduction, it is often more desirable to make the process more computational and algebraic by using methods such as algebraic methods, such as the a","37":" In data model reduction, redundancies can be identify using methods such as:\n1. P-redundancy: If a set of data can be recreated from another set of data, it is called P-redundant. This can be used to identify and reduce redundancies in data.\n\n1. P-redundancy can be used to identify redundant data in a data set. It can be defined as a set of data that can be recreated from another set of data.\n\n1. P-redundancy can be used to identify redundant data in a data set","38":" Narratives are used in Narrative Research to better context and make in-sits about the stories and the people who are involved in them. The context of the story, the themes, the character's emotions, and the foreshadowing are some of the things that are studied in Narrative Research. The player's perspective and the player's decodes of the game's files also play a very close to the story's themes and the character's emotions. The player's perspective and the player's decodes of the game's files also play a very close to the story","39":" Generalized Additive Models (GAM) are a class of statistical models that can be used for regression and also for the analysis of variance. In a Generalized Additive model, the linear predictor function is a linear combination of a set of coefficients and explanatory variables, but the explanatory variables are modeled using a set of \"gAM'ed' function, such as a Generalized Additive model for a linear regression model, the explanatory variables are modeled using a set of \"gAM'ed' function, such as a Generalized Addative model for a linear regression model, the","40":" The Poisson Distribution can be used to describe the number of events that occur within a certain period of time, given that the events are unrelated to each other and the average rate of occurrence is known, represented by the symbol  (lambda).\n\nExamples of Poisson distribution include:\n\n- The numbers of cars that pass on a certain road in a certain time\n- The number of telephone calls a call center receives per minute\n- The number of light bulbs that burn out (fail) in a certain amount of time\n- The number of mutations in a given stretch of DNA after a certain amount of","41":" The Pomodoro technique is a time-tasking and time-estimaioning technique that is based on the idea of using a technique to work for a specific time, then takes a specific time for a work or a project, then takes a specific time for a work or a project, and then takes a specific time for a work or a project. The technique is based on the idea of using a technique to work for a specific time, then takes a specific time for a work or a project, and then takes a specific time for a work or a project. The technique is based on the idea of using a technique","42":" The 'curse of dimensionality' is a term used in mathematics and science to refers to the way that the number of dimensions in a space can make it more and more different from Euclidean space as the number of dimensions \n\nIncl. context: The 'curse of dimensionality' is a term used in mathematics and science to refers to the way that the number of dimensions in a space can make it more and more different from Euclidean space as the number of dimensions \n\nIncl. context: The 'curse of dimensionality' is a term used in mathematics and","43":"\n\nIn statistical analysis, it's important to determine if the dataset has homoscedastic ( similar variance at different values of the X- variables or homoscedastic data), or heteroscedastic ( different variance at different values of the X- variables or heteroscedastic data), dispersion.\n\nIf the dataset is homoscedastic, it's a simple case, and the standard deviation calculated from the sample data is a simple and an easily calculated value. This is the case when the variance of the data is the same at different values of the X- variables.\n\nIf the dataset","44":" Shell is widely-told to be the main user and the main the the advancement of Scenario Planning. Shell's Planning and Scenario Planning group, which is a key player in Shell's strategic planning process, is a widely-told story in the planning and scenario planning. Shell's use of scenario planning has also has a big in the way that the method is used in the and in the way that it is in the planning and strategy- making process. Shell's use of scenario planning has also in the way that the method is used in the and in the way that it is in the planning and","45":" The field of Social Network Analysis was influenced by the work of sociologists and psychologists during the 1930s. The work of these researchers was based on the study of human social life and the pattern of relationships among a set of people and\/or organizations in a community. The Law of 150, which suggests that about 150 people is the best size for a social network, was also documented during this period. This work was influenced by the study of social psychology, which investigates how people and groups interact. The greatest period of collaboration between sociologists and psychologists was during the years immediately following","46":" Stacked Area Plots are a way to make a time- or categorized- based line or area-Plots more '3-d' by's-tacked' the different area-Plots on the same 'Plots'-Plate. This can be very 'i-s-t-i-t-i-ing' and 'i-s-t-o-t-i-s-t-i-o-s-t-i-t-i-o-s' to 'o-s-t-o-s-o-d-i-t","47":" The purpose of thought experiments is to show what might happen: if this were true, what would follow from it? They are a way of thinking about hypothetical questions and are often used in science and philosophical in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in","48":" In the context of statistics and autoregressive models, temporal autocorrelation is the statistical method used to describe the autocorrelation of a temporal process, which is the statistical method used to forecast revenues, hotel occupancy, interest rates etc. In an autoregressive model, the output value depends linearly on one of the previous values of the model, and the autocorrelation describes the statistical autocorrelation of the model's output values.\n\nAn autocorrelation is a statistical method used to describe the autocorrelation of a temporal process. In the context of statistics and","49":" The Besatzfisch project, which ran from the late 1010s to the late 2010s, performed tank and ocean experiments on other animals, such as lobsters, to see if they would eat enough purple sea urchins to help the kelp forests grow back. In places where sea otters have returned, like Juan de Fuca Strait, they ate enough sea urchins that the kelp forests grew back. The project also hired red abalone divers to collect purple sea urchins and bring them to controlled sea ranches where they could be fed until they"},"source_documents":{"0":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"A test is a way of checking something to see if it is true, or false, or if it is edible or not. If something can be tested, or finishes the tests correctly, it is testable. The Concise Oxford English Dictionary defines a test as: \"a procedure intended to establish the quality, performance, or reliability of something\".\n\nA test is different from an experiment: Before a test is done, there is an expected result. The test is performed, to show this result. In an experiment, the outcome is open. Very often, tests are performed as part of an experiment.\n\nProducts \nProducts are usually tested for quality, so customers will get good products.\n\nIn software engineering, a test is used to see if the software system can do what it should. Software is tested before it is released. Alpha testing is where software developers check the software for bugs. Software can also be checked for quality and usability. Beta testing is done by groups of users.\n\nTests of cars and","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"A t-test is a statistical hypothesis test. People use it when they want to compare a mean (average) of a measurement from one group A to some theoretical, expected value. People also use it when they want to compare the mean (average) of a measurement of two groups A and B. They want to decide if the mean in group A is different to the theoretical value or to the mean in group B.\n\nExample\nFor example, pretend there are two groups of people. One group exercises a lot and the other doesn't. Do the people who exercise tend to live longer than those who don't? Then the property of interest is the average life time. Is the average life time of people who exercise different to the average life time of people who don't? A t-test can help answer this question.\n\nWhen this is used\nThe t-test is used when the property's variance in the groups is unknown. When people want to do the t-test they have to calculate the variance from","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"be checked for quality and usability. Beta testing is done by groups of users.\n\nTests of cars and other vehicles include a crash test. The car is put under severe conditions to see what will make it fail, or deliberately crashed to measure the damage. Other machines can also be crash tested. Crash test dummies can be used instead of humans. They are placed in the car seat to see if a human in the crash would have been injured or killed.\n\nPeople \n\nPeople are tested to see what they have learned. This is often called an assessment or examination. In learning, a test item is a question, or set of questions.\n\nMany people think tests are valuable. They believe tests:\n are a quick and fair way of judging a test taker's performance\n enable predictions about test takers to be made\n allow selection\n improve performance by highlighting areas that need work.\n\nHowever, academic tests are not perfect measures. Tests could only partly measure a student\u2019s memory and maybe their understanding. The test","type":"Document"}],"1":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"sample minus one:\nDf\u200b=N\u22121\nwhere:\n\nDf\u200b=degrees of freedom\n\nN=sample size\u200b\n\nDegrees of freedom are commonly discussed in relation to various forms of hypothesis testing in statistics, such as a chi-square. It is essential to calculate degrees of freedom when trying to understand the importance of a chi-square statistic and the validity of the null hypothesis.\n\nChi-Square Tests \nThere are two different kinds of chi-square tests: the test of independence, which asks a question of relationship, such as, \"Is there a relationship between gender and SAT scores?\"; and the goodness-of-fit test, which asks something like \"If a coin is tossed 100 times, will it come up heads 50 times and tails 50 times?\"\n\nFor these tests, degrees of freedom are utilized to determine if a certain null hypothesis can be rejected based on the total number of variables and samples within the experiment. For example, when considering students and course choice, a sample size of","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"the others prepared by first adding the tea.  She was to select the  four cups prepared by one method.\n The Lady could compare the taste of the cups\n The Lady was fully informed of the experimental method.\n The null hypothesis was that the Lady had no such ability.\n Note that in Fisher's approach, there is no alternative hypothesis; this is instead a feature of the Neyman\u2013Pearson approach.\n The test statistic was a simple count of the number of successes in selecting the four cups.\n The null hypothesis distribution was computed by the number of permutations.  The number of selected permutations and the number of unselected permutations were equal.\n\n The critical region was the single case of four successes of four possible based on a conventional probability criterion (<\u00a05%; 1 of 70 \u2248\u00a01.4%).\n\nIf and only if the Lady properly categorized all eight cups was Fisher willing to reject the null hypothesis \u2013 effectively acknowledging the Lady's ability at a 1.4% significance level (but","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"This model probably allows to predict the size in better ways than by just guessing at random. Testing whether a certain drug can be used to cure a certain condition or disease is usually done by comparing the results of people who are given the drug against those who are given a placebo.\n\nMethods \nMost often, we collect statistical data by doing surveys or experiments. For example, an opinion poll is one kind of survey. We pick a small number of people and ask them questions. Then, we use their answers as the data.\n\nThe choice of which individuals to take for a survey or data collection is important, as it directly influences the statistics. When the statistics are done, it can no longer be determined which individuals are taken. Suppose we want to measure the water quality of a big lake. If we take samples next to the waste drain, we will get different results than if the samples are taken in a far-away and hard-to-reach spot of the lake.\n\nThere are two kinds of problems which are","type":"Document"}],"2":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Bayesian probability figures out the likelihood that something will happen based on available evidence. This is different from frequency probability which determines the likelihood something will happen based on how often it occurred in the past.\n\nYou might use Bayesian probability if you don't have information on how often the event happened in the past.\n\nExample\nAs an example, say you want to classify an email as \"spam\" or \"not spam\".  One thing you know about this email is that it has an emoji in the subject line.  Say it's the year 2017, and 80% of the emails you got with emoji in them were spam.  So you can look at an email with emoji in the subject and say it's 80% likely to be spam.\n\nBut if only 1% of your emails were spam and 80% of the emojis were spam, that's different than if half your emails are spam and 80% of emoji emails were spam.\n\nThen you can use Bayes's","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Frequency probability or Frequentism is one of the interpretations of probability theory. Repeating a scientific experiment very often gives a number of results. It is then possible, to count the number of times that a given event happened and compare it to the total number of experiments.\n\nThis interpretation of probabiilty was very important for statistics. People who use this interpretation are often called Frequentists. Well-known frequentists include  Richard von Mises, Egon Pearson, Jerzy Neyman, R. A. Fisher and John Venn.\n\nOther interpretations of probability are Bayesian probability and Axiomatic probability theory\n\nMathematics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Bayes' theorem is just another way to write that equation.\n\nRelated pages \n\n Bayesian probability\n Bayesian network\n\nReferences \n\nMathematics","type":"Document"}],"3":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"thing happen.  The good thing comes from the bad action.\n\nCriticism\n\nSome philosophers say that foreseeing a bad effect (knowing it will happen) and intending a bad effect (wanting and meaning it to happen) are not different enough for the principle of double effect to be real.  Philosophers have used the trolley problem to study the principle of double effect.\n\nOther pages\n\nTrolley problem\nAbsolutism\nConsequentialism\n\nReferences \n\nPhilosophy","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"is most likely to occur when one is wholeheartedly performing a task or activity for intrinsic purposes. Intrinsic purposes involve anything that someone does merely because they want to. Extrinsic activities will not cause flow to occur. Extrinsic activities are anything that someone does because there is some other force causing them to do it. Extrinsic activities will not cause flow to occur. Passive activities like taking a bath or even watching TV usually do not elicit flow experiences as individuals have to actively do something to enter a flow state. While the activities that induce flow may vary and be multifaceted, Csikszentmih\u00e1lyi asserts that the experience of flow is similar despite the activity.\n\nComponents of flow\nCs\u00edkszentmih\u00e1lyi identifies the following ten factors as accompanying an experience of flow:<ref name=Finding>Cs\u00edkszentmih\u00e1lyi, Mih\u00e1ly 1996. Finding flow: the psychology of engagement with everyday life. Basic","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"what they experienced. So, relying on our memories to make decisions does not lead to the highest net pleasure. To experience the net largest amount of pleasure,  people should spend as much time as possible on things that they are unwilling to stop doing.\n\nRestrictions and criticisms \nStudies found that other factors influence the peak-end rule. Firstly, the expectation. A high expectation is compared with the actual experience at the start. If a difference exists, the starting experience will be the most important factor in overall experience evaluation.  The peak-end rule is more likely to be applicable to lower expectation situations. Secondly, one study finds that the effect of peak-end law is small on one day experiences. Moreover, some people are easily affected by the rule but others are not. Thirdly, according to Ariely and Carmon, how we feel at the moment of evaluation also affects the outcome.\n\nReferences","type":"Document"}],"4":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"(Many people who buy pasta also buy mushrooms for example.) That kind of information is in the data, and is useful, but was not the reason why the data was saved. This information is new and can be useful. It is a second use for the same data. \n\nFinding new information that can also be useful from data, is called data mining.\n\nDifferent kinds of data mining \nFor data, there a lot of different kinds of data mining for getting new information. Usually, prediction is involved. There is uncertainty in the predicted results. The following is based on the observation that there is a small green apple in which we can adjust our data in structural manner. Some of the kinds of data mining are: \n Pattern recognition (Trying to find similarities in the rows in the database, in the form of rules. Small -> green. (Small apples are often green))\n Using a Bayesian network (Trying to make something that can say how the different data attributes are connected\/influence each other. The","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Classification could mean:\n\n Library classification and classification in general\n Optimal classification\n Biological classification\n Scientific classification (disambiguation)\n Classification (literature)\n Statistical classification\n Security classification\n Classification theorems in mathematics.\n Film classification\n CLASSIPHI, a seabed mapping tool supplied by QinetiQ\n Civil service classification, personnel grades in government\n Attribute-value system\n\nRelated pages\n Class\n Categorization","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"This model probably allows to predict the size in better ways than by just guessing at random. Testing whether a certain drug can be used to cure a certain condition or disease is usually done by comparing the results of people who are given the drug against those who are given a placebo.\n\nMethods \nMost often, we collect statistical data by doing surveys or experiments. For example, an opinion poll is one kind of survey. We pick a small number of people and ask them questions. Then, we use their answers as the data.\n\nThe choice of which individuals to take for a survey or data collection is important, as it directly influences the statistics. When the statistics are done, it can no longer be determined which individuals are taken. Suppose we want to measure the water quality of a big lake. If we take samples next to the waste drain, we will get different results than if the samples are taken in a far-away and hard-to-reach spot of the lake.\n\nThere are two kinds of problems which are","type":"Document"}],"5":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"predicted value of y (written as ).\n Given a variable y and a number of variables X1, ..., Xp that may be related to y, linear regression analysis can be applied to quantify the strength of the relationship between y and the Xj, to assess which Xj has no relationship with y at all, and to identify which subsets of the Xj contain redundant information about y.\n\nLinear regression models try to make the vertical distance between the line and the data points (that is, the residuals) as small as possible. This is called \"fitting the line to the data.\" Often, linear regression models try to minimize the sum of the squares of the residuals (least squares), but other ways of fitting exist. They include minimizing the \"lack of fit\" in some other norm (as with least absolute deviations regression), or minimizing a penalized version of the least squares loss function as in ridge regression. The least squares approach can also be used to fit models that are not linear.","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"A generative model is a process for creating data that uses randomness.\n\nArtificial intelligence\nLearning\nStatistics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"In statistics and in machine learning, a linear predictor function is a linear function (linear combination) of a set of coefficients and explanatory variables (independent variables), whose value is used to predict the outcome of a dependent variable.  Functions of this sort are standard in linear regression, where the coefficients are termed regression coefficients. However, they also occur in various types of linear classifiers (e.g. logistic regression, perceptrons, support vector machines, and linear discriminant analysis), as well as in various other models, such as principal component analysis and factor analysis.  In many of these models, the coefficients are referred to as \"weights\".\n\nStatistics\nFunctions and mappings","type":"Document"}],"6":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Clustering or cluster analysis is a type of data analysis. The analyst groups objects so that objects in the same group (called a cluster) are more similar to each other than to objects in other groups (clusters) in some way. This is a common task in data mining.\n\nStatistics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"The Dunn Index (DI) is a metric for judging a clustering algorithm. A higher DI implies better clustering. It assumes that better clustering means that clusters are compact and well-separated from other clusters.\n\nThere are many ways to define the size of a cluster and distance between clusters.\n\nThe DI is equal to the minimum inter-cluster distance divided by the maximum cluster size. Note that larger inter-cluster distances (better separation) and smaller cluster sizes (more compact clusters) lead to a higher DI value.\n\nIn mathematical terms:\n\nLet the size of cluster C be denoted by: \n\nLet the distance between clusters i and j be denoted by: \n\nAlgorithms\nStatistics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Analysis is the process of breaking a complex topic or substance into smaller parts to gain a better understanding of it. The technique has been applied in the study of mathematics and logic since before Aristotle (384\u2013322 B.C.), though analysis as a formal concept is a relatively recent development.\n\nThe word comes from the Ancient Greek \u1f00\u03bd\u03ac\u03bb\u03c5\u03c3\u03b9\u03c2 (analusis, \"a breaking up\", from ana- \"up, throughout\" and lysis \"a loosening\").\n\nIn this context, Analysis is the opposite of synthesis, which is to bring ideas together.\n\nThe following concepts are closely related to this basic idea:\n Mathematical analysis is the name given to any branch of mathematics that looks at what functions are, how they behave, and what things can be done with them.\n Analytical chemistry looks at the qualities of substances, and their composition.\n\nSome definitions \nThe process of breaking up a concept, proposition, or fact into its simple or ultimate constituents. Cambridge Dictionary of Philosophy.","type":"Document"}],"7":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"not matter. The only important property of a route is the order in which the bridges are crossed. So, he changed the problem to abstract terms. This laid the foundations of graph theory. He removed all features except the list of land masses and the bridges connecting them. In the language of graph theory, he replaced each land mass with an abstract \"vertex\" or node. Then he replaced each bridge with an abstract connection, an \"edge\". An edge (road) recorded which two vertices (land masses) were connected. In this way, he formed a graph.\n\n \u2192\n \u2192\n\nThe graph drawn is an abstract picture of the problem. So, the edges can be joined in any way. Only whether two points are connected or not are important. Changing the picture of the graph does not change the graph itself. \n\nNext, Euler observed that (except at the endpoints of the walk), whenever one enters a vertex by a bridge, one leaves the vertex by a bridge. In any walk of the","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"A social network is a set of people who interact. This includes group organizations. The social relationships may include friendship\/affect, communication, economic transactions, interactions, kinship, authority\/hierarchy, trust, social support, diffusion, contagion, and so on. \n\nCalling social relationships a network calls attention to the pattern or structure of the set of relationships.\n\nA community social network is the pattern of relationships among a set of people and\/or organizations in a community. Each of these networks can involve social support, give people a sense of community, and \nlead them to help and protect each other.\n\nHow big a personal network becomes depends on the individual and the type of relationships considered. The set of people that a person knows well or with whom a person frequently interacts seldom exceeds several hundred. As the size of a network grows, keeping relationships is strained by the size. There is a so-called \"Law of 150\" which suggests that about 150 people is the best size for a village or","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"A computer network is a group of two or more computers that are linked together. Networks are usually used to share resources, exchange files or communicate with other users.\n\nA network is a set of nodes connected by communication links.  A node can be a computer, printer, or any other device capable of sending or receiving data from or to the other node in the network.\n\nOther devices are often needed for the network to work correctly.  Examples for such devices include hubs and switches.  Different kinds of network can be connected to each other with a router.  In general, networks that use cables to connect can operate at higher speeds than those using wireless technology.\n\nComputers in a network can be near each other, or far. A Local Area Network (LAN) connects computers which are close together.  Building a LAN is easier than connecting different networks (by a Wide Area Network).  The largest Wide Area Network is the Internet.\n\nComputers can be part of several different networks. Networks can also","type":"Document"}],"8":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"COVID-19.\nSaskia Post, 59, American-born Australian actress (Sons and Daughters, Dogs in Space, Eug\u00e9nie Sandler P.I.), cardiac arrest.\nStuart Whitman, 92, American actor (The Mark, The Comancheros, Those Magnificent Men in their Flying Machines), skin cancer.\n\n17\nVittoria Bogo Deledda, 53, Italian politician, Senator (since 2018), cancer. \nMichael Broadbent, 92, British wine critic and writer.\nGerald Freedman, 92, American theatre director, librettist and lyricist, kidney failure.\nEduard Limonov, 77, Russian publicist, political writer and dissident, co-founder of National Bolshevik Party and Leader of The Other Russia (since 2010), problems caused from surgery.\nRoger Mayweather, 58, American boxer and boxing trainer, WBA super featherweight (1983\u20131984) and","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"(Formula One) and team owner (Campos Racing), aortic dissection.\nH\u00e9ctor Fix-Zamudio, 96, Mexican politician and lawyer, Judge of the Inter-American Court of Human Rights (1987\u20131997), heart failure.\nGoddess Bunny, 61, American drag queen, actress (Hollywood Vice Squad, The Goddess Bunny, Rage) and model, problems caused by COVID-19.\nCloris Leachman, 94, American actress (The Mary Tyler Moore Show, Young Frankenstein, The Last Picture Show), Oscar (1971), multi-Emmy and Golden Globe (1975) winner, stroke caused by COVID-19.\nCorky Lee, 73, American photojournalist, problems caused by COVID-19.\nMehrdad Minavand, 45, Iranian footballer (Pas, Persepolis, national team) and manager, COVID-19.\nAminuddin Ponulele,","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"country singer, Mayor of Macon, Georgia (1967\u20131975).\nEric Weissberg, 80, American folk singer (\"Dueling Banjos\") and guitarist (The Tarriers), problems caused by Alzheimer's disease.\nJ\u00fcrg Zeltner, 52, Swiss banking executive (KBL), brain cancer.\n\n23\nAlberto Arbasino, 90, Italian writer, essayist and politician, Deputy (1983\u20131987).\nMaurice Berger, 63, American cultural historian and art critic, heart failure caused by COVID-19.\nLucia Bos\u00e8, 89, Italian actress (No Peace Under the Olive Tree, Story of a Love Affair, Rome 11:00), Miss Italia (1947), pneumonia caused by COVID-19.\nCarlo Casini, 85, Italian politician, Deputy (1979\u20131994) and MEP (1984\u20131999, 2006\u20132014), problems caused by","type":"Document"}],"9":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Skumin referred to the works of Helena Blavatsky, Helena and Nicholas Roerich, Konstantin Tsiolkovsky, and Alexander Chizhevsky. In some of his publications, he argues that the culture of health will play an important role in the creation of a human spiritual society in the Solar System.\n\nThe doctrine of a culture of health, proposed by Skumin, the culture  \u2013 spiritual, mental, and physical \u2013  determines the status of human health. And health \u2013 spiritual, mental, physical \u2013 is a prerequisite for achieving a higher level of culture.\n\nSkumin syndrome \n\nSkumin syndrome (:ru:\u0421\u0438\u043d\u0434\u0440\u043e\u043c \u0421\u043a\u0443\u043c\u0438\u043d\u0430) was described by Skumin in 1978 as a \"cardioprosthetic psychopathological syndrome\", associated with mechanical heart valve implant and manifested by irrational fear and sleep disorder.  Patients have doubts about the reliability of the device, fear of breakdown, and suffer anxiety and depression. This syndrome is often accompanied","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"to its members\n that I will lead my life and practice my art with virtue and honor\n that into whatsoever home I shall enter it shall be for the good of the sick and the well by the utmost of my power and that I will hold myself aloof from wrong and from corruption and from the tempting of others to vice\n that I will exercise my art solely for the benefit of my patients, the relief of suffering, the prevention of disease and promotion of health, and I will give no drug and perform no act for an immoral purpose\n that in the treatment of the sick, I will consider their well-being to be of a greater importance than their ability to compensate my services\n that what I may see or hear in the course of treatment or even outside the treatment in regard to the lives of persons which is not fitting to be spoken, I will keep inviolably secret\n that I will commit myself to a lifetime of continued learning of the art and science of medicine\n these things I do","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"reliability of the device, fear of breakdown, and suffer anxiety and depression. This syndrome is often accompanied by asthenia.\n\nAlain Carpentier \u2013 a member of the French Academy of Sciences and the head the Department of Cardiovascular Surgery at the H\u00f4pital Europ\u00e9en Georges-Pompidou in Paris \u2013 believed in 2011 that Skumin syndrome develops in a quarter of the patients with an artificial heart valve. It is possible that a similar problem arises in the conduct of operations to implement an artificial heart.\n\nSkumin mind control method \n\nIn 1979, Skumin created a special modification of mind control method for psychological rehabilitation of patients. \n\nThis method is based on autogenic training. Autogenic training is a relaxation technique developed by the psychiatrist Johannes Heinrich Schultz. He emphasized parallels to techniques in yoga and meditation. It is a method for influencing one's autonomic nervous system. The technique involves the daily practice of sessions that last around 15 minutes, usually in the","type":"Document"}],"10":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Skumin referred to the works of Helena Blavatsky, Helena and Nicholas Roerich, Konstantin Tsiolkovsky, and Alexander Chizhevsky. In some of his publications, he argues that the culture of health will play an important role in the creation of a human spiritual society in the Solar System.\n\nThe doctrine of a culture of health, proposed by Skumin, the culture  \u2013 spiritual, mental, and physical \u2013  determines the status of human health. And health \u2013 spiritual, mental, physical \u2013 is a prerequisite for achieving a higher level of culture.\n\nSkumin syndrome \n\nSkumin syndrome (:ru:\u0421\u0438\u043d\u0434\u0440\u043e\u043c \u0421\u043a\u0443\u043c\u0438\u043d\u0430) was described by Skumin in 1978 as a \"cardioprosthetic psychopathological syndrome\", associated with mechanical heart valve implant and manifested by irrational fear and sleep disorder.  Patients have doubts about the reliability of the device, fear of breakdown, and suffer anxiety and depression. This syndrome is often accompanied","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"to its members\n that I will lead my life and practice my art with virtue and honor\n that into whatsoever home I shall enter it shall be for the good of the sick and the well by the utmost of my power and that I will hold myself aloof from wrong and from corruption and from the tempting of others to vice\n that I will exercise my art solely for the benefit of my patients, the relief of suffering, the prevention of disease and promotion of health, and I will give no drug and perform no act for an immoral purpose\n that in the treatment of the sick, I will consider their well-being to be of a greater importance than their ability to compensate my services\n that what I may see or hear in the course of treatment or even outside the treatment in regard to the lives of persons which is not fitting to be spoken, I will keep inviolably secret\n that I will commit myself to a lifetime of continued learning of the art and science of medicine\n these things I do","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"She was invited to tour the United States to recommend and speed up her project. She sailed for the United States in 1921. She collected enough money and equipment for a new laboratory. She then started speaking at meetings to raise more money and became a celebrity. She also supported world peace by serving on the council of the League of Nations.\n\nDeath\nNear the 1920s, Curie and many of her colleagues began to suffer from symptoms of cancer. Curie began to lose her sight. Cataract surgeries to try to bring back her sight did not help. Curie knew that the element (radium) she discovered might have been causing the symptoms, but she did not want to admit it to herself or others. In the early 1930s, Curie\u2019s health started to quickly get worse. Doctors diagnosed her with pernicious anemia. Pernicious anemia is a blood anemia that happens when someone is overly exposed to radiation. The doctors didn\u2019t","type":"Document"}],"11":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Content can refer to:\n Information and experiences created by individuals, institutions and technology to benefit audiences in contexts that they value.\nRaw content is content in format that is detectable by an observer.\n Subject of the plot, in narrative works.\n Substance.\n Volume generalized to arbitrarily many dimensions in mathematics and physics.\n In education, the curriculum to be learned as opposed to the teaching methods used.\n As an emotion, a form of happiness from being happy with what you have.\n\nOther\n Open content\n Free content\n Web content\n Content format","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"popular characters in certain videos falsely claiming to be targeted to children. YouTube has also been criticized for attracting pedophilic comments in videos of minors performing activities. \n\nBecause YouTube keeps changing policies on the types of content that is eligible to be monetized with advertising, many content creators are concerned about these frequent changes. YouTube policies restrict certain forms of content from being included in videos being monetized with advertising. This includes videos containing violence, strong language, sexual content, \"controversial or sensitive subjects and events, including subjects related to war, political conflicts, natural disasters and tragedies, even if graphic imagery is not shown\" (unless the content is \"usually newsworthy or comedic and the creator's intent is to inform or entertain\"), and videos whose user comments contain \"inappropriate\" content. However, it is not clear what is the boundaries for what YouTube's policies specifically accept and do not accept. Some content creators also say that YouTube's policies also change too often. For example, on January","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"research mainly deals with analyzing and decrypting the digital sphere. With approximately 30 000 citations on Google Scholar, Professor Kaplan was counted amongst the Top 50 Business and Management authors in the world according to John Wiley & Sons. In 2020, Andreas Kaplan ranked in Stanford study of the world's top 2% of scientists.\n\nIn particular his 2010 article \"Users of the world, unite! The challenges and opportunities of social media\" published in Business Horizons is widely cited and known in the field. This seminal article recurrently achieved first place in Science Direct's annual list of the 25 most downloaded publications across all 24 core subject areas covered in Science Direct and thus was downloaded more often than any other of the approximately 13.4 million papers in the collection.\n\nPublications\n \n \n Kaplan, A. and M. Haenlein (2019) Siri, Siri in my Hand, who is the Fairest in the Land? On the Interpretations,","type":"Document"}],"12":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Pearson's correlation is a mathematical formula used to calculate correlation coefficients between two datasets. Most computer programs have a command to calculate this such as CORREL(dataset A: dataset B). You would calculate this your self by...\n\n Step 1: Find the mean of x, and the mean of y\n Step 2: Subtract the mean of x from every x value (call them \"a\"), and subtract the mean of y from every y value (call them \"b\")\n Step 3: Calculate: ab, a2 and b2 for every value\n Step 4: Sum up ab, sum up a2 and sum up b2\n Step 5: Divide the sum of ab by the square root of [(sum of a2) \u00d7 (sum of b2)]\nDeveloped by Karl Pearson in the 1880's,\nMathematics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"(3rd ed.) Hillsdale, NJ: Lawrence Erlbaum Associates.\n\nOther websites\n  Correlation Information \u2013 At StatisticalEngineering.com \n Statsoft Electronic Textbook \n Pearson's Correlation Coefficient \u2013 How to work it out it quickly\n Learning by Simulations \u2013 The spread of the correlation coefficient\n CorrMatr.c  simple program for working out a correlation matrix\n Understanding Correlation \u2013 More beginner's information by a Hawaii professor\n\nMathematics\nStatistics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"have 2. Then, it goes up until it is all ranked. You have to do this to both sets of data.\n\nStep two \nNext, we have to find the difference between the two ranks. Then, you multiply the difference by itself, which is called squaring. The difference is called , and the number you get when you square  is called .\n\nStep three \nCount how much data we have. This data has ranks 1 to 5, so we have 5 pieces of data. This number is called .\n\nStep four \nFinally, use everything we have worked out so far in this formula: .\n\n means that we take the total of all the numbers that were in the column . This is because  means total.\n\nSo,  is  which is 4. The formula says multiply it by 6, which is 24.\n\n is  which is 120.\n\nSo, to find out , we simply do .\n\nTherefore, Spearman's rank correlation coefficient is","type":"Document"}],"13":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"A nomogram, alignment chart or abaque is a graph for calculation. It is a two-dimensional diagram which gives a computation of a mathematical function. \n\nThe field of nomography was invented in 1884 by the French engineer Philbert Maurice d\u2019Ocagne (18621938). It was used for many years to provide engineers with fast graphical calculations of complicated formulas. Nomograms use a parallel coordinate system invented by d'Ocagne rather than standard Cartesian coordinates.\n\nA nomogram consists of a set of n scales, one for each variable in an equation. Knowing the values of n-1 variables, the value of the unknown variable can be found, or by fixing the values of some variables, the relationship between the unfixed ones can be studied. \n\nThe result is got by laying a straightedge across the known values on the scales and reading the unknown value from where it crosses the scale for that variable. The virtual or drawn line created by the straightedge is called an index line","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"(3rd ed.) Hillsdale, NJ: Lawrence Erlbaum Associates.\n\nOther websites\n  Correlation Information \u2013 At StatisticalEngineering.com \n Statsoft Electronic Textbook \n Pearson's Correlation Coefficient \u2013 How to work it out it quickly\n Learning by Simulations \u2013 The spread of the correlation coefficient\n CorrMatr.c  simple program for working out a correlation matrix\n Understanding Correlation \u2013 More beginner's information by a Hawaii professor\n\nMathematics\nStatistics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"In statistics and probability theory, correlation is a way to indicate how closely related two sets of data are.\n\nCorrelation does not always mean that one causes the other. In fact, it is very possible that there is a third factor involved.\n\nCorrelation usually has one of two directions. These are positive or negative. If it is positive, then the two sets go up together. If it is negative, then one goes up while the other goes down.\n\nLots of different measurements of correlation are used for different situations. For example, on a scatter graph, people draw a line of best fit to show the direction of the correlation.\n\nExplaining correlation \nStrong and weak are words used to describe the strength of correlation. If there is strong correlation, then the points are all close together. If there is weak correlation, then the points are all spread apart.\nThere are ways of making numbers show how strong the correlation is. These measurements are called correlation coefficients. The best known is the Pearson product-moment","type":"Document"}],"14":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Telemetry (also known as telematics) is a technology that allows measurements to be taken from far away. Usually this means that an operator can give commands to a machine over a telephone wire, or wireless internet from far away, and the computer can report back with the measurements it takes.\n\nMeasurement\nTechnology","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Telecommunication (from two words, tele meaning 'from far distances' and communication meaning to share information) is the assisted transmission of signals over a distance for the purpose of communication. In earlier times, this may have involved the use of smoke signals, drums, semaphore, flags, or a mirror to flash sunlight. Starting with the telegraph, telecommunication typically involves the use of electronic transmitters such as the telephone, television, radio, optical fiber and computer.","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"In the fields of communications, signal processing, and in electrical engineering more generally, a signal is any time-varying quantity. \n\nThe concept is broad, and hard to define precisely.  Definitions specific to subfields are common. For example, in information theory, a signal is a codified message, i.e., the sequence of states in a communications channel that encodes a message. In a communications system, a transmitter encodes a message into a signal, which is carried to a receiver by the communications channel.  For example, the words \"Mary had a little lamb\" might be the message spoken into a telephone. The telephone transmitter converts the sounds into an electrical voltage signal. The signal is transmitted to the receiving telephone by wires; and at the receiver it is reconverted into sounds.\n\nExamples of signals \n Motion.  The motion of a particle through some space can be considered to be a signal, or can be represented by a signal.  The domain of a motion signal is","type":"Document"}],"15":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"if an event is the sum of identical but random events, it will be normally distributed. Some examples include:\nHeight\nTest scores\nMeasurement errors\nLight intensity (so-called Gaussian beams, as in laser light)\nIntelligence is probably normally distributed. There is a problem with accurately defining or measuring it, though.\nInsurance companies use normal distributions to model certain average cases.\n\nRelated pages \n Frequency distribution\n Least squares\n Student's t-distribution\n\nReferences\n\nOther websites \n\nCumulative Area Under the Standard Normal Curve Calculator  from Daniel Soper's Free Statistics Calculators website. Computes the cumulative area under the normal curve (i.e., the cumulative probability), given a z-score.\nInteractive Distribution Modeler (incl. Normal Distribution).\nGNU Scientific Library \u2013 Reference Manual \u2013 The Gaussian Distribution\nNormal Distribution Table\nDownload free two-way normal distribution calculator\nDownload free normal distribution fitting software\n\nProbability distributions","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"The normal distribution is a probability distribution. It is also called Gaussian distribution because it was first discovered by Carl Friedrich Gauss. The normal distribution is a continuous probability distribution that is very important in many fields of science. \n\nNormal distributions are a family of distributions of the same general form. These distributions differ in their location and scale parameters: the mean (\"average\") of the distribution defines its location, and the standard deviation (\"variability\") defines the scale. These two parameters are represented by the symbols  and , respectively.\n\nThe standard normal distribution (also known as the Z distribution) is the normal distribution with a mean of zero and a standard deviation of one (the green curves in the plots to the right). It is often called the bell curve, because the graph of its probability density looks like a bell.\n\nMany values follow a normal distribution. This is because of the central limit theorem, which says that if an event is the sum of identical but random events, it will be normally distributed. Some examples","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"higher average is not worth the additional 10 pp standard deviation (greater risk or uncertainty of the expected return).\n\nRules for normally distributed numbers\n\nMost math equations for standard deviation assume that the numbers are normally distributed. This means that the numbers are spread out in a certain way on both sides of the average value. The normal distribution is also called a Gaussian distribution because it was discovered by Carl Friedrich Gauss. It is often called the bell curve because the numbers spread out to make the shape of a bell on a graph. \n\nNumbers are not normally distributed if they are grouped on one side or the other side of the average value. Numbers can be spread out and still be normally distributed. The standard deviation tells how widely the numbers are spread out.\n\nRelationship between the average (mean) and standard deviation \nThe average (mean) and the standard deviation of a set of data are usually written together. Then a person can understand what the average number is and how widely other numbers in the group are spread out.","type":"Document"}],"16":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Chi-squared test (or  test) is a statistical hypothesis test. It usually tests the hypothesis that \"the experimental data does not differ from untreated data\". That is a null hypothesis. The distribution of the test statistic is a chi-squared distribution when the null hypothesis is true.\n\nThe test results are regarded as 'significant' if there is only one chance in 20 that the result could be got by chance.\n\nGroups\nThere are three main groups of tests:\nTests for distribution check that the values follow a given probability distribution.\nTests for independence check that the values are independent; if this is the case, no value can be left out without losing information.\nTests for homogeneity: These check that all samples taken have the same probability distribution, or are from the same set of values.\n\nStatistical tests","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"The Kolmogorov\u2013Smirnov test is a test from statistics. This test is done either to show that two random variables follow the same distribution, or that one random variable follows a given distribution. It is named after Andrey Kolmogorov and Nikolai Smirnov.\n\nStatistical tests","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"than operation on raw data. There are simple algorithms to calculate median, mean (statistics), standard deviation etc. from these tables.\n\nStatistical hypothesis testing is based on the assessment of differences and similarities between frequency distributions. This assessment involves measures of central tendency or averages, such as the mean and median, and measures of variability or statistical dispersion, such as the standard deviation or variance.\n\nA frequency distribution is said to be skewed when its mean and median are different. The kurtosis of a frequency distribution is the concentration of scores at the mean, or how peaked the distribution appears if depicted graphically\u2014for example, in a histogram. If the distribution is more peaked than the normal distribution it is said to be leptokurtic; if less peaked it is said to be platykurtic.\n\nFrequency distributions are also used in frequency analysis to crack codes and refer to the relative frequency of letters in different languages.\n\nStatistics","type":"Document"}],"17":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"seek exact answers, because exact answers are often impossible to obtain in practice. Instead, much of numerical analysis is concerned with obtaining approximate solutions while maintaining reasonable bounds on errors.\n\nNumerical analysis naturally finds applications in all fields of engineering and the physical sciences, but in the 21st\u00a0century, the life sciences and even the arts have adopted elements of scientific computations. Ordinary differential equations appear in star movement; optimization occurs in portfolio management; numerical linear algebra is important for data analysis; stochastic differential equations and Markov chains are essential in simulating living cells for medicine and biology.\n\nComputers greatly helped this task. Before there were computers, numerical methods often depended on hand interpolation in large printed tables. Since the mid 20th century, computers calculate the required functions instead. These same interpolation formulas nevertheless continue to be used as part of the software algorithms for solving differential equations.\n\nFamous numerical software\nIn order to support numerical analysts, many kinds of numerical software has been created:\n MATLAB - made by","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"of the Melbourne College of Divinity\n Eidiko Tmima Alexiptotiston, Greek special operations unit\n A numerical weather prediction model formally known as the Eta","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Forecasting is studying and saying what is likely to happen in the future. It is similar to predicting, but usually forecasting is done with scientific methods. Forecasting can be done for many different things, like weather forecasting (predicting the weather) or economy forecasting.  Science cannot know the future for sure, so forecasters try to identify the most probable events, and sometimes they are wrong.\n\nWords","type":"Document"}],"18":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Sustainability means that a process or state can be maintained at a certain level for as long as is wanted.\n\nOne definition of sustainability is the one created by the Brundtland Commission, led by the former Norwegian Prime Minister Gro Harlem Brundtland. The Commission defined sustainable development as development that \"meets the needs of the present without compromising the ability of future generations to meet their own needs.\"\n\nSustainability relates to the connection of economic, social, institutional and environmental aspects of human society, as well as the non-human environment. Some overarching principles of sustainability include minimalism, efficiency, resilience and self-sufficiency. Sustainability is one of the four Core Concepts behind the 2007 Universal Forum of Cultures.\n\nRelated pages\n\n Environmentalism\nSecond law of thermodynamics\n Simple living\n\nNotes and References\n\nFootnotes\n\nReferences\n\nBibliography\n \n AtKisson, A. 1999. Believing Cassandra, An Optimist looks at a Pessimist\u2019s World,","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"The Sustainable Development Goals (SDGs) are created by the [United Nations] and promoted as the Global Goals for Sustainable Development. They replaced the [Millennium Development Goals] that expired at the end of 2015. The SDGs run from 2015 to 2030. There are 17 goals and 169 specific targets for those goals.\n\nGoals\n\nIn August of 2015 193 countries agreed to the following 17 goals:\n\n No poverty \n Zero hunger \n Good health and wellbeing\n Quality education \n Gender equality\n Clean water and sanitation\n Affordable and clean energy \n Decent work and economic growth \n Industry, innovation and infrastructure\n Reduce inequality \n Sustainable cities and communities \n Responsible consumption and production\n Climate action \n Life below water\n Life on land\n Peace and justice.  Strong institutions\n Partnerships for the goals\n\nReferences\n\nSustainability\nDevelopment\nUnited Nations","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Sustainable development''' is a way for people to use resources without the resources running out. It means doing development without damaging or affecting the environment.\nThe term used by the Brundtland Commission defined it as development with sustainability that \"meets the needs of the present and don't compromise the ability of future generations to meet their own needs.\"\n\nEveryone wants a better place to live. Some people want better homes and housing, while other people want better schools, more jobs, better shops, or cleaner and safer streets. Others may want all these things. Whatever the problems in any neighbourhood, they can usually be grouped into three issues. People need:\n a better environment \u2013 that means green spaces, play areas, no litter, nice gardens, decent houses, less noise and pollution. The resources used should renew over generations.\n a better economy \u2013 that means jobs, reasonable prices, cheaper heat and light, no loan sharks\n better social conditions \u2013 that means good leisure facilities, lots of community groups offering sports","type":"Document"}],"19":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Porto Alegre: Medical Arts.\n 2004. From being to doing: the origins of the biology of cognition, with Bernhard Poerksen.\n 2009. The Origins of humanness in the biology of love, with Gerda Verden-Zoller and Pille Brunnel.\n 2004. From biology to psychology. \n 2009. Sense of humanity.\n\nReferences \n\n1928 births\nBiologists\nSystems scientists\n2021 deaths\nChilean scientists\nChilean writers\nPhilosophers\nPeople from Santiago\nDeaths from pneumonia","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Pragmatic ethics is a kind of ethics that focuses  on  the development in society: People such as John Dewey believe that the moral progress a society makes is related to the progress and level in science of that society. Scientists look at hypotheses and examine them; they can then act in such a way that they believe these hypotheses to be true. When science advances, future scientists can replace a hypothesis with a better one. \n\nEthics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"a short section of 30 pages at the end of the book. Yet because of this section, the (apparently) new field of sociobiology became the subject of heated controversy. The criticism was driven by political events of the day.\n\n\"The mid-1970s were years of intense political activity on campuses, much of it initiated by left-wing professors and their students who opposed the war in Vietnam. At Harvard University [Wilson's employer] the war... came under fire from a number of scholars of the Marxist or semi-Marxist persuasion... Marxist philosophy is founded on the premise of the perfectability of human institutions through ideological prescription. Therefore, persons with Marxist views were particularly unreceptive to the notion that an evolved 'human nature' exists\".\n\nCriticism by Richard Lewontin and Stephen Jay Gould, and the Sociobiology Study Group hinted that there was some relationship between these ideas and some of the worst events in history. The main concern of the critics seemed to be the idea that","type":"Document"}],"20":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Lateral thinking is a term invented by Edward de Bono, a Maltese psychologist, physician and writer. It first appeared in the title of his book The Use of Lateral Thinking, published in 1967. De Bono explains lateral thinking as methods of thinking about changing concepts and perception. Lateral thinking is about reasoning that is not immediately obvious and about ideas that may not be obtainable by using only traditional step-by-step logic. \n\nEveryday life","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Problem solving is a mental activity related to intelligence and thinking. It consists of finding solutions to problems. A problem is a situation that needs to be changed. It suggests that the solution is not totally obvious, for then it would not be a problem. A great deal of human life is spent solving problems. Social life is based on the notion that together we might solve problems which we could not as individuals. \n\nThe word \"problem\" comes from a Greek word meaning an \"obstacle\" (something that is in your way). If someone has a problem, they have to find a way of solving the problem. The way to solve it is called a solution. Some problem-solving techniques have been developed and used in artificial intelligence, computer science, engineering, and mathematics. Some are related to mental problem-solving techniques studied in gestalt psychology, cognitive psychology. and chess.\n\nProblems can be classified as ill-defined or well-defined.  Ill-defined problems are those that do not have clear goals, solution","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Universal reason is something that philosophers think is at the bottom of a thinking system that allows it to understand certain natural things that are generally complex.\n\nPhilosophy","type":"Document"}],"21":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"a process in which a physicist-observer takes part, but rather <u\/l>any interaction between classical and quantum objects regardless of any observer<\/u\/l>.\n\nThe idea of indeterminacy\n\nThe uncertainty principle came from Werner Heisenberg's matrix mechanics. Max Planck  already knew that the energy of a unit of light is proportional to the frequency of that unit of light (), and that its amount of energy can be expressed in familiar terms such as the joule by using a proportionality constant. The constant he gave the world is now called the Planck constant and is represented by the letter h.  When matrices are used to express quantum mechanics, frequently two matrices have to be multiplied to get a third matrix that gives the answer the physicist is trying to find. But multiplying a matrix such as P (for momentum) by a matrix such as X (for position) gives a different answer matrix from the one you get when you multiply X by P. The result of multiplying P by X","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"force carriers\u2014would appear to defy mechanical principles altogether. None could predict a quantum particle's location from moment to moment.\n\nIn the slit experiment, an electron would travel through one hole placed in front of it. Yet a single electron would travel simultaneously though multiple holes, however many were placed in front of it. The single electron would leave on the detection board an interference pattern as if the single particle were a wave that had passed through all the holes simultaneously. And yet this occurred only when unobserved. If light were shone on the expected event, the photon's interaction with the field would set the electron to a single position.\n\nBy the uncertainty principle, any quantum particle's exact location and momentum cannot be determined with certainty, however. The particle's interaction with the observation\/measurement instrument deflects the particle such that greater determination of its position yields lower determination of its momentum, and vice versa.\n\nField theory quantized \n\nBy extending quantum mechanics across a field, a consistent pattern emerged. From location","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"anything changed, but our measuring itself makes a change, and the best we can hope to do is to reduce to a minimum the energy we contribute to the electron by measuring it. That minimum amount of energy has the Planck constant as one of its factors.\n\nUncertainty goes beyond matrix math\n\nHeisenberg's uncertainty principle was found in the earliest equations of the \"new\" quantum physics, and the theory was given by using matrix math. However, the uncertainty principle is a fact about nature, and it shows up in other ways of talking about quantum physics such as the equations made by Erwin Schr\u00f6dinger.\n\nIndeterminacy in nature, not uncertainty of humans\n\nThere have been two very different ways of looking at what Heisenberg discovered: Some people think that things that happen in nature are \"determinate,\" that is, things happen by a definite rule and if we could know everything we need to know we could always say what will happen next. Other people think that things","type":"Document"}],"22":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"samples from a production lot) based on how well it met its design specifications. In contrast, Statistical Process Control uses statistical tools to observe the performance of the production process in order to predict significant deviations that may later result in rejected product.\n\nTwo kinds of variation occur in all manufacturing processes: both these types of process variation cause subsequent variation in the final product. The first is known as natural or common cause variation and consists of the variation inherent in the process as it is designed. Common cause variation may include variations in temperature, properties of raw materials, strength of an electrical current etc. The second kind of variation is known as special cause variation, or assignable-cause variation, and happens less frequently than the first. With sufficient investigation, a specific cause, such as abnormal raw material or incorrect set-up parameters, can be found for special cause variations.\n\nFor example, a breakfast cereal packaging line may be designed to fill each cereal box with 500\u00a0grams of product, but some boxes will have slightly more","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"experimental data\".\n\nReferences\n\n \n Basu D. (1980b). \"The Fisher Randomization Test\", reprinted with a new preface in Statistical Information and Likelihood : A Collection of Critical Essays by Dr. D. Basu ; J.K. Ghosh, editor. Springer 1988.\n \n Salsburg D. (2002) The Lady Tasting Tea: how statistics revolutionized science in the Twentieth Century W.H. Freeman \/ Owl Book. \n\nExperiments\nStatistics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Informatica, 30:3\u201331, 2006.\n\nFurther reading \n\n Bradley, R.A. and Terry, M.E. (1952). Rank analysis of incomplete block designs, I. the method of paired comparisons. Biometrika, 39, 324\u2013345.\n David, H.A. (1988). The Method of Paired Comparisons. New York: Oxford University Press.\n Luce, R.D. (1959). Individual Choice Behaviours: A Theoretical Analysis. New York: J. Wiley.\n Thurstone, L.L. (1927).  A law of comparative judgement. Psychological Review, 34, 278\u2013286.\n Thurstone, L.L. (1929).  The Measurement of Psychological Value.  In T.V. Smith and W.K. Wright (Eds.), Essays in Philosophy by Seventeen Doctors of Philosophy of the \tUniversity of Chicago.  Chicago: Open Court.\n Thurstone, L.L.","type":"Document"}],"23":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"no reason to think that this is true at this time, but we might want to note it as another possible answer.\n\nReplication crisis \nThe replication crisis (or replicability crisis) refers to a crisis in science. Very often the result of a scientific experiment is difficult or impossible to replicate later, either by independent researchers or by the original researchers themselves. While the crisis has long-standing roots, the phrase was coined in the early 2010s as part of a growing awareness of the problem.\n\nSince the reproducibility of experiments is an essential part of the scientific method, the inability to replicate studies has potentially grave consequences.\n\nThe replication crisis has been particularly widely discussed in the field of psychology (and in particular, social psychology) and in medicine, where a number of efforts have been made to re-investigate classic results, and to attempt to determine both the validity of the results, and, if invalid, the reasons for the failure of replication.\n\nRecent discussions have made this problem better","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"quite common in science for some studies to contradict others, for example in cases where different methods are used to measure an outcome, or where human error or chance may lead to unusual results. This means that there is often a study someone can use to support their claim, and they can cherry pick that one study even if many more contradict it.\n\nReferences\n\nLogical fallacies","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Replication may refer to:\n\nIn science:\n Replication (scientific method), one of the main principles of the scientific method\n Replication (statistics), the repetition of a test or complete experiment\n Self-replication, the process in which something (a cell, virus, program) makes a copy of itself\n DNA replication, the process of copying a double-stranded DNA molecule\n Semiconservative replication, mechanism of DNA replication\n Replication (metallography), the use of thin plastic films to duplicate the microstructure of a component\n\nIn computing:\n Replication (computing), the use of redundant resources to improve reliability or performance","type":"Document"}],"24":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"and making choices in their own best interest. \n\"I will state that coercive persuasion and thought reform techniques are effectively practiced on na\u00efve, uninformed subjects with disastrous health consequences. I will try to give enough information to indicate my reasons for further inquiries as well as review of applicable legal processes\".\n\nThe following methods have been used in some or all cults studied:\n People are put in physically or emotionally distressing situations;\n Their problems are reduced to one simple explanation, which is repeatedly emphasized;\n They receive what seems to be unconditional love, acceptance, and attention from a charismatic leader or group;\n They get a new identity based on the group;\n They are subject to entrapment (isolation from friends, relatives and the mainstream culture) and their access to information is severely controlled.\n\nThis view is disputed by some. Society for the Scientific Study of Religion stated in 1990 that there was not sufficient research for a consensus, and that \"one should not automatically equate the techniques involved in the process","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"well developed, it develops even more common. The theory has been used to show why people join groups who really want things to happen (activist groups), to organize the external (real, actual) and internal (perceived) parts (dimensions) of problem recognition, and to learn whether information that is used in information processing (processed information) can create publics. Also, some more research was done on the internal and external dimensions of problem recognition, constraint recognition, and level of involvement (Grunig & Hon, 1988; Grunig, 1997). The research is about whether the ideas are internal or external. The research shows that if the concepts are internal, they can be changed by communication, and that if they are external, then the holdable things that are around the person need to be changed in order for the person's concept of the variables to change (Grunig, 1997, p.\u00a025). But, there is a small amount","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Tuckman's stages of group development is a model of group development made by Bruce Tuckman in 1965. It has four phases: Forming, Storming, Norming and Performing. \n\nForming is when the members of a team just got together.\nStorming is when they are in conflict and are not agreeing with each other.\nNorming is when they have finished deciding what is \"normal\".\nPerforming is when they are working together efficiently.\n\nTuckman believed that these stages are all necessary and always happen in order for a team:\nto grow\nto face challenges\nto tackle problems\nto find solutions\nto plan work\nto deliver results\n\nThis model has become the basis for later models.\n\nMore reading on this topic can be found here: \n\nPsychology\nPerforming this is a stage of a fully functional group where members see themselves as a group and get involved in the task.","type":"Document"}],"25":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"predicted value of y (written as ).\n Given a variable y and a number of variables X1, ..., Xp that may be related to y, linear regression analysis can be applied to quantify the strength of the relationship between y and the Xj, to assess which Xj has no relationship with y at all, and to identify which subsets of the Xj contain redundant information about y.\n\nLinear regression models try to make the vertical distance between the line and the data points (that is, the residuals) as small as possible. This is called \"fitting the line to the data.\" Often, linear regression models try to minimize the sum of the squares of the residuals (least squares), but other ways of fitting exist. They include minimizing the \"lack of fit\" in some other norm (as with least absolute deviations regression), or minimizing a penalized version of the least squares loss function as in ridge regression. The least squares approach can also be used to fit models that are not linear.","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"In statistics and in machine learning, a linear predictor function is a linear function (linear combination) of a set of coefficients and explanatory variables (independent variables), whose value is used to predict the outcome of a dependent variable.  Functions of this sort are standard in linear regression, where the coefficients are termed regression coefficients. However, they also occur in various types of linear classifiers (e.g. logistic regression, perceptrons, support vector machines, and linear discriminant analysis), as well as in various other models, such as principal component analysis and factor analysis.  In many of these models, the coefficients are referred to as \"weights\".\n\nStatistics\nFunctions and mappings","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"in ridge regression. The least squares approach can also be used to fit models that are not linear. As outlined above, the terms \"least squares\" and \"linear model\" are closely linked, but they are not synonyms.\n\nUsage\n\nEconomics\n\nLinear regression is the main analytical tool in economics. For example, it is used to guess consumption spending, fixed investment spending, inventory investment, purchases of a country's exports, spending on imports, the demand to hold liquid assets, labor demand and labor supply.\n\nRelated pages \n\n Curve fitting\n Logistic regression\n Ordinary least squares\n\nReferences\n\nStatistics","type":"Document"}],"26":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Isotherms are lines drawn around places with the same temperature range on isotherm maps. Each point on this line shows one temperature reading, or the average of many temperature readings. Isotherm maps also have scales that tell the signals or colors for the different temperatures. Isotherm lines are usually curvy and not straight lines.\n\nMeteorology\nThermodynamics\n\nen:Contour line#Temperature and related subjects","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Map coloring is a term used for two different concepts: In geography and mapmaking it is used to say that colors are assigned to certain areas on a map. Examples of this are coloring that show the countries or divisions of a country, but also to visualize other data, for example the altitude. The other use is in mathematics: There it is used to describe the problem of finding the minimal number of colors needed to color a given map.\n\nIn mapmaking \nColor is very useful to show different features on a map. Typical uses of color include showing different countries, different temperatures, or different kinds of roads.\n\nDisplaying the information in different colors can affect the understanding or feel of the map. In many cultures, certain colors have certain meanings. For example, red can mean danger, green can mean nature, and blue can mean water, which can be confused with the sea.\n\nMapmakers may also use colors that are related to what they are mapping. For example, when mapping where it rains more","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"A weather map is a tool. It shows facts about the weather quickly.  Weather maps have been used from the mid-19th century, for study and for weather forecasting. Some maps show differences of temperature, and weather fronts. \n\nA station model is a symbolic picture showing the weather at a reporting station. Meteorologists made the station model to put down many weather elements in a small space on weather maps. Maps thickly filled with station-model plots can be hard to read. However, they help meteorologists, pilots, and mariners to see important weather patterns. A computer draws a station model for every place of observation. The station model is mostly used for surface-weather maps. It can also be used to show the weather in the sky, though. A complete station-model map lets people study patterns in air pressure, temperature, wind, cloud cover, and precipitation.\n\nHistory \n\nPeople first began using weather charts in a modern way in the mid-19th century. They began using","type":"Document"}],"27":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Alhazen<ref> (Arabic: \u0623\u0628\u0648 \u0639\u0644\u064a \u0627\u0644\u062d\u0633\u0646 \u0628\u0646 \u0627\u0644\u062d\u0633\u0646 \u0628\u0646 \u0627\u0644\u0647\u064a\u062b\u0645, Latinized: Alhacen or Ibn al-Haytham)<\/ref> or Alhacen or ibn al-Haytham (965\u20131039) was a pioneer of modern optics. Some have also described him as a \"pioneer of the modern scientific method\" and \"first scientist\", but others think this overstates his contribution. Alhazen's Risala fi\u2019l-makan (Treatise on Place) discussed theories on the motion of a body. He maintained that a body moves perpetually unless an external force stops it or changes its direction of motion. He laid foundations for telescopic astronomy.\n\nHe was an Arab Muslim polymath who made contributions to the principles of optics, as well as to anatomy, engineering, mathematics, medicine, ophthalmology, philosophy, physics, psychology, Muslim","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"to anatomy, engineering, mathematics, medicine, ophthalmology, philosophy, physics, psychology, Muslim theology, visual perception. He is sometimes called al-Basri (Arabic: \u0627\u0644\u0628\u0635\u0631\u064a), after his birthplace in the city of Basra in Iraq (Mesopotamia).\n\nAlhazen lived mainly in Cairo, Egypt, dying there at age 74. Over-confident about practical application of his mathematical knowledge, he thought he could regulate the floods of the Nile. When he was ordered by Al-Hakim bi-Amr Allah, the sixth ruler of the Fatimid caliphate, to carry out this operation, he realized he could not do it, and retired from engineering. Fearing for his life, he pretended to be mad, and was placed under house arrest. For the rest of his life he devoted himself entirely to his scientific work.\n\nRelated pages\n Islamic Golden Age\n Book of Optics\n Scientific method\n\n References \n\n Other websites","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"and, if invalid, the reasons for the failure of replication.\n\nRecent discussions have made this problem better known.\n\nHistorical aspects \nElements of scientific method were worked out by some early students of nature.\n \"We consider it a good principle to explain the phenomena by the simplest hypothesis possible.\" Ptolemy (85165\u00a0AD). This is an early example of what we call Occam's razor.\n Ibn al-Haytham (Alhazen) (965\u20131039), Robert Grosseteste (1175\u20131253) and Roger Bacon (1214\u20131294), all made some progress in developing scientific method.\n Scientists in the 17th century started agreeing that the experimental method is the main way to find the truth. This was done in western Europe by men like Galileo, Kepler, Hooke, Boyle, Halley and Newton. At the same time, the microscope and the telescope were invented (in Holland), and the Royal Society was formed. Instruments,","type":"Document"}],"28":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Vector graphics (also called graphical modeling, or object-oriented graphics) is a type of computer graphics. Vector graphics uses geometrical objects, like points, lines, curves, and polygons to model the image. Mathematics can be used to describe the graphics. Most often vectors and matrices are used. The first major use of vector graphics was in the Semi-Automatic Ground Environment air defense system.\n\nThe other way to model computer graphics is to use raster graphics. Raster graphics model images as a collection of pixels. Unlike raster images, vector-based images can be scaled indefinitely without loss of quality. Vector graphics are most often used for diagrams, and other things that can be described using simple shapes. Photographs are most often raster images.\n\nRelated pages\nRaster graphics\n\nComputer graphics\nVector graphics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"A graph is a picture designed to express words, particularly the connection between two or more quantities. You can see a graph on the right.\n\nA simple graph usually shows the relationship between two numbers or measurements in the form of a grid. If this is a rectangular graph using Cartesian coordinate system, the two measurements will be arranged into two different lines at right angle to one another. One of these lines will be going up (the vertical axis). The other one will be going right (the horizontal axis). These lines (or axes, the plural of axis) meet at their ends in the lower left corner of the graph.\n\nBoth of these axes have tick marks along their lengths. You can think of each axis as a ruler drawn on paper. So each measurement is indicated by the length of the associated tick mark along the particular axis.\n\nA graph is a kind of chart or diagram. However, a chart or a diagram may not relate one quantity to other quantities. Flowcharts and tree diagrams are charts or","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"techniques, which display a relationship between two variables that take either discrete or a continuous ranges of values; examples:\n\nSchematics and other types of diagrams, e.g.,\n\nReferences \n\n \nNon-verbal communication","type":"Document"}],"29":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science.\n\nThe idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs.\n\nMachine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision.\n\nUsing machine learning has risks. Some algorithms create a final model which is a black box. Models have been criticized for biases in hiring, criminal justice, and recognizing faces.\n\nReferences \n\nArtificial intelligence\nLearning","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"fields. A simple example is attempting to find the smallest possible difference in the distance of two objects in two-dimensional space (x and y). In this context, the derivative of the function that gives the difference is taken in order to find the minimum. A more complicated example is in Machine Learning, in which the optimization function attempts to find the global minimum of the loss function in order to minimize the difference or loss between the algorithm\u2019s predictions and the actual values. This example is more difficult as Machine learning algorithms often utilize multidimensional data usually in the form of tensors yielding more complicated functions.\n\nRelated software\nToday, there are many tools to support optimization studies:\n MATLAB\n Wolfram Mathematica\n\nReferences\n\nScience\nMathematics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a classifier. Usually, the system uses inductive reasoning to generalize the training data.\n\nArtificial intelligence","type":"Document"}],"30":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science.\n\nThe idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs.\n\nMachine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision.\n\nUsing machine learning has risks. Some algorithms create a final model which is a black box. Models have been criticized for biases in hiring, criminal justice, and recognizing faces.\n\nReferences \n\nArtificial intelligence\nLearning","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a classifier. Usually, the system uses inductive reasoning to generalize the training data.\n\nArtificial intelligence","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"to make something that can say how the different data attributes are connected\/influence each other. The size and the colour are related. So if you know something about the size, you can guess the colour.)\n Using a Neural network (Trying to make a model like a brain, which is hard to understand, but a computer can tell that if the apple is green it has a higher chance to be sour, if we tell the computer the apple is green. So this is like a black box model, we do not know how it works, but it works.) \n Using Classification tree (With all other knowledge trying to say what one other thing about the thing we are looking at will be. Here is an apple with a size, a colour and shininess, what will it taste like?)\n\nComputer science","type":"Document"}],"31":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Scientific method refers to ways to investigate phenomena, get new knowledge, correct errors and mistakes, and test theories.\n\nThe Oxford English Dictionary says that scientific method is: \"a method or procedure that has characterized natural science since the 17th century, consisting in systematic observation, measurement, and experiment, and the formulation, testing, and modification of hypotheses\".\n\nA scientist gathers empirical and measurable evidence, and uses sound reasoning. New knowledge often needs adjusting, or fitting into, previous knowledge.\n\nCriterion \nWhat distinguishes a scientific method of inquiry is a question known as 'the criterion'. It is an answer to the question: is there a way to tell whether a concept or theory is science, as opposed to some other kind of knowledge or belief? There have been many ideas as to how it should be expressed. Logical positivists thought a theory was scientific if it could be verified; but Karl Popper thought this was a mistake. He thought a theory was not scientific unless there was some way it","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"primarily attributed to the accuracy and objectivity (i.e. repeatability) of observation of the reality that science explores.\n\nThe role of observation in the scientific method \n\nScientific method refers to techniques for investigating phenomena, acquiring new knowledge, or correcting and integrating previous knowledge. To be termed scientific, a method of inquiry must be based on gathering observable, empirical and measurable evidence subject to specific principles of reasoning. A scientific method consists of the collection of data through observation and experimentation, and the formulation and testing of hypotheses.\n\nAlthough procedures vary from one field of inquiry to another, identifiable features distinguish scientific inquiry from other methodologies of knowledge. Scientific researchers propose hypotheses as explanations of phenomena, and design experimental studies to test these hypotheses. These steps must be repeatable in order to dependably predict any future results. Theories that encompass wider domains of inquiry may bind many hypotheses together in a coherent structure. This in turn may help form new hypotheses or place groups of hypotheses into context.\n\nAmong other facets shared by the","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"methods used by scientists to find knowledge. The main features of the scientific method are:\n Scientists identify a question or a problem about nature. Some problems are simple, such as \"how many legs do flies have?\" and some are very deep, such as \"why do objects fall to the ground?\"\n Next, scientists investigate the problem. They work at it, and collect facts. Sometimes all it takes is to look carefully.\n Some questions cannot be answered directly. Then scientists suggest ideas, and test them out. They do experiments and collect data.\n Eventually, they find what they think is a good answer to the problem. Then they tell people about it.\n Later, other scientists may agree or not agree. They may suggest another answer. They may do more experiments. Anything in science might be revised if we find out the previous solution was not good enough.\n\nAn example \nA famous example of science in action was the expedition led by Arthur Eddington to Principe Island in Africa in","type":"Document"}],"32":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Meditation tries to get past the \"thinking\" mind and aims to go into a deeper state of relaxation or awareness.\n\nMeditation is a practice where an individual trains attention and awareness to get to a clearer and calmer state. Scholars have found meditation difficult to define. The practices vary both between traditions and within them.\n\nIt is a common practice in many religions including Buddhism, Christianity (sometimes), Taoism, Hinduism (where Yoga is important)\nand other religions. Meditation has now become a modern trend, showing many health benefits.\nThe initial origin of meditation is from the Vedic times of India.\n\nBuddhist meditation \n\nIn Buddhism, three things are very important: being a good person, making the mind stronger, and understanding (Insight or Wisdom) about why people are in pain (Dukkha). For Buddhists, meditation is used to calm the mind so that the mind can better see the cause of pain. Buddhists believe that this type of seeing can end","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Mih\u00e1ly 1996. Finding flow: the psychology of engagement with everyday life. Basic Books.  [a popular exposition emphasizing technique]<\/ref>\n\n Clear goals. Expectations and rules are known and goals are attainable and within one's skills and abilities.  Moreover, the challenge level and skill level should both be high.\n Concentrating: a high degree of concentration on a limited field of attention (a person engaged in the activity will have the opportunity to focus and to delve deeply into it).\n A loss of the feeling of self-consciousness.\n Distorted sense of time, one's sense of time is altered.\n Direct and immediate feedback (successes and failures in the course of the activity are apparent, so that behavior can be adjusted as needed).\n A balance between ability level and challenge: the activity is neither too easy nor too difficult.\n A sense of control over the situation or activity.\n The activity is intrinsically rewarding, so there is an effortlessness of action.\n A lack","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"the mind can better see the cause of pain. Buddhists believe that this type of seeing can end pain.\n\nBuddhist meditation is not just used for spiritual reasons. Research shows that Buddhist meditation lowers stress, anxiety and depression.\n\nMost types of Buddhist meditation focus on something. The most popular things to focus on include breath,  metta or Loving-Kindness towards all, other recollections, situational mindfulness and religious images and sounds.\n\nChristian meditation \nChristians sometimes meditate by thinking about small parts of the Bible, or by saying the words of a prayer to themselves over and over. Meditation is an expression of Christian prayer. In the Catechism of the Catholic Church is specified that by means of meditation \"The mind seeks to understand the why and how of the Christian life, in order to adhere and respond to what the Lord is asking\"; also it is pointed out that \"meditation engages thought, imagination, emotion, and desire. This mobilization of faculties is necessary in","type":"Document"}],"33":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"details some explicit relationships between the objects of the diagram. For example, the arrow between the agent and CAT:Elsie depicts an example of an is-a relationship, as does the arrow between the location and the MAT. The arrows between the gerund SITTING and the nouns agent and location express the diagram's basic relationship; \"agent is SITTING on location\"; Elsie is an instance of CAT.\n\nAlthough the description sitting-on (graph 1) is more abstract than the graphic image of a cat sitting on a mat (picture 1), the delineation of abstract things from concrete things is somewhat ambiguous; this ambiguity or vagueness is characteristic of abstraction. Thus something as simple as a newspaper might be specified to six levels, as in Douglas Hofstadter's illustration of that ambiguity, with a progression from abstract to concrete in G\u00f6del, Escher, Bach (1979):\n(1) a publication\n(2) a newspaper\n(3) The San Francisco","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Each of these smaller areas (room, state, number) is next to other small areas (other rooms\/states\/numbers). The places where the areas meet are connections. If we write down on paper a list of spaces, and the connections between them, we have written down a description of a space -- a topological space. All topological spaces have the same properties such as connections, and are made of the same structure (a list of smaller areas). This makes it easier to study how spaces behave. It also makes it easier to write algorithms. For instance, to program a robot to navigate a house, we simply give it a list of rooms, the connections between each room (doors), and an algorithm that can work out which rooms to go through to reach any other room. For more examples of this type of problem, look at Graph theory.\n\nWe can go further by creating subdivisions of subdivisions of space. For instance, a nation divided into states, divided into counties, divided into","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"writing space in which traces of authority persist only as local and contingent effects, the social equivalent of the deconstructed author-function. A \"populite\" culture might mark the first step toward realization of Jean-Francois Lyotard's \"game of perfect information\" where all have equal access to the world of data, and where \"[g]iven equal competence (no longer in the acquisition of knowledge, but in its production), what extra performativity depends on in the final analysis is 'imagination,' which allows one either to make a new move or change the rules of the game.\" This is the utopia of information-in-process, the ultimate wetware dream of the clerisy: discourse converted with 100 percent efficiency into capital, the mechanism of that magical process being nomology or rule-making\u2014admittedly a rather specialized form of \"imagination.\"\n\nWorks by Ted Nelson\n Life, Love, College, etc. (1959)\n Computer Lib: You can and must","type":"Document"}],"34":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"he began his systematic approach of the analysis of real data as the springboard for the development of new statistical methods.\n\nHe began to pay particular attention to the labour involved in the necessary computations, and developed practical methods. In 1925, his first book was published: Statistical methods for research workers. This went into many editions and translations in later years, and became a standard reference work for scientists in many disciplines. In 1935, this was followed by The design of experiments, which also became a standard.\n\nHis work on the theory of population genetics made him one of the three great figures of that field, together with Sewall Wright and J.B.S. Haldane. He was one of the founders of the neo-Darwinian modern evolutionary synthesis. In addition to founding modern quantitative genetics with his 1918 paper, he was the first to use diffusion equations to attempt to calculate the distribution of gene frequencies among populations.\n\nHe pioneered the estimation of genetic linkage and gene frequencies by maximum","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"law \n\nWeinberg developed the principle of genetic equilibrium independently of British mathematician G.H. Hardy. He delivered an exposition of his ideas in a lecture on 13 January 1908, about six months before Hardy's paper was published in English. His lecture was printed later that year in the society's yearbook. \n\nWeinberg's contributions were unrecognized in the English speaking world for more than 35 years. Curt Stern, a German geneticist who emigrated to the United States before World War II, pointed out in a brief paper in Science that Weinberg's exposition was both earlier and more comprehensive than Hardy's.\n\nAscertainment bias \nWeinberg pioneered studies of twins, and developed techniques to analyse phenotypic variation. His aim was to partition this variance into genetic and environmental components. In the process, he recognized that ascertainment bias was affecting many of his calculations, and he produced methods to correct for it. \n\nWeinberg observed that proportions of homozygotes","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"and the length of the month are also ancient.\n\nThe Round-to-even method has served as the ASTM (E-29) standard since 1940. The origin of the terms unbiased rounding and statistician's rounding are fairly self-explanatory. In the 1906 4th edition of Probability and Theory of Errors  Robert Simpson Woodward called this \"the computer's rule\" indicating that it was then in common use by human computers who calculated mathematical tables. Churchill Eisenhart's 1947 paper \"Effects of Rounding or Grouping Data\" (in Selected Techniques of Statistical Analysis, McGrawHill, 1947, Eisenhart, Hastay, and Wallis, editors) indicated that the practice was already \"well established\" in data analysis.\n\nThe origin of the term \"bankers' rounding\" remains more obscure. If this rounding method was ever a standard in banking, the evidence has proved extremely difficult to find. To the contrary, section 2 of the European Commission","type":"Document"}],"35":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"for some time and measure their blood pressure before and after.\n\nDescriptive and inferential statistics \nNumbers that describe the data one can see are called descriptive statistics. Numbers that make predictions about the data one cannot see are called inferential statistics.\n\nDescriptive statistics involves using numbers to describe features of data. For example, the average height of women in the United States is a descriptive statistic: it describes a feature (average height) of a population (women in the United States).\n\nOnce the results have been summarized and described, they can be used for prediction. This is called inferential statistics. As an example, the size of an animal is dependent on many factors. Some of these factors are controlled by the environment, but others are by inheritance. A biologist might therefore make a model that says that there is a high probability that the offspring will be small in size\u2014if the parents were small in size. This model probably allows to predict the size in better ways than by just guessing at random. Testing whether","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"This model probably allows to predict the size in better ways than by just guessing at random. Testing whether a certain drug can be used to cure a certain condition or disease is usually done by comparing the results of people who are given the drug against those who are given a placebo.\n\nMethods \nMost often, we collect statistical data by doing surveys or experiments. For example, an opinion poll is one kind of survey. We pick a small number of people and ask them questions. Then, we use their answers as the data.\n\nThe choice of which individuals to take for a survey or data collection is important, as it directly influences the statistics. When the statistics are done, it can no longer be determined which individuals are taken. Suppose we want to measure the water quality of a big lake. If we take samples next to the waste drain, we will get different results than if the samples are taken in a far-away and hard-to-reach spot of the lake.\n\nThere are two kinds of problems which are","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"reduction) from the co-occurrence of those terms in the whole set of documents.\n Models with transcendent term interdependencies allow a representation of interdependencies between terms, but they do not allege how the interdependency between two terms is defined. They rely an external source for the degree of interdependency between two terms. (For example a human or sophisticated algorithms.)\n\nIn addition, each model has parameters, which influence its performance. Some of the models make a number of assumption about the data; they were developed for a very special purpose. Using such a model for a different purpose may not yield good results.\n\nComputer science","type":"Document"}],"36":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"same in both cases; it is then possible to write another equation, which replaces the two equations and reduces the number of equations by one.\nGaussian elimination\nQR decomposition\nCholesky decomposition\nCramer's rule\nExamples for iterative methods are:\nRelaxation, including the Gauss-Seidel and Jacobi methods\nMultigrid method\nKrylow method\n\nThere are examples such as geodesy where there many more measurements than unknowns. Such a system is almost always overdetermined and has no exact solution. Each measurement is usually inaccurate and includes some amount of error. Since the measurements are not exact, it is not possible to obtain an exact solution to the system of linear equations; methods such as Least squares can be used to compute a solution that best fits the overdetermined system. This least squares solution can often be used as a stand-in for an exact solution.\n\nSolving a system of linear equations has a complexity of at most O (n3). At least n2","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"alignment\n Reduction (town), a form of Catholic mission in South America in the 17th and 18th centuries\n Purchasing reduction, in economics and in waste management, is the process of decreasing the purchase of consumer goods\n Reduction (Sweden), in 1680 a return of lands to the Crown earlier granted to the nobility.\n Waste reduction is the first and most desirable component of the waste hierarchy (reduce, reuse, recycle)\n\nIn mathematics and computer science''':\n Reduction (mathematics), the process of manipulating a series of equations or matrices into a desired 'simpler' format\n Reduction property, in descriptive set theory, a pointclass allows partitioning the union of two sets in the pointclass into two disjoint sets in the same pointclass\n Reduction (complexity), in computational complexity theory, the transformation of an instance of one problem into an instance of another\n Reduce computer algebra system, a general-purpose computer algebra system geared towards applications in physics.\n Reduce (higher-order","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"geometric modeller\". Proc. Uncertainty in Geometric Computations,  1\u201314. Kluwer Academic Publishers, .\n L. H. de Figueiredo, J. Stolfi, and L. Velho (2003), \"Approximating parametric curves with strip trees using affine arithmetic\". Computer Graphics Forum, 22  2,  171\u2013179.\n C. F. Fang, T. Chen, and R. Rutenbar (2003), \"Floating-point error analysis based on affine arithmetic\". Proc. 2003 International Conf. on Acoustic, Speech and Signal Processing.\n A. Paiva, L. H. de Figueiredo, and J. Stolfi (2006), \"Robust visualization of strange attractors using affine arithmetic\". Computers & Graphics, 30  6,  1020\u2013 1026.\n\nSurveys\nL. H. de Figueiredo and J.","type":"Document"}],"37":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"In information theory, redundancy means that a message is encoded and transmitted using more bits that are necessary to encode the message. If a piece of information is redundant, it can be left out, without loss of information.  Redudant information such as checksums can be used to detect and correct errors in transmission or storage.\n\nOperations like data compression reduce redundancy. This can be good, as the data can be sent more quickly and take less space.  It can also be bad, if an error can no longer be corrected automatically.\n\nWhen using databases, redundancies must be avoided, as they can lead to inconsistencies. In this case, the process is called normalisation. \n\nComputer science","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"reduction) from the co-occurrence of those terms in the whole set of documents.\n Models with transcendent term interdependencies allow a representation of interdependencies between terms, but they do not allege how the interdependency between two terms is defined. They rely an external source for the degree of interdependency between two terms. (For example a human or sophisticated algorithms.)\n\nIn addition, each model has parameters, which influence its performance. Some of the models make a number of assumption about the data; they were developed for a very special purpose. Using such a model for a different purpose may not yield good results.\n\nComputer science","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"alignment\n Reduction (town), a form of Catholic mission in South America in the 17th and 18th centuries\n Purchasing reduction, in economics and in waste management, is the process of decreasing the purchase of consumer goods\n Reduction (Sweden), in 1680 a return of lands to the Crown earlier granted to the nobility.\n Waste reduction is the first and most desirable component of the waste hierarchy (reduce, reuse, recycle)\n\nIn mathematics and computer science''':\n Reduction (mathematics), the process of manipulating a series of equations or matrices into a desired 'simpler' format\n Reduction property, in descriptive set theory, a pointclass allows partitioning the union of two sets in the pointclass into two disjoint sets in the same pointclass\n Reduction (complexity), in computational complexity theory, the transformation of an instance of one problem into an instance of another\n Reduce computer algebra system, a general-purpose computer algebra system geared towards applications in physics.\n Reduce (higher-order","type":"Document"}],"38":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"a graphics gallery, a replay function, and the ability to view various endings once they are achieved during a normal game.\n\n\u00a0Manufacturer's description:\n\nIs a hero, to keep with the story made up only doing the animation drives ?love story begins with the fourth series of the port city of snow. The main character, had received the emotions live in apartments next to Sakuragi, loses his love. One day, I told the police that the incident happened to. When leading a secret desire, a mixture of truth and falsehood.\n\n\u00a0Features:\n\n First person perspective.\n 2D graphics\n Cartoon graphics\n Mystery, dating & Anime themes.\n\nPlayStation games\nPlayStation Portable games\n1998 video games\n2005 video games\nVisual novels\nJapan exclusive video games","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"She has studied about them until now and taught about cultural anthropology in Kawamura Gakuen Woman\u2019s University\n\nHer career as a writer started in 1989. She published her first work \u201cSeirei-no-Ki (Spirit Tree)\u201d. From that year she has written many stories until today.\n\nFictional Works\n\nShika-no-Oh series (King of the Deers) \nVan, a man who was the top of the \u201cDokkaku (a kind of army)\u201d , Yuna, a young girl who was saved by Van and Hossal, a doctor, had fought with the mysterious sickness named \u201cMizzal (black-wolf fever)\u201d.\n\nKemono-no-Soja series (The Beast Player) \nErin, an orphan girl met with a sacred young animal and grew with it experiencing various things, meeting with a lot of people and learning about what the creatures are.\n\nKoteki-no-Kanata (Beyond the Fox Whistle)","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"can be viewed. The game also makes the player view some of the files that the game uses to play.\n\nThe game has a lot of foreshadowing that tells the player certain things about the story. If the player decodes the character files, there are extra stories unlocked. At certain times special files appear in the game files. Text documents show up about the next scenes.\n\nPlot\nThe player's character is invited by his childhood friend, Sayori, to join the Literature Club. He meets the other members of the club. They are Natsuki, Yuri, and Monika. The player begins to get involved in the club and getting to know the girls better. Near the end of the first act, Sayori tells the player that she has depression and loves the player. Sayori soon commits suicide by hanging herself. The game shows a lot of glitches and it restarts.\n\nWhen the player begins a new game, the game is very close to the first run, but","type":"Document"}],"39":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"A generative model is a process for creating data that uses randomness.\n\nArtificial intelligence\nLearning\nStatistics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"In statistics and in machine learning, a linear predictor function is a linear function (linear combination) of a set of coefficients and explanatory variables (independent variables), whose value is used to predict the outcome of a dependent variable.  Functions of this sort are standard in linear regression, where the coefficients are termed regression coefficients. However, they also occur in various types of linear classifiers (e.g. logistic regression, perceptrons, support vector machines, and linear discriminant analysis), as well as in various other models, such as principal component analysis and factor analysis.  In many of these models, the coefficients are referred to as \"weights\".\n\nStatistics\nFunctions and mappings","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"has the disadvantage that the same list of values does not have a well-defined, deterministic median.\n\nMedian and mean \nMedian and mean are different in several ways. Mean is a better measure in many cases, because many of the statistical tests can use mean and standard deviation of two observations to compare them, while the same comparison cannot be performed using the medians.\n\nMedian is more useful when the variance of the values is not important, and we only need a central measure of the values. If the maximum value of a set of numbers changes while the other numbers of this set are kept the same, the mean of this set of numbers changes, but the median does not.\n\nAnother advantage of median is that it can be calculated sooner when we are studying survival data. For example, a researcher can calculate the median survival of patients with a kidney transplant, when half the patients participated in his study die. Calculating the mean survival requires continuing the study, and following all the patients until their death.\n\nExample","type":"Document"}],"40":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"In probability and statistics, Poisson distribution is a probability distribution. It is named after Sim\u00e9on Denis Poisson. It measures the probability that a certain number of events occur within a certain period of time. The events need to be unrelated to each other. They also need to occur with a known average rate, represented by the symbol  (lambda). \n\nMore specifically, if a random variable  follows Poisson distribution with rate , then the probability of the different values of  can be described as follows: \n\n    for  \n\nExamples of Poisson distribution include:\n The numbers of cars that pass on a certain road in a certain time\n The number of telephone calls a call center receives per minute\n The number of light bulbs that burn out (fail) in a certain amount of time\n The number of mutations in a given stretch of DNA after a certain amount of radiation\n The number of errors that occur in a system\n The number of Property & Casualty insurance claims experienced in a","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"The calculation of the last three quantities is explained in the respective Wiki pages. Then, with the help of formulas given in the previous section, the factors \u03bc and \u03b2 can be calculated. In this way, the CDF of the Gumbel distribution belonging to the data can be determined and the probability of interesting data values can be found.\n\nApplication \n\nIn hydrology, the Gumbel distribution is used to analyze such variables as monthly and annual maximum values of daily rainfall and river discharge volumes, and also to describe droughts.\n \nThe blue picture illustrates an example of fitting the Gumbel distribution to ranked maximum one-day October rainfalls showing also the 90% confidence belt based on the binomial distribution.\n\nReferences \n\nProbability distributions","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"heads (or tails) is still 50%).\n\nRelated pages \n\n Bernoulli distribution\n Poisson distribution\n\nReferences \n\nProbability distributions","type":"Document"}],"41":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"that submerge it by a time in the language no figurativo. Also Manterola  has worked the sculpture, converting each piece in an only piece using different materials so much the iron , steel cut ,copper , iron galvanised , nylon, stainless steel, resin or iron painted.\n\nAnother of the appearances to stand out of Manterola is that it believes in the synergies and in the collaborations with other artists and disciplines. It says that it exists a mutual enrichment in all maridaje. Proof of this are the exercises with artists like Gorka Larra\u00f1aga and Samuel Dougados, the project UNYON beside Ivory Jewellers and, more recently, the collaboration with the chef French H\u00e9l\u00e8ne Darroze, that has 3 stars Michelin, for the one who has designed the servilleteros of his restaurant of Paris and where in each table luce one of his sculptures.\n\nBibliography \n Article of Him Figaro of 18 September","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"authors of the various paintings, will draw the contours of the paintings on the roadway, first with chalk and then with lime, based on the original sketch, also using perforated cartoons (dusting technique).  The placement of the flowers is done by placing the petals, taken from the baskets, within the contours already traced on the street.  On Sunday evening Mass is celebrated in front of the Church of Saint Maria of Cima and, after a solemn Eucharistic celebration in which the bishop of Albano often takes part, the carpet is covered by the religious procession of the celebrants who bring the Blessed Sacrament to the not so distant Collegiate Church of the Holy Trinity.  The carpet is maintained, with replacements of withered petals, until Monday evening, when the destruction of the floral display bychildren (the so-called shoulder ) takes place.\n\nNote \n\n Anna Baldazzi and Renato Torti (edited by).  Genzano and the flower display   : anthology of","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"actual nature;\n in an ironic sense, it alludes to the idea that an already established artist would find a market and the consent of a critic for any work he produces, beyond its specific quality;\n the operation of Garau at the same time the artistic value of this work by Piero Manzoni is delicately conceptual art, and therefore accessible to all without restrictions due to either the purchase cost, material possession or physical accessibility, nor due to technical reproducibility. It is therefore, according to Duchamp, a typical \"anesthetic\".\n\nRelated works\n\nFiato d\u2019artista\nThe most famous related work is the Fiato d\u2019artista (Artist\u2019s Breath), involving red, blue or white balloons inflated by Piero Manzoni himself, closed with string and lead, with the name \"Piero Manzoni\" punched into it, then attached to a wooden base with a plaque on it using gesso. The pieces were made in 1960, and","type":"Document"}],"42":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"4D, meaning the common 4 dimensions, is a concept in mathematics. It has been studied by mathematicians and philosophers since the 18th century.  Mathematicians who studied four-dimension space in the 19th century include M\u00f6bius, Schl\u00e4fi, Bernhard Riemann, and Charles Howard Hinton.\n\nIn geometry, the fourth dimension is related to the other three dimensions  of length, width, and depth by imagining another direction through space. Just as the dimension of depth can be added to a square to create a cube, a fourth dimension can be added to a cube to create a tesseract.\n\n4D is also an important idea in physics, developed in the 20th century. In physics, it refers to the idea of time as a fourth dimension, added to the (3D) spatial dimensions.  Albert Einstein developed the idea of spacetime by connecting space and time together. The difference is that spacetime is not a Euclidean space,","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Dimensions are the way we see, measure and experience our world, by using up and down, right to left, back to front, hot and cold, how heavy and how long, as well as more advanced concepts from mathematics and physics. One way to define a dimension is to look at the degrees of freedom, or the way an object can move in a specific space. There are different concepts or ways where the term dimension is used, and there are also different definitions. There is no definition that can satisfy all concepts. \n\nIn a vector space  (with vectors being \"arrows\" with directions), the dimension of , also written as , is equal to the cardinality (or number of vectors) of a basis of  (a set which indicates how many unique directions  actually has). It is also equal to the number of the largest group of straight line directions of that space. \"Normal\" objects in everyday life are specified by three dimensions, which are usually called length, width and","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"objects in everyday life are specified by three dimensions, which are usually called length, width and depth. Mathematicians call this concept Euclidean space.\n\nDimensions can be used to measure position too. The distance to a position from a starting place can be measured in the length, width and height directions. These distances are a measure of the position.\n\nIn some occasions, a fourth (4D) dimension, time, is used to show the position of an event in time and space.\n\nOther Dimensions\nIn modern science, people use other dimensions. Dimensions like temperature and weight can be used to show the position of something in less simple spaces. Scientist study those dimension with dimensional analysis.\n\nMathematicians also use dimensions. In mathematics, dimensions are more general. Dimensions in mathematics might not measure things in the world. The rules for doing arithmetic with dimensions in mathematics might be different than usual arithmetic rules.\n\nDimensions and vectors\nVectors are used to show distances and directions. Vectors are often used in engineering and","type":"Document"}],"43":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"than operation on raw data. There are simple algorithms to calculate median, mean (statistics), standard deviation etc. from these tables.\n\nStatistical hypothesis testing is based on the assessment of differences and similarities between frequency distributions. This assessment involves measures of central tendency or averages, such as the mean and median, and measures of variability or statistical dispersion, such as the standard deviation or variance.\n\nA frequency distribution is said to be skewed when its mean and median are different. The kurtosis of a frequency distribution is the concentration of scores at the mean, or how peaked the distribution appears if depicted graphically\u2014for example, in a histogram. If the distribution is more peaked than the normal distribution it is said to be leptokurtic; if less peaked it is said to be platykurtic.\n\nFrequency distributions are also used in frequency analysis to crack codes and refer to the relative frequency of letters in different languages.\n\nStatistics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Bessel's correction has high importance in calculating standard deviation. As per Bessel's correction, we should consider n-1 separation while calculating standard deviation of sampled data.\n\nStatistics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"...,x25, with mean:\n\nIf we take another sample of 25 cups, we could easily expect to find values like 250.4 or 251.1 grams. A sample mean value of 280 grams, however, would be extremely rare if the mean content of the cups is in fact close to 250g. \n\nThere is a whole interval around the observed value 250.2 of the sample mean within which, if the whole population mean actually takes a value in this range, the observed data would not be considered particularly unusual. Such an interval is called a confidence interval for the parameter \u03bc. \n\nTo calculate such an interval, the endpoints of the interval have to be calculated from the sample, so they are statistics, functions of the sample X1, ..., X25, and hence are random variables themselves.\n\nIn our case, we may determine the endpoints by considering that the sample mean  from a normally distributed sample is also normally distributed, with the same expectation \u03bc, but","type":"Document"}],"44":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"the idea to a prospective producer, director, or composer.\n\nScenarios are also used in policy planning, and when trying out strategies against uncertain future developments. Here the key idea is for the scenario to be an overview, a summary, of a projected course of action, events or situations. Scenarios are widely used by organizations of all types to understand different ways that future events might unfold.\n\nTheater\nPlanning","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Scenario may refer to:\n Scenario, a brief description of an event.\n Screenplay, in movies.\n Scenario (computing), a typical interaction between the user and the system or between two software components.\n Scenario analysis, a process of analysing possible future events by considering alternative possible outcomes. \n Scenario paintball, a variant of the game of paintball.\n Scenario planning, a strategic planning method that some organisations use to make flexible long-term plans.\n Scenario test, a test based on a hypothetical story used to help a person think through a complex problem or system.\n Kingmaker scenario, in a game of three or more players, is an endgame situation where a losing player, him- or herself unable to win, has the capacity to determine which player among others is the winner.\n User scenario, used to communicate an idea for a product or experience involving interactivity.\nScenario (A Tribe Called Quest), a 1992 song by hip-hop group, A Tribe Called Quest.","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Planning is the way most organizations work to do big projects. It is thinking about what needs to happen, and then making a detailed plan. It may include a schedule.\n\nAll humans plan to some extent: it is a fundamental property of intelligent behaviour. In big organisations and government planning is a main activity. It combines forecasting  developments with scenarios of how to react to them.\n\nForecasting is predicting what the future will look like, whereas planning predicts what the future should look like.\n\nThe \"nuts and bolts\" of planning are the documents, diagrams, and meetings, the objectives and the strategy to be followed. Beyond this, planning has a different meaning depending on the context in which it is used.\n\nThe counterpart to planning is self-organization, when order emerges spontaneously out of seeming chaos.\n\nReferences","type":"Document"}],"45":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"A social network is a set of people who interact. This includes group organizations. The social relationships may include friendship\/affect, communication, economic transactions, interactions, kinship, authority\/hierarchy, trust, social support, diffusion, contagion, and so on. \n\nCalling social relationships a network calls attention to the pattern or structure of the set of relationships.\n\nA community social network is the pattern of relationships among a set of people and\/or organizations in a community. Each of these networks can involve social support, give people a sense of community, and \nlead them to help and protect each other.\n\nHow big a personal network becomes depends on the individual and the type of relationships considered. The set of people that a person knows well or with whom a person frequently interacts seldom exceeds several hundred. As the size of a network grows, keeping relationships is strained by the size. There is a so-called \"Law of 150\" which suggests that about 150 people is the best size for a village or","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"church or temple is almost always a center of a social network). Often the network has an identity of its own which is quite real, even though it may have no official recognition. Networks may be centered on places, or on families, or on worldwide communities with common interests.\n\nSources \nThe Law of 150 is documented in R.I.M. Dunbar 1992. Neocortex size as a constraint on group size in primates. Journal of Human Evolution. 20, pp.\u00a0469\u2013493.\n\nThe field of study which investigates human social life is social psychology.\n\nRelated pages \nSocial network service\n\nRelationships\nSocial groups","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Social psychology is the study in psychology of how people and groups interact. Researchers in this field are often either psychologists or sociologists. All social psychologists use both the individual and the group as their unit of analysis.\n\nDespite their similarity, psychological and sociological researchers tend to differ in their goals, approaches, methods, and terminology. They also favor separate academic journals and professional groups. The greatest period of collaboration between sociologists and psychologists was during the years immediately following World War II. Although there has been increasing isolation and specialization in recent years, some degree of overlap and influence remains between the two disciplines.\n\nReferences\n\nRelating pages\nCognitive psychology\nErich Fromm\nSociology\n\nBranches of psychology","type":"Document"}],"46":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"the base.\n\nFor example, a descriptive system widely used in Australia is based on structural characteristics based on life-form, plus the height and amount of foliage cover of the tallest layer or dominant species.\n\nFor shrubs 2\u20138 m high the following structural forms are categorized:\n dense foliage cover (70\u2013100%) \u2014 closed-scrub\n mid-dense foliage cover (30\u201370%) \u2014 open-scrub\n sparse foliage cover (10\u201330%) \u2014 tall shrubland\n very sparse foliage cover (<10%) \u2014 tall open shrubland\n\nFor shrubs less than 2 m high the following structural forms are categorized:\n dense foliage cover (70\u2013100%) \u2014 closed-heath\n mid-dense foliage cover (30\u201370%) \u2014 heath\n sparse foliage cover (10\u201330%) \u2014 low shrubland\n very sparse foliage cover (<10%) \u2014 low open shrubland\n\nReferences\n\nOther websites\nSelecting Shrubs for Your Home (University of Illinois","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"this area.  This is also where farming takes place.\n Below 1,000 metres are the lowlands.  Here, a larger variety of plants are produced. Aside from plants, villages are also in the lowlands because the temperature is easier for humans and farm animals.\n\nThe Alps is a classic example of what happens when a temperate area at lower altitude gives way to higher land. A rise from sea level into the upper regions causes the temperature to decrease. The effect of mountain chains on winds is to carry warm air belonging to the lower region into an upper zone, where it expands and loses heat, and drops snow or rain.\n\nPlants \nThe typical trees\u2014oak, beech, ash and sycamore maple have a natural height limit: the 'tree line'. Their upper limit matches the change in climate which comes with increasing height. The change from a temperate to a colder climate is also shown true by a change in the wild flowering plant life. This limit","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"more than one class, then all of those exams must be at a different time. The teacher wants to know if he can schedule all of the exams in the same day so that every student is able to take the exam for each of their classes.\n A farmer wants to take 100 watermelons of different masses to the market. She needs to pack the watermelons into boxes. Each box can only hold 20 kilograms without breaking.  The farmer needs to know if 10 boxes will be enough for her to carry all 100 watermelons to market. (This is trivial, if no more than one watermelon weighs more than 2\u00a0kg then any 10 can be placed in each of the crates, if no more than ten watermelons weighs more than 2\u00a0kg then one of each of them can be placed in each crate, etc., to a fast solution; observation will be the key to any rapid solution such as this or the number set problem).","type":"Document"}],"47":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"A thought experiment is an experiment that takes place in people's minds instead of in a laboratory or in the real world. In a real-life experiment, people can see and measure changes, but thought experiments only show special ways of thinking.  Anyone can do a thought experiment.\n\nThe usual goal of a thought experiment is to show what might happen: if this were true, what would follow from it?\n\nThe history of science has many thought experiments in it. Hans Christian \u00d8rsted was the first to use the German term  (means 'thought experiment') in about 1812. \n\nPosing hypothetical questions had been done for long time (by scientists and philosophers). However, people had no way of talking about it.\n\nFamous thought experiments\nTrolley problem\nSchr\u00f6dinger's cat\n\nReferences\n\nRelated pages \nParadox\nZeno's paradoxes\n\nScience\nPhilosophy of science\nThought","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"An experiment is a test of an idea or a method. It is often used by scientists and engineers. An experiment is used to see how well the idea matches the real world. Experiments have been used for many years to help people understand the world around them. Experiments are part of scientific method. Many experiments are controlled experiments or even blind experiments. Many are done in a laboratory. But thought experiments are done in mind.\n\nExperiments can tell us if a theory is false, or if something does not work. They cannot tell us if a theory is true. When Einstein said that gravity could affect light, it took a few years before astronomers could test it. General relativity predicts that the path of light is bent in a gravitational field; light passing a massive body is deflected towards that body. This effect has been confirmed by observing the light of stars or distant quasars being deflected as it passes the Sun.<ref>Shapiro S.S. et al 2004.","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"they only shared some of these thoughts with Beck.  For example, a person might have thought to themselves, \u201cThe therapist is being very quiet today; I wonder if he\u2019s mad at me?\u201d and then began to feel anxious as a result.\n\nIn the 1960s, researchers did a number of scientific experiments to study how thoughts affect behaviours and emotions.  This period in the history of psychotherapy is called \u201cthe cognitive revolution,\u201d and is also known as the \u201csecond wave\u201d of CBT.\n\nHow it works \nCBT targets different kinds of maladaptive thinking. The goal is to recognise unhealthy thoughts and develop them into positive thinking patterns. In that sense, CBT is scientific because irrational beliefs are thought of as theories which are tested to see if they are true. CBT is structured in that it uses an ABC format. A represents the activating event which triggers B, your beliefs. This is followed by C, the consequences, which are your actions. Beliefs are composed","type":"Document"}],"48":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Time Series is a statistical method used to forecast revenues, hotel occupancy, interest rates etc.\n\nStatistics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"An autoregressive model is a kind of model, which is mainly used in statistics. Like all statistics models, the idea is to describe a random process. In an autoregressive model, the output value depends linearly on one of the previous values of the model, plus a ransom variable, which describes that there is some randomness in the outcome. \n\nStatistics","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"Thompson: Digital Signal Processing - Concepts and Applications, Palgrave Macmillan, \nSteven W. Smith: Digital Signal Processing - A Practical Guide for Engineers and Scientists, Newnes, \nPaul A. Lynn, Wolfgang Fuerst: Introductory Digital Signal Processing with Computer Applications, John Wiley & Sons, \nJames D. Broesch: Digital Signal Processing Demystified, Newnes, \nJohn G. Proakis, Dimitris Manolakis: Digital Signal Processing - Principles, Algorithms and Applications, Pearson, \nHari Krishna Garg: Digital Signal Processing Algorithms, CRC Press, \nP. Gaydecki: Foundations Of Digital Signal Processing: Theory, Algorithms And Hardware Design, Institution of Electrical Engineers, \nPaul M. Embree, Damon Danieli: C++ Algorithms for Digital Signal Processing, Prentice Hall, \nAnthony Zaknich: Neural Networks for Intelligent Signal Processing, World Scientific Pub Co Inc, \nVijay Madisetti, Douglas B. Williams:","type":"Document"}],"49":[{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"fishermen, as well as spin and bait casting fishermen, to increase\u00a0conservation\u00a0and to protect rare fish such as marlin. The practice is however disputed as it by some is considered unethical to perform painful actions to the fish for fun and not for the reason of food production. Because of this, catch-and-release practice is illegal in\u00a0Norway.\n\nCollection of live fish\nFish can also be collected in ways that do not injure them (such as in a\u00a0seine net), for observation and study or for keeping in\u00a0Aquarium. There is a substantial industry devoted to the collection, transport, export and farming of wild and domesticated live fish, usually freshwater or marine tropical fish.\n\nFishing with traps\nFish can also be collected in ways that do not injure them (such as in a\u00a0seine net), for observation and study or for keeping in\u00a0Aquarium. There is a substantial industry devoted to the collection, transport, export and farming of wild and","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"most of which are either deposit or\u00a0filter feeders. In this way, the toxins are\u00a0concentrated upward\u00a0within ocean\u00a0food chains.\n\nWhen pesticides are incorporated into the\u00a0marine ecosystem, they quickly become absorbed into marine\u00a0food webs. Once in the food webs, these pesticides can cause mutations, as well as diseases, which can be harmful to humans as well as the entire food web.\n\nToxic metals\u00a0can also be introduced into marine food webs. These can cause a change to tissue matter, biochemistry, behaviour, reproduction, and suppress growth in marine life. Also, many\u00a0animal feeds\u00a0have a high\u00a0fish meal\u00a0or\u00a0fish hydrolysate\u00a0content. In this way, marine toxins can be transferred to land animals, and appear later in meat and dairy products.  \n\nEvery time we wash a car or use fertilizer on our lawns we are polluting the ocean. People often think that water pollution comes from big factories, but most of the","type":"Document"},{"lc_attributes":{},"lc_secrets":{},"metadata":{},"page_content":"the late 2010s.\n\nRestoration\nScientists performed tank and ocean experiments on other animals, such as lobsters, to see if they would eat enough purple sea urchins to help the kelp forests grow back, but they only helped a little.\n\nIn places where sea otters have returned, like Juan de Fuca Strait, they ate enough sea urchins that the kelp forests grew back.\n\nSome companies hired red abalone divers to collect purple sea urchins and bring them to controlled sea ranches where they could be fed until they were healthy enough to sell for human use.\n\nReferences\n\nBiomes\nEcology\nHabitats","type":"Document"}]}}
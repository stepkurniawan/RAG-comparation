# prepare environement
import os
import time
import pandas as pd
from rag_vectorstore import similarity_search_doc, multi_similarity_search_doc
from LogSetup import logger
from rag_ragas import retriever_evaluation
from StipVectorStore import StipVectorStore
from StipKnowledgeBase import load_suswiki, load_wikipedia, load_50_qa_dataset
from StipEmbedding import StipEmbedding

####
EMBED_MODEL = StipEmbedding("bge").embed_model
CHUNK_SIZE = 200
CHUNK_OVERLAP_SCALE = 0.1
TOP_K = 3
INDEX_DISTANCE = "l2"
VECTORSTORE = StipVectorStore("faiss")
QUESTION_DATASET = load_50_qa_dataset()['train']


#%%### retriever
#### create vector store (ONLY FIRST TIME) #### 
## load knowledge base
# suswiki_kb = load_suswiki()
# wikipedia_kb = load_wikipedia()
## create vector store
# suswiki_vectorstore = VECTORSTORE.create_vectorstore(suswiki_kb, EMBED_MODEL, CHUNK_SIZE, CHUNK_OVERLAP_SCALE, INDEX_DISTANCE)
# wikipedia_vectorstore = VECTORSTORE.create_vectorstore(wikipedia_kb, EMBED_MODEL, CHUNK_SIZE, CHUNK_OVERLAP_SCALE, INDEX_DISTANCE)

#### load vector store
suswiki_vectorstore = VECTORSTORE.load_vectorstore("vectorstores/db_faiss/sustainability-methods-wiki/bge-large-en-v1.5_200_0.1_l2")
wikipedia_vectorstore = VECTORSTORE.load_vectorstore("vectorstores/db_faiss/wikipedia/bge-large-en-v1.5_200_0.1_l2")
#%% 

## sanity check
sanity_suswiki = suswiki_vectorstore.similarity_search_with_score("A/B testing", k=3)
sanity_wikipedia = wikipedia_vectorstore.similarity_search_with_score("A/B testing", k=3)




print("")